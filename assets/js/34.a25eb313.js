(window.webpackJsonp=window.webpackJsonp||[]).push([[34],{362:function(s,t,a){"use strict";a.r(t);var n=a(8),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"mysql"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mysql"}},[s._v("#")]),s._v(" MySQL")]),s._v(" "),t("h2",{attrs:{id:"前言"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#前言"}},[s._v("#")]),s._v(" 前言")]),s._v(" "),t("p",[s._v("文档涉及到的知识：")]),s._v(" "),t("ol",[t("li",[s._v("深入理解Mysql索引底层数据结构与算法")])]),s._v(" "),t("ul",[t("li",[t("p",[s._v("索引底层数据结构红黑树、B+树详解")])]),s._v(" "),t("li",[t("p",[s._v("面试常问的B树与B+树的区别是什么")])]),s._v(" "),t("li",[t("p",[s._v("索引在B+树上如何快速定位")])]),s._v(" "),t("li",[t("p",[s._v("千万级数据表如何用B+树索引快速查找")])]),s._v(" "),t("li",[t("p",[s._v("MylSAM与Innodb存储引擎底层索引实现区别")])]),s._v(" "),t("li",[t("p",[s._v("聚集索引、聚簇索引与稀疏索引到底是什么")])]),s._v(" "),t("li",[t("p",[s._v("为什么推荐使用自增整型的主键而不是UUID")])]),s._v(" "),t("li",[t("p",[s._v("很少使用的索引底层结构Hash是怎样的")])]),s._v(" "),t("li",[t("p",[s._v("联合索引底层数据存储结构又是怎样的")])]),s._v(" "),t("li",[t("p",[s._v("索引最左前缀原则底层实现原理")])])]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[s._v("Explain详解与索引最佳实践")])]),s._v(" "),t("ul",[t("li",[t("p",[s._v("Mysql执行计划Explain工具详解")])]),s._v(" "),t("li",[t("p",[s._v("Mysql优化经常用到的覆盖索引详解")])]),s._v(" "),t("li",[t("p",[s._v("从B+树底层来分析下常见索引优化规则")])]),s._v(" "),t("li",[t("p",[s._v("经常用到的like查询应该如何优化")])]),s._v(" "),t("li",[t("p",[s._v("索引优化最佳实践")])])]),s._v(" "),t("ol",{attrs:{start:"3"}},[t("li",[s._v("—条SQL在MySQL中是如何执行的")])]),s._v(" "),t("ul",[t("li",[t("p",[s._v("梳理下MySQL内部组件结构")])]),s._v(" "),t("li",[t("p",[s._v("为什么说Mysql的查询缓存很鸡肋")])]),s._v(" "),t("li",[t("p",[s._v("Mysql词法分析器原理详解")])]),s._v(" "),t("li",[t("p",[s._v("Mysql底层优化器与执行器详解")])]),s._v(" "),t("li",[t("p",[s._v("Mysql归档日志bin-log详解")])]),s._v(" "),t("li",[t("p",[s._v("不小心删库了如何快速恢复")])])]),s._v(" "),t("ol",{attrs:{start:"4"}},[t("li",[s._v("Mysql索引优化实战")])]),s._v(" "),t("ul",[t("li",[t("p",[s._v("Mysql索引下推优化详解")])]),s._v(" "),t("li",[t("p",[s._v("为什么范围查找Mysql没有用索引下推优化")])]),s._v(" "),t("li",[t("p",[s._v("Mysql内部选择索引机制揭秘")])]),s._v(" "),t("li",[t("p",[s._v("Mysql索引成本计算工具trace详解")])]),s._v(" "),t("li",[t("p",[s._v("看下常用的Order by与Group by优化细节")])]),s._v(" "),t("li",[t("p",[s._v("Using filesort文件排序原理详解")])]),s._v(" "),t("li",[t("p",[s._v("文件单路排序与双路排序详细过程")])]),s._v(" "),t("li",[t("p",[s._v("文件排序优化机制详解")])]),s._v(" "),t("li",[t("p",[s._v("互联网公司索引设计核心原则")])]),s._v(" "),t("li",[t("p",[s._v("社交场景APP索引设计优化实战")])])]),s._v(" "),t("ol",{attrs:{start:"5"}},[t("li",[s._v("Mysql索引优化实战二")])]),s._v(" "),t("ul",[t("li",[t("p",[s._v("最常用的分页查询如何高效优化")])]),s._v(" "),t("li",[t("p",[s._v("Join表关联查询优化")])]),s._v(" "),t("li",[t("p",[s._v("表关联嵌套循环连接Nested-Loop Join(NLJ)算法详解")])]),s._v(" "),t("li",[t("p",[s._v("基于块的嵌套循环连接Block Nested-Loop Join(BNL)算法")])]),s._v(" "),t("li",[t("p",[s._v("in和exsits优化细节小表驱动大表详解")])]),s._v(" "),t("li",[t("p",[s._v("count查询的各种形式优化细节")])]),s._v(" "),t("li",[t("p",[s._v("阿里巴巴Mysql优化规范详解")])]),s._v(" "),t("li",[t("p",[s._v("MySQL数据类型选择优化")])])]),s._v(" "),t("ol",{attrs:{start:"6"}},[t("li",[s._v("深入理解Mysql事务隔离级别与锁机制")])]),s._v(" "),t("ul",[t("li",[t("p",[s._v("Mysql事务及其ACID属性详解")])]),s._v(" "),t("li",[t("p",[s._v("Mysql事务隔离级别详解")])]),s._v(" "),t("li",[t("p",[s._v("Mysql底层锁机制详解")])]),s._v(" "),t("li",[t("p",[s._v("实例演示各种事务隔离级别效果")])]),s._v(" "),t("li",[t("p",[s._v("Mysql底层脏读与幻读如何解决")])]),s._v(" "),t("li",[t("p",[s._v("Mysql底层间隙锁(Gap Lock)详解与优化")])]),s._v(" "),t("li",[t("p",[s._v("Mysql底层临键锁(Next-key Locks)详解")])]),s._v(" "),t("li",[t("p",[s._v("lnnoDB的行锁到底锁的是什么")])])]),s._v(" "),t("ol",{attrs:{start:"7"}},[t("li",[s._v("深入理解MVCC与BufferPool缓存机制")])]),s._v(" "),t("ul",[t("li",[t("p",[s._v("彻底理解MVCC多版本并发控制机制")])]),s._v(" "),t("li",[t("p",[s._v("undo日志版本链与read view机制详解")])]),s._v(" "),t("li",[t("p",[s._v("通过实例演示理解MVCC内部版本链比对规则")])]),s._v(" "),t("li",[t("p",[s._v("lnnodb引擎SQL执行的BufferPool缓存机制")])])]),s._v(" "),t("ol",{attrs:{start:"8"}},[t("li",[s._v("进阶知识")])]),s._v(" "),t("ul",[t("li",[t("p",[s._v("MySQL内核查询成本计算实战")])]),s._v(" "),t("li",[t("p",[s._v("MySQL执行原理之索引合并详解")])]),s._v(" "),t("li",[t("p",[s._v("MySQL内核查询优化规则详解")])]),s._v(" "),t("li",[t("p",[s._v("InnoDB引擎底层原理及MySQL8.0新增特性详解")])])]),s._v(" "),t("h2",{attrs:{id:"数据库范式设计"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#数据库范式设计"}},[s._v("#")]),s._v(" 数据库范式设计")]),s._v(" "),t("h3",{attrs:{id:"范式设计"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#范式设计"}},[s._v("#")]),s._v(" 范式设计")]),s._v(" "),t("p",[s._v("关系数据库有六种范式：第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴斯-科德范式（BCNF）、第四范式(4NF）和第五范式（5NF，又称完美范式）。")]),s._v(" "),t("p",[t("strong",[s._v("第一范式")])]),s._v(" "),t("p",[s._v("定义： 属于第一范式关系的所有属性都不可再分，即数据项不可分。")]),s._v(" "),t("p",[s._v("理解： 第一范式强调数据表的原子性，是其他范式的基础。例如下表：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/2100.png",alt:"0"}})]),s._v(" "),t("p",[t("code",[s._v("name-age")]),s._v("列具有两个属性，一个name，一个 age不符合第一范式，把它拆分成两列")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/2102.png",alt:"0"}})]),s._v(" "),t("p",[t("strong",[s._v("第二范式")])]),s._v(" "),t("p",[s._v("第二范式（2NF）要求数据库表中的每个实例或行必须可以被惟一地区分。通常在实现来说，需要为表加上一个列，以存储各个实例的惟一标识。例如员工信息表中加上了员工编号（emp_id）列，因为每个员工的员工编号是惟一的，因此每个员工可以被惟一区分。这个惟一属性列被称为"),t("strong",[s._v("主关键字或主键、主码")]),s._v("。")]),s._v(" "),t("p",[s._v("也就是说要求表中只具有一个业务主键，而且第二范式（2NF）要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性。")]),s._v(" "),t("p",[s._v("有两张表：订单表，产品表")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/2093.png",alt:"0"}})]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/2101.png",alt:"0"}})]),s._v(" "),t("p",[s._v("一个订单有多个产品，所以订单的主键为【订单ID】和【产品ID】组成的联合主键，这样2个组件不符合第二范式，而且产品ID和订单ID没有强关联，故，把订单表进行拆分为订单表与订单与商品的中间表")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/2088.png",alt:"0"}})]),s._v(" "),t("p",[t("strong",[s._v("第三范式")])]),s._v(" "),t("p",[s._v("每一个非主属性既不部分依赖于也不传递依赖于业务主键，也就是在第二范式的基础上消除了非主键对主键的传递依赖。")]),s._v(" "),t("p",[s._v("例如，存在一个部门信息表，其中每个部门有部门编号（dept_id）、部门名称、部门简介等信息。那么在员工信息表中列出部门编号后就不能再将部门名称、部门简介等与部门有关的信息再加入员工信息表中。如果不存在部门信息表，则根据第三范式（3NF）也应该构建它，否则就会有大量的数据冗余。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/2094.png",alt:"img"}})]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/2099.png",alt:"img"}})]),s._v(" "),t("p",[s._v("其中")]),s._v(" "),t("ol",[t("li",[t("strong",[s._v("产品 ID与订单编号存在关联关系")])]),s._v(" "),t("li",[t("strong",[s._v("产品名称与订单编号存在关联关系")])]),s._v(" "),t("li",[t("strong",[s._v("产品ID与产品名称存在关联关系")])])]),s._v(" "),t("blockquote",[t("p",[s._v("订单表里如果如果产品ID发生改变，同一个表里产品名称也要跟着改变，这样不符合第三范式，应该把"),t("strong",[s._v("产品名称")]),s._v("这一列从订单表中删除。")])]),s._v(" "),t("h3",{attrs:{id:"反范式设计"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#反范式设计"}},[s._v("#")]),s._v(" 反范式设计")]),s._v(" "),t("p",[s._v("反范式化就是为了性能和读取效率得考虑而适当得对数据库设计范式得要求进行违反。允许存在少量得冗余，换句话来说反范式化就是使用空间来换取时间。")]),s._v(" "),t("p",[t("strong",[s._v("性能提升-缓存和汇总")])]),s._v(" "),t("p",[s._v("最常见的反范式化数据的方法是"),t("strong",[s._v("复制或者缓存")]),s._v("，在不同的表中存储相同的特定列。比如从父表冗余一些数据到子表的。")]),s._v(" "),t("p",[s._v("缓存衍生值也是有用的。如果需要显示每个用户发了多少消息，可以每次执行一个对用户发送消息进行"),t("code",[s._v("count")]),s._v("的子查询来计算并显示它，也可以在user表用户中建一个消息发送数目的专门列，每当用户发新消息时更新这个值。")]),s._v(" "),t("p",[s._v("有需要时创建一张完全独立的汇总表或缓存表也是提升性能的好办法。“缓存表”来表示存储那些可以比较简单地从其他表获取（但是每次获取的速度比较慢）数据的表（例如，逻辑上冗余的数据)。而“汇总表”时,则保存的是使用"),t("code",[s._v("GROUP BY")]),s._v("语句聚合数据的表。")]),s._v(" "),t("p",[s._v("在使用缓存表和汇总表时，有个关键点是如何维护缓存表和汇总表中的数据，常用的有两种方式")]),s._v(" "),t("ul",[t("li",[s._v("实时维护数据")]),s._v(" "),t("li",[s._v("定期重建")])]),s._v(" "),t("p",[s._v("这个取决于应用程序，不过一般来说，缓存表用实时维护数据更多点，往往在一个事务中同时更新数据本表和缓存表，汇总表则用定期重建更多，使用定时任务对汇总表进行更新。")]),s._v(" "),t("p",[t("strong",[s._v("性能提升-计数器表")])]),s._v(" "),t("p",[s._v("计数器表在Web应用中很常见。比如网站点击数、用户的朋友数、文件下载次数等。对于高并发下的处理，首先可以创建一张独立的表存储计数器，这样可使计数器表小且快，并且可以使用一些更高级的技巧。")]),s._v(" "),t("p",[s._v("比如假设有一个计数器表，只有一行数据，记录网站的点击次数，网站的每次点击都会导致对计数器进行更新，问题在于，对于任何想要更新这一行的事务来说，这条记录上都有一个全局的互斥锁(mutex)。这会使得这些事务只能串行执行，会严重限制系统的并发能力。")]),s._v(" "),t("p",[s._v("改进：可以将计数器保存在多行中，每次随机选择一行进行更新。在具体实现上，可以增加一个槽（"),t("code",[s._v("slot")]),s._v(")字段，然后预先在这张表增加100行或者更多数据，当对计数器更新时，选择一个随机的槽（"),t("code",[s._v("slot")]),s._v(")进行更新即可。")]),s._v(" "),t("blockquote",[t("p",[s._v("这种解决思路其实就是"),t("strong",[s._v("写热点的分散")]),s._v("，在JDK的JDK1.8中新的原子类"),t("code",[s._v("LongAdder")]),s._v("也是这种处理方式，而我们在实际的缓冲中间件Redis等的使用、架构设计中，可以采用这种写热点的分散的方式，当然架构设计中对于写热点还有"),t("strong",[s._v("削峰填谷")]),s._v("的处理方式，这种在MySQL的实现中也有体现。")])]),s._v(" "),t("p",[t("strong",[s._v("反范式设计-分库分表中的查询")])]),s._v(" "),t("p",[s._v("例如，用户购买了商品,需要将交易记录保存下来,那么如果按照买家的纬度分表，则每个买家的交易记录都被保存在同一表中，我们可以很快、 很方便地査到某个买家的购买情况,，但是某个商品被购买的交易数据很有可能分布在多张表中，査找起来比较麻烦。反之，按照商品维度分表，则可以很方便地査找到该商品的购买情况，但若要査找到买家的交易记录，则会比较麻烦 。")]),s._v(" "),t("p",[s._v("所以常见的解决方式如下：")]),s._v(" "),t("ol",[t("li",[s._v("在多个分片表查询后合并数据集, 这种方式的效率很低；")]),s._v(" "),t("li",[s._v("记录两份数据, 一份按照买家纬度分表, 一份按照商品维度分表；")]),s._v(" "),t("li",[s._v("通过搜索引擎解决, 但如果实时性要求很高, 就需要实现实时搜索。")])]),s._v(" "),t("p",[s._v("在某电商交易平台下，可能有买家査询自己在某一时间段的订单，也可能有卖家査询自已在某一时间段的订单，如果使用了分库分表方案，则这两个需求是难以满足的，因此，通用的解决方案是：在交易生成时生成一份按照买家分片的数据副本和一份按照卖家分片的数据副本，查询时分别满足之前的两个需求，因此，查询的数据和交易的数据可能是分别存储的，并从不同的系统提供接口。")]),s._v(" "),t("h3",{attrs:{id:"范式化和反范式总结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#范式化和反范式总结"}},[s._v("#")]),s._v(" 范式化和反范式总结")]),s._v(" "),t("p",[t("strong",[s._v("范式化设计优缺点")])]),s._v(" "),t("ol",[t("li",[s._v("范式化的更新操作通常比反范式化要快。")]),s._v(" "),t("li",[s._v("当数据较好地范式化时，就只有很少或者没有重复数据，所以只需要修改更少的数据。")]),s._v(" "),t("li",[s._v("范式化的表通常更小，可以更好地放在内存里，所以执行操作会更快。")]),s._v(" "),t("li",[s._v("很少有多余的数据意味着检索列表数据时更少需要DISTINCT或者GROUP BY语句。在非范式化的结构中必须使用DISTINCT或者GROUPBY才能获得一份唯一的列表，但是如果是一张单独的表，很可能则只需要简单的查询这张表就行了。")])]),s._v(" "),t("p",[s._v("范式化设计的缺点是通常需要关联。稍微复杂一些的查询语句在符合范式的表上都可能需要至少一次关联，也许更多。这不但代价昂贵，也可能使一些索引策略无效。例如，范式化可能将列存放在不同的表中，而这些列如果在一个表中本可以属于同一个索引。")]),s._v(" "),t("p",[t("strong",[s._v("反范式化设计优缺点")])]),s._v(" "),t("ol",[t("li",[s._v("反范式设计可以减少表的关联")]),s._v(" "),t("li",[s._v("可以更好的进行索引优化。")])]),s._v(" "),t("p",[s._v("反范式设计缺点也很明显")]),s._v(" "),t("ol",[t("li",[s._v("存在数据冗余及数据维护异常；")]),s._v(" "),t("li",[s._v("对数据的修改需要更多的成本。")])]),s._v(" "),t("h2",{attrs:{id:"mysql内部结构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mysql内部结构"}},[s._v("#")]),s._v(" MySQL内部结构")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/12570.png",alt:"img"}})]),s._v(" "),t("p",[s._v("大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。")]),s._v(" "),t("p",[t("strong",[s._v("Server层")])]),s._v(" "),t("p",[s._v("主要包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。")]),s._v(" "),t("p",[t("strong",[s._v("Store层")])]),s._v(" "),t("p",[s._v("存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。也就是说如果我们在create table时不指定表的存储引擎类型,默认会给你设置存储引擎为InnoDB。")]),s._v(" "),t("p",[t("strong",[s._v("示例数据库")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("255")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ENGINE")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("InnoDB")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHARSET")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("utf8"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("strong",[s._v("连接器")])]),s._v(" "),t("p",[s._v("连接数据库。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令如下：")]),s._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("mysql "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-h")]),s._v(" host"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("数据库地址"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-u")]),s._v(" root"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("用户"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-p")]),s._v(" root"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("密码"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-P")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3306")]),s._v("\n")])])]),t("p",[s._v("在完成经典的 TCP 握手后，连接器就要开始认证身份。用户成功建立连接后，即使用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。用户的权限表在系统表空间的mysql的user表中。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/12637.png",alt:"img"}})]),s._v(" "),t("p",[s._v("连接完成后，如果没有后续的动作，这个连接就处于空闲状态，可以在 "),t("code",[s._v("show processlist")]),s._v(" 命令中看到它。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/12632.png",alt:"img"}})]),s._v(" "),t("blockquote",[t("p",[s._v("客户端如果长时间不发送command到Server端，连接器就会自动将它断开。这个时间是由参数 "),t("code",[s._v("wait_timeout")]),s._v(" 控制的，默认值是 8 小时。")]),s._v(" "),t("p",[s._v("开发当中我们大多数时候用的都是长连接，连接成功后，如果客户端持续有请求，则一直使用同一个连接，如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉。")]),s._v(" "),t("p",[s._v("怎么解决"),t("strong",[s._v("长连接累积导致内存占用太大")]),s._v("问题呢？")]),s._v(" "),t("ol",[t("li",[s._v("定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。")]),s._v(" "),t("li",[s._v("如果用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 "),t("code",[s._v("mysql_reset_connection")]),s._v(" 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。")])])]),s._v(" "),t("p",[t("strong",[s._v("分析器")])]),s._v(" "),t("p",[s._v("MySQL 需要对 SQL 语句做解析。词法分析器分成6个主要步骤完成对sql语句的分析")]),s._v(" "),t("p",[t("strong",[s._v("词法分析->语法分析->语义分析->构造执行树->生成执行计划->计划的执行")])]),s._v(" "),t("p",[s._v("下图是SQL词法分析的过程步骤：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/12742.png",alt:"img"}})]),s._v(" "),t("p",[t("strong",[s._v("优化器")])]),s._v(" "),t("p",[s._v("优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。通过"),t("strong",[s._v("计算cost值")]),s._v("选择最佳的执行方案。")]),s._v(" "),t("p",[t("strong",[s._v("执行器")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" test "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("ol",[t("li",[s._v("调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；")]),s._v(" "),t("li",[s._v("调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。")]),s._v(" "),t("li",[s._v("执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。")])]),s._v(" "),t("p",[t("strong",[s._v("bin-log归档")])]),s._v(" "),t("p",[s._v("SQL执行时，会将sql语句的执行逻辑记录在bin-log当中，binlog是Server层实现的二进制日志，它会记录我们的cud操作。")]),s._v(" "),t("p",[s._v("Binlog有以下几个特点：")]),s._v(" "),t("ol",[t("li",[s._v("Binlog在MySQL的Server层实现（引擎共用）")]),s._v(" "),t("li",[s._v("Binlog为逻辑日志,记录的是一条语句的原始逻辑")]),s._v(" "),t("li",[s._v("Binlog不限大小,追加写入,不会覆盖以前的日志")])]),s._v(" "),t("p",[s._v("如果，我们"),t("strong",[s._v("误删了数据库")]),s._v("，可以"),t("strong",[s._v("使用binlog进行归档")]),s._v("！首先需要先开启MySQL的binlog功能。")]),s._v(" "),t("p",[t("strong",[s._v("配置my.cnf")])]),s._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("配置开启binlog\nlog-bin"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("/usr/local/mysql/data/binlog/mysql-bin\n注意5.7以及更高版本需要配置本项：server-id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("123454")]),s._v("（自定义,保证唯一性）"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#binlog格式，有3种statement,row,mixed")]),s._v("\nbinlog-format"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("ROW\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#表示每1次执行写入就与硬盘同步，会影响性能，为0时表示，事务提交时mysql不做刷盘操作，由系统决定")]),s._v("\nsync-binlog"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n")])])]),t("p",[t("strong",[s._v("binlog命令")])]),s._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("show variables like "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'%log_bin%'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" 查看bin-log是否开启\nflush logs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" 会多一个最新的bin-log日志\nshow master status"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" 查看最后一个bin-log日志的相关信息\nreset master"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" 清空所有的bin-log日志\n/usr/local/mysql/bin/mysqlbinlog --no-defaults /usr/local/mysql/data/binlog/mysql-bin.000001 查看binlog内容 \n")])])]),t("p",[s._v("binlog里的内容不具备可读性，所以需要我们自己去判断恢复的逻辑点位，怎么观察呢？看重点信息，比如"),t("code",[s._v("begin,commit")]),s._v("这种关键词信息，只要在binlog当中看到了，你就可以理解为begin-commit之间的信息是一个完整的事务逻辑,然后再根据位置position判断恢复即可。binlog内容如下：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/12847.png",alt:"img"}})]),s._v(" "),t("p",[t("strong",[s._v("数据归档操作")])]),s._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("从bin-log恢复数据\n恢复全部数据\n/usr/local/mysql/bin/mysqlbinlog --no-defaults /usr/local/mysql/data/binlog/mysql-bin.000001 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("mysql "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-uroot")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-p")]),s._v(" tuling"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("数据库名"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n恢复指定位置数据\n/usr/local/mysql/bin/mysqlbinlog --no-defaults --start-position"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"408"')]),s._v(" --stop-position"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"731"')]),s._v("  /usr/local/mysql/data/binlog/mysql-bin.000001 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("mysql "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-uroot")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-p")]),s._v(" tuling"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("数据库"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n恢复指定时间段数据\n/usr/local/mysql/bin/mysqlbinlog --no-defaults /usr/local/mysql/data/binlog/mysql-bin.000001 --stop-date"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"2018-03-02 12:00:00"')]),s._v("  --start-date"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"2019-03-02 11:55:00"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("mysql "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-uroot")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-p")]),s._v(" test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("数据库"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),t("p",[t("strong",[s._v("归档测试")])]),s._v(" "),t("ol",[t("li",[s._v("定义一个存储过程，写入数据")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("drop")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("procedure")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("exists")]),s._v(" tproc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("delimiter")]),s._v(" $$\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("create")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("procedure")]),s._v(" tproc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("begin")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("declare")]),s._v(" s "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("default")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("declare")]),s._v(" c "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("char")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("default")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("repeat")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" s"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),s._v("i "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("start")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("transaction")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("insert")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("into")]),s._v(" test "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("c"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("commit")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" s"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("s"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v("$$\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("delimiter")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("ol",{attrs:{start:"2"}},[t("li",[s._v("删除数据")])]),s._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("truncate "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("test")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("ol",{attrs:{start:"3"}},[t("li",[s._v("利用binlog归档")])]),s._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("/usr/local/mysql/bin/mysqlbinlog --no-defaults /usr/local/mysql/data/binlog/mysql-bin.000001 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("mysql "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-uroot")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-p")]),s._v(" tuling"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("数据库名"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),t("ol",{attrs:{start:"4"}},[t("li",[s._v("归档完毕，数据恢复")])]),s._v(" "),t("h2",{attrs:{id:"explain工具"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#explain工具"}},[s._v("#")]),s._v(" Explain工具")]),s._v(" "),t("p",[s._v("使用"),t("code",[s._v("EXPLAIN")]),s._v("关键字可以模拟优化器执行SQL语句，分析你的查询语句或是结构的性能瓶颈 在 select 语句之前增加 explain 关键字，MySQL 会在查询上设置一个标记，执行查询会返回执行计划的信息，而不是执行这条SQL")]),s._v(" "),t("blockquote",[t("p",[s._v("如果 from 中包含子查询，仍会执行该子查询，将结果放入临时表中")])]),s._v(" "),t("p",[t("strong",[s._v("Explain分析示例")])]),s._v(" "),t("p",[t("a",{attrs:{href:"https://dev.mysql.com/doc/refman/5.7/en/explain-output.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("参考官方文档"),t("OutboundLink")],1)]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[s._v("示例表：\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DROP")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("IF")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXISTS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("actor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("actor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("45")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("update_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("datetime")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ENGINE")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("InnoDB")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHARSET")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("utf8"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("actor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("update_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2017-12-22 15:27:18'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2017-12-22 15:27:18'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2017-12-22 15:27:18'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DROP")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("IF")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXISTS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("film"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("film"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("idx_name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ENGINE")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("InnoDB")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHARSET")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("utf8"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("film"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'film0'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'film1'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'film2'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DROP")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("IF")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXISTS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("film_actor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("film_actor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("film_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("actor_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("remark"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("255")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("idx_film_actor_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("film_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("actor_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ENGINE")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("InnoDB")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHARSET")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("utf8"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("film_actor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("film_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("actor_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" actor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119170032583.png",alt:"image-20240119170032583"}})]),s._v(" "),t("blockquote",[t("p",[s._v("在查询中的每个表会输出一行，如果有两个表通过 join 连接查询，那么会输出两行")])]),s._v(" "),t("p",[s._v("接下来我们将展示 explain 中每个列的信息。")]),s._v(" "),t("p",[t("strong",[s._v("1. id列")])]),s._v(" "),t("p",[s._v("id列的编号是 select 的序列号，有几个 select 就有几个id，并且id的顺序是按 select 出现的顺序增长的。")]),s._v(" "),t("p",[s._v("id列越大执行优先级越高，id相同则从上往下执行，id为NULL最后执行。")]),s._v(" "),t("p",[t("strong",[s._v("2. select_type列")])]),s._v(" "),t("p",[s._v("select_type 表示对应行是简单还是复杂的查询。")]),s._v(" "),t("p",[s._v("1）simple：简单查询。查询不包含子查询和union")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" film "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[s._v("2）primary：复杂查询中最外层的 select")]),s._v(" "),t("p",[s._v("3）subquery：包含在 select 中的子查询（不在 from 子句中）")]),s._v(" "),t("p",[s._v("4）derived：包含在 from 子句中的子查询。MySQL会将结果存放在一个临时表中，也称为派生表（derived的英文含义）")]),s._v(" "),t("p",[s._v("用这个例子来了解 primary、subquery 和 derived 类型")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("session")]),s._v(" optimizer_switch"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'derived_merge=off'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 关闭mysql5.7新特性对衍生表的合并优化")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" actor "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" film "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" der"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119170436480.png",alt:"image-20240119170436480"}})]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("session")]),s._v(" optimizer_switch"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'derived_merge=on'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\t"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#还原默认配置")]),s._v("\n")])])]),t("p",[s._v("5）union：在 union 中的第二个和随后的 select")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("union")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("all")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119170503645.png",alt:"image-20240119170503645"}})]),s._v(" "),t("p",[t("strong",[s._v("3. table列")])]),s._v(" "),t("p",[s._v("这一列表示 explain 的一行正在访问哪个表。")]),s._v(" "),t("p",[s._v("当 from 子句中有子查询时，table列是格式，表示当前查询依赖 id=N 的查询，于是先执行 id=N 的查询。")]),s._v(" "),t("p",[s._v("当有 union 时，UNION RESULT 的 table 列的值为，1和2表示参与 union 的 select 行id。")]),s._v(" "),t("p",[t("strong",[s._v("4. type列")])]),s._v(" "),t("p",[s._v("这一列表示"),t("strong",[s._v("关联类型或访问类型")]),s._v("，即MySQL决定如何查找表中的行，查找数据行记录的大概范围。")]),s._v(" "),t("p",[s._v("依次从最优到最差分别为："),t("strong",[s._v("system > const > eq_ref > ref > range > index > ALL")])]),s._v(" "),t("p",[s._v("一般来说，"),t("strong",[s._v("得保证查询达到range级别，最好达到ref")])]),s._v(" "),t("p",[t("strong",[s._v("NULL")]),s._v("：mysql能够在优化阶段分解查询语句，在执行阶段用不着再访问表或索引。例如：在索引列中选取最小值，可以单独查找索引来完成，不需要在执行时访问表")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("min")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" film"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119170731360.png",alt:"image-20240119170731360"}})]),s._v(" "),t("p",[t("strong",[s._v("const, system")]),s._v("：mysql能对查询的某部分进行优化并将其转化成一个常量（可以看"),t("code",[s._v("show warnings")]),s._v(" 的结果）。用于 primary key 或 unique key 的所有列与常数比较时，所以表最多有一个匹配行，读取1次，速度比较快。"),t("strong",[s._v("system是const的特例")]),s._v("，表里只有一条元组匹配时为system")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("extended")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" film "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" tmp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119170801219.png",alt:"image-20240119170801219"}})]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("show")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("warnings")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119170823446.png",alt:"image-20240119170823446"}})]),s._v(" "),t("p",[t("strong",[s._v("eq_ref")]),s._v("：primary key 或 unique key 索引的所有部分被连接使用 ，最多只会返回一条符合条件的记录。这可能是在 const 之外最好的联接类型了，简单的 select 查询不会出现这种 type。")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" film_actor "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("left")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v(" film "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v(" film_actor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("film_id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" film"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119170843948.png",alt:"image-20240119170843948"}})]),s._v(" "),t("p",[t("strong",[s._v("ref")]),s._v("：相比 eq_ref，不使用唯一索引，而是使用普通索引或者唯一性索引的部分前缀，索引要和某个值相比较，可能会找到多个符合条件的行。")]),s._v(" "),t("ol",[t("li",[s._v("简单 select 查询，name是普通索引（非唯一索引）")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" film "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'film1'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119170938304.png",alt:"image-20240119170938304"}})]),s._v(" "),t("p",[s._v("2.关联表查询，idx_film_actor_id是film_id和actor_id的联合索引，这里使用到了film_actor的左边前缀film_id部分。")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" film_id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" film "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("left")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v(" film_actor "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v(" film"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" film_actor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("film_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119170952591.png",alt:"image-20240119170952591"}})]),s._v(" "),t("p",[t("strong",[s._v("range")]),s._v("：范围扫描通常出现在 "),t("code",[s._v("in(), between ,> ,<, >=")]),s._v(" 等操作中。使用一个索引来检索给定范围的行。")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" actor "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119171018445.png",alt:"image-20240119171018445"}})]),s._v(" "),t("p",[t("strong",[s._v("index")]),s._v("：扫描全索引就能拿到结果，一般是扫描某个二级索引，这种扫描不会从索引树根节点开始快速查找，而是直接对二级索引的叶子节点遍历和扫描，速度还是比较慢的，这种查询一般为使用覆盖索引，二级索引一般比较小，所以这种通常比ALL快一些。")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" film"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119171049668.png",alt:"image-20240119171049668"}})]),s._v(" "),t("p",[t("strong",[s._v("ALL")]),s._v("：即全表扫描，扫描你的聚簇索引的所有叶子节点。通常情况下这需要增加索引来进行优化了。")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" actor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119171057757.png",alt:"image-20240119171057757"}})]),s._v(" "),t("p",[t("strong",[s._v("5. possible_keys列")])]),s._v(" "),t("p",[s._v("这一列显示查询可能使用哪些索引来查找。")]),s._v(" "),t("p",[s._v("explain 时可能出现 possible_keys 有列，而 key 显示 NULL 的情况，这种情况是因为表中数据不多，mysql认为索引对此查询帮助不大，选择了全表查询。")]),s._v(" "),t("p",[s._v("如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查 where 子句看是否可以创造一个适当的索引来提高查询性能，然后用 explain 查看效果。")]),s._v(" "),t("p",[t("strong",[s._v("6. key列")])]),s._v(" "),t("p",[s._v("这一列显示mysql实际采用哪个索引来优化对该表的访问。")]),s._v(" "),t("p",[s._v("如果没有使用索引，则该列是 NULL。如果想强制mysql使用或忽视possible_keys列中的索引，在查询中使用 force index、ignore index。")]),s._v(" "),t("p",[t("strong",[s._v("7. key_len列")])]),s._v(" "),t("p",[s._v("这一列显示了mysql在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列。")]),s._v(" "),t("p",[s._v("举例来说，film_actor的联合索引 idx_film_actor_id 由 film_id 和 actor_id 两个int列组成，并且每个int是4字节。通过结果中的key_len=4可推断出查询使用了第一个列：film_id列来执行索引查找。")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" film_actor "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" film_id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119171742592.png",alt:"image-20240119171742592"}})]),s._v(" "),t("p",[s._v("key_len计算规则如下：")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("字符串，char(n)和varchar(n)，5.0.3以后版本中，"),t("strong",[s._v("n均代表字符数，而不是字节数")]),s._v("，如果是utf-8，一个数字或字母占1个字节，一个汉字占3个字节")])]),s._v(" "),t("li",[t("ul",[t("li",[s._v("char(n)：如果存汉字长度就是 3n 字节")]),s._v(" "),t("li",[s._v("varchar(n)：如果存汉字则长度是 3n + 2 字节，加的2字节用来存储字符串长度，因为varchar是变长字符串")])])]),s._v(" "),t("li",[t("p",[s._v("数值类型")])]),s._v(" "),t("li",[t("ul",[t("li",[s._v("tinyint：1字节")]),s._v(" "),t("li",[s._v("smallint：2字节")]),s._v(" "),t("li",[s._v("int：4字节")]),s._v(" "),t("li",[s._v("bigint：8字节")])])]),s._v(" "),t("li",[t("p",[s._v("时间类型")])]),s._v(" "),t("li",[t("ul",[t("li",[s._v("date：3字节")]),s._v(" "),t("li",[s._v("timestamp：4字节")]),s._v(" "),t("li",[s._v("datetime：8字节")])])]),s._v(" "),t("li",[t("p",[s._v("如果字段允许为 NULL，需要1字节记录是否为 NULL")])])]),s._v(" "),t("p",[s._v("索引最大长度是768字节，当字符串过长时，mysql会做一个类似"),t("strong",[s._v("左前缀索引")]),s._v("的处理，将前半部分的字符提取出来做索引。")]),s._v(" "),t("p",[t("strong",[s._v("8. ref列")])]),s._v(" "),t("p",[s._v("这一列显示了在key列记录的索引中，表查找值所用到的列或常量，常见的有：const（常量），字段名（例：film.id）")]),s._v(" "),t("p",[t("strong",[s._v("9. rows列")])]),s._v(" "),t("p",[s._v("这一列是mysql估计要读取并检测的行数，注意这个不是结果集里的行数。")]),s._v(" "),t("p",[t("strong",[s._v("10. Extra列")])]),s._v(" "),t("p",[s._v("这一列展示的是额外信息。常见的重要值如下：")]),s._v(" "),t("p",[s._v("1）"),t("strong",[s._v("Using index")]),s._v("：使用覆盖索引")]),s._v(" "),t("p",[t("strong",[s._v("覆盖索引定义")]),s._v("：mysql执行计划explain结果里的key有使用索引，如果select后面查询的字段都可以从这个索引的树中获取，这种情况一般可以说是用到了覆盖索引，extra里一般都有using index；覆盖索引一般针对的是辅助索引，整个查询结果只通过辅助索引就能拿到结果，不需要通过辅助索引树找到主键，再通过主键去主键索引树里获取其它字段值")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" film_id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" film_actor "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" film_id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119171919125.png",alt:"image-20240119171919125"}})]),s._v(" "),t("p",[s._v("2）"),t("strong",[s._v("Using where")]),s._v("：使用 where 语句来处理结果，并且查询的列未被索引覆盖")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" actor "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119171945765.png",alt:"image-20240119171945765"}})]),s._v(" "),t("p",[s._v("3）"),t("strong",[s._v("Using index condition")]),s._v("：查询的列不完全被索引覆盖，where条件中是一个前导列的范围；")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" film_actor "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" film_id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119172021404.png",alt:"image-20240119172021404"}})]),s._v(" "),t("p",[s._v("4）"),t("strong",[s._v("Using temporary")]),s._v("：mysql需要创建一张临时表来处理查询。出现这种情况一般是要进行优化的，首先是想到用索引来优化。")]),s._v(" "),t("ol",[t("li",[s._v("actor.name没有索引，此时创建了张临时表来distinct")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("distinct")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" actor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119172059358.png",alt:"image-20240119172059358"}})]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[s._v("film.name建立了idx_name索引，此时查询时extra是using index，没有用临时表")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("distinct")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" film"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119172151676.png",alt:"image-20240119172151676"}})]),s._v(" "),t("p",[s._v("5）"),t("strong",[s._v("Using filesort")]),s._v("：将用外部排序而不是索引排序，数据较小时从内存排序，否则需要在磁盘完成排序。这种情况下一般也是要考虑使用索引来优化的。")]),s._v(" "),t("ol",[t("li",[s._v("actor.name未创建索引，会浏览actor整个表，保存排序关键字name和对应的id，然后排序name并检索行记录")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" actor "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119172230846.png",alt:"image-20240119172230846"}})]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[s._v("film.name建立了idx_name索引,此时查询时extra是using index")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" film "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119172254791.png",alt:"image-20240119172254791"}})]),s._v(" "),t("p",[s._v("6）"),t("strong",[s._v("Select tables optimized away")]),s._v("：使用某些聚合函数（比如 max、min）来访问存在索引的某个字段时")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("min")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" film"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119172315772.png",alt:"image-20240119172315772"}})]),s._v(" "),t("h2",{attrs:{id:"mysql索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mysql索引"}},[s._v("#")]),s._v(" MySQL索引")]),s._v(" "),t("h3",{attrs:{id:"索引数据结构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#索引数据结构"}},[s._v("#")]),s._v(" 索引数据结构")]),s._v(" "),t("p",[s._v("索引是帮助MySQL高效获取数据的排好序的数据结构")]),s._v(" "),t("p",[t("strong",[s._v("B-Tree")]),s._v("性质：")]),s._v(" "),t("ol",[t("li",[s._v("叶节点具有相同的深度，叶节点的指针为空")]),s._v(" "),t("li",[s._v("所有索引元素不重复")]),s._v(" "),t("li",[s._v("节点中的数据索引从左到右递增排列")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119182449764.png",alt:"image-20240119182449764"}})]),s._v(" "),t("p",[t("strong",[s._v("B+Tree")]),s._v("性质：")]),s._v(" "),t("ol",[t("li",[s._v("非叶子节点不存储data，只存储索引(冗余)，可以放更多的索引")]),s._v(" "),t("li",[s._v("叶子节点包含所有索引字段")]),s._v(" "),t("li",[s._v("叶子节点用指针连接，提高区间访问的性能")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119182548156.png",alt:"image-20240119182548156"}})]),s._v(" "),t("p",[t("strong",[s._v("MyISAM存储引擎索引实现")])]),s._v(" "),t("p",[s._v("MyISAM索引文件和数据文件是分离的(非聚簇)")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119182643155.png",alt:"image-20240119182643155"}})]),s._v(" "),t("p",[t("strong",[s._v("InnoDB存储引擎索引实现")])]),s._v(" "),t("p",[s._v("InnoDB索引实现(主键索引是聚簇，非主键索引（辅助索引）是非聚簇)")]),s._v(" "),t("ol",[t("li",[s._v("表数据文件本身就是按B+Tree组织的一个索引结构文件")]),s._v(" "),t("li",[s._v("聚簇索引-叶节点包含了完整的数据记录")]),s._v(" "),t("li",[s._v("非主键索引结构叶子节点存储的数据包含主键值（考虑到数据一致性和节省存储空间）")])]),s._v(" "),t("p",[t("strong",[s._v("主键索引")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119182749357.png",alt:"image-20240119182749357"}})]),s._v(" "),t("p",[t("strong",[s._v("非主键索引（二级索引）")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119182752863.png",alt:"image-20240119182752863"}})]),s._v(" "),t("p",[t("strong",[s._v("联合索引")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119182835797.png",alt:"image-20240119182835797"}})]),s._v(" "),t("h3",{attrs:{id:"innodb中的索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#innodb中的索引"}},[s._v("#")]),s._v(" InnoDB中的索引")]),s._v(" "),t("p",[t("strong",[s._v("聚簇索引和非聚簇索引")])]),s._v(" "),t("p",[s._v("聚簇索引的定义：叶子节点保存的不只是键值，还保存了位于同一行记录里的其他列的信息，由于聚簇索引决定了表的物理排列顺序，一个表只有一个物理排列顺序，所以一个表只能创建一个聚簇索引。")]),s._v(" "),t("p",[s._v("非聚簇索引：叶子节点仅保存了键位信息以及该行数据的地址，有的非聚簇索引只保存了键位信息机器主键。")]),s._v(" "),t("ul",[t("li",[s._v("mysam存储引擎：不管是主键索引，唯一键索引还是普通索引都是非聚簇索引；")]),s._v(" "),t("li",[s._v("innodb存储引擎：有且只有一个聚簇索引。")])]),s._v(" "),t("blockquote",[t("p",[s._v("聚簇索引就是"),t("code",[s._v("innodb")]),s._v("存储引擎里的聚簇索引，非聚簇索引就是"),t("code",[s._v("innodb")]),s._v("存储引擎里的普通二级索引。")])]),s._v(" "),t("p",[t("strong",[s._v("聚簇索引")])]),s._v(" "),t("p",[s._v("InnoDB中使用了聚簇索引，就是"),t("strong",[s._v("将表的主键用来构造一棵B+树，并且将整张表的行记录数据存放在该B+树的叶子节点中，一页数据占16KB")]),s._v("。也就是所谓的索引即数据，数据即索引。由于聚簇索引是利用表的主键构建的，所以每张表只能拥有一个聚簇索引。")]),s._v(" "),t("p",[s._v("聚簇索引的叶子节点就是数据页。换句话说，数据页上存放的是完整的每行记录。聚簇索引优点就是：")]),s._v(" "),t("ul",[t("li",[s._v("通过过聚簇索引能获取完整的整行数据。")]),s._v(" "),t("li",[s._v("对于主键的排序查找和范围查找速度非常快。")])]),s._v(" "),t("blockquote",[t("p",[s._v("如果没有定义主键，MySQL会使用唯一性索引，没有唯一性索引，MySQL也会创建一个隐含列RowID来做主键，然后用这个主键来建立聚簇索引。")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/2098.png",alt:"0"}})]),s._v(" "),t("p",[t("strong",[s._v("辅助索引/二级索引")])]),s._v(" "),t("p",[s._v("对于辅助索引(Secondary Index，也称二级索引、非聚簇索引)，叶子节点并不包含行记录的全部数据。叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含了相应行数据的聚簇索引键。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/2096.png",alt:"0"}})]),s._v(" "),t("p",[s._v("比如辅助索引"),t("code",[s._v("index(node)")]),s._v("，那么叶子节点中包含的数据就包括了"),t("code",[s._v("(主键、note)")]),s._v("。")]),s._v(" "),t("p",[t("strong",[s._v("回表")])]),s._v(" "),t("p",[s._v("辅助索引的存在并不影响数据在聚簇索引中的组织，因此每张表上可以有多个辅助索引。")]),s._v(" "),t("p",[s._v("当通过辅助索引来寻找数据时")]),s._v(" "),t("ol",[t("li",[s._v("InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键；")]),s._v(" "),t("li",[s._v("然后再通过主键索引（聚簇索引）来找到一个完整的行记录。")])]),s._v(" "),t("blockquote",[t("p",[s._v("这个过程也被称为"),t("strong",[s._v("回表")]),s._v("。也就是根据辅助索引的值查询一条完整的用户记录需要使用到2棵B+树：一次辅助索引，一次聚簇索引。")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/2086.png",alt:"0"}})]),s._v(" "),t("p",[t("strong",[s._v("MRR")])]),s._v(" "),t("p",[s._v("从上文可以看出，每次从二级索引中读取到一条记录后，就会根据该记录的主键值执行回表操作。而在某个扫描区间中的二级索引记录的主键值是无序的，也就是说这些二级索引记录对应的聚簇索引记录所在的页面的页号是无序的。")]),s._v(" "),t("p",[s._v("每次执行回表操作时都相当于要随机读取一个聚簇索引页面，而这些随机IO带来的性能开销比较大。")]),s._v(" "),t("p",[s._v("MySQL中提出了一个名为"),t("code",[s._v("Disk-Sweep Multi-Range Read")]),s._v(" (MRR，多范围读取)的优化措施，即先读取一部分二级索引记录，将它们的主键值排好序之后再统一执行回表操作。")]),s._v(" "),t("p",[s._v("相对于每读取一条二级索引记录就立即执行回表操作，这样会节省一些IO开销。使用这个"),t("code",[s._v("MRR")]),s._v("优化措施的条件比较苛刻，所以我们直接认为每读取一条二级索引记录就立即执行回表操作。")]),s._v(" "),t("p",[t("strong",[s._v("联合索引/复合索引")])]),s._v(" "),t("p",[s._v("将表上的多个列组合起来进行索引我们称之为联合索引或者复合索引，比如"),t("code",[s._v("index(a,b)")]),s._v("就是将"),t("code",[s._v("a, b")]),s._v("两个列组合起来构成一个索引。")]),s._v(" "),t("blockquote",[t("p",[s._v("建立联合索引只会建立1棵B+树，多个列分别建立索引会分别以每个列则建立B+树，有几个列就有几个B+树，比如，"),t("code",[s._v("index(note)、index(b)")]),s._v("，就分别对"),t("code",[s._v("note, b")]),s._v("两个列各构建了一个索引。")])]),s._v(" "),t("p",[t("code",[s._v("index(note,b)")]),s._v("在索引构建上，包含了两个意思：")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("先把各个记录按照note列进行排序。")])]),s._v(" "),t("li",[t("p",[s._v("在记录的note列相同的情况下，采用b列进行排序")])])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/2097.png",alt:"0"}})]),s._v(" "),t("p",[t("strong",[s._v("自适应哈希索引")])]),s._v(" "),t("p",[s._v("在InnoDB存储引擎内部自己去监控索引表，如果监控到某个索引经常用，那么就认为是"),t("strong",[s._v("热数据")]),s._v("，然后内部自己创建一个"),t("code",[s._v("hash")]),s._v("索引，称之为自适应哈希索引( "),t("code",[s._v("Adaptive Hash Index,AHI")]),s._v(")，创建以后，如果下次又查询到这个索引，那么直接通过"),t("code",[s._v("hash")]),s._v("算法推导出记录的地址，直接一次就能查到数据，比重复去"),t("code",[s._v("B+tree")]),s._v("索引中查询三四次节点的效率高了不少。")]),s._v(" "),t("p",[s._v("InnoDB存储引擎使用的哈希函数采用"),t("strong",[s._v("除法散列方式")]),s._v("，其冲突机制采用"),t("strong",[s._v("链表方式")]),s._v("。")]),s._v(" "),t("blockquote",[t("p",[s._v("对于自适应哈希索引仅是数据库自身创建并使用的，我们并不能对其进行干预。")]),s._v(" "),t("p",[s._v("哈希索引只能用来搜索等值的查询，如 "),t("code",[s._v("SELECT* FROM table WHERE index co=xxx")]),s._v("。而对于其他查找类型，如范围查找，是不能使用哈希索引的")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 查看当前自适应哈希索引的使用状况")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("show")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("engine")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("innodb")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("status")]),s._v("\\G"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/2084.png",alt:"0"}})]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/2090.png",alt:"0"}})]),s._v(" "),t("p",[s._v("通过 "),t("code",[s._v("hash searches: non-hash searches")]),s._v("可以大概了解使用哈希索引后的效率。")]),s._v(" "),t("h3",{attrs:{id:"三星索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#三星索引"}},[s._v("#")]),s._v(" 三星索引")]),s._v(" "),t("p",[s._v("对于一个查询而言，一个三星索引，可能是其最好的索引。")]),s._v(" "),t("p",[s._v("如果查询使用三星索引，一次查询通常只需要进行一次磁盘随机读以及一次窄索引片的扫描，因此其相应时间通常比使用一个普通索引的响应时间少几个数量级。")]),s._v(" "),t("p",[s._v("三星索引概念：")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("索引将相关的记录放到一起则获得一星；")])]),s._v(" "),t("li",[t("p",[s._v("如果索引中的数据顺序和查找中的排列顺序一致则获得二星；")])]),s._v(" "),t("li",[t("p",[s._v("如果索引中的列包含了查询中需要的全部列则获得三星。")])])]),s._v(" "),t("p",[t("strong",[s._v("一星★★")])]),s._v(" "),t("p",[s._v("一星的意思是：如果一个查询相关的索引行是相邻的或者至少相距足够靠近的话，必须扫描的索引片宽度就会缩至最短，也就是说，让索引片尽量变窄，也就是所说的索引的扫描范围越小越好。")]),s._v(" "),t("p",[t("strong",[s._v("二星（排序星）★")])]),s._v(" "),t("p",[s._v("在满足一星的情况下，当查询需要排序，"),t("code",[s._v("group by, order by")]),s._v("，如果查询所需的顺序与索引是一致的（索引本身是有序的），就可以不用再另外排序了，一般来说排序可是影响性能的关键因素。")]),s._v(" "),t("p",[t("strong",[s._v("三星（宽索引星）★★")])]),s._v(" "),t("p",[s._v("在满足了二星的情况下，如果索引中所包含了这个查询所需的所有列（包括 "),t("code",[s._v("where 子句")]),s._v(" 和 "),t("code",[s._v("select 子句")]),s._v("中所需的列，也就是覆盖索引），这样一来，查询就不再需要回表了，减少了查询的步骤和IO请求次数，性能几乎可以提升一倍。")]),s._v(" "),t("p",[t("strong",[s._v("达成三星索引")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("create")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" customer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  cno "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  lname "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  fname "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  sex "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  weight "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  city "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- sql查询")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" cno"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("fname "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" customer "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" lname "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("’xx’ "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" city "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("’yy’ "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" fname"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 建立三星索引")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("create")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("index")]),s._v(" idx_cust "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v(" customer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("city"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("lname"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("fname"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("cno"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("blockquote",[t("p",[s._v("第一颗星：所有等值谓词的列，是组合索引的开头的列，可以把索引片缩得很窄，符合。")]),s._v(" "),t("p",[s._v("第二颗星：order by的fname字段在组合索引中且是索引自动排序好的，符合。")]),s._v(" "),t("p",[s._v("第三颗星：select中的cno字段、fname字段在组合索引中存在，符合。")])]),s._v(" "),t("p",[t("strong",[s._v("达不成三星索引")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("user_name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("sex"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("c_date"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("datetime")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ENGINE")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("InnoDB")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHARSET")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("utf8"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- sql查询")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" user_name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("sex"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("age "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" test "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" user_name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("like")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'test%'")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" sex "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ORDER")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BY")]),s._v(" age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("ul",[t("li",[s._v("建立索引"),t("code",[s._v("(user_name,sex,age)")])])]),s._v(" "),t("p",[s._v("不满足第二颗星，user_name 采用了范围匹配，sex 是过滤列，此时age 列无法保证有序的。")]),s._v(" "),t("ul",[t("li",[s._v("建立索引"),t("code",[s._v("(sex, age，user_name)")])])]),s._v(" "),t("p",[s._v("不满足第一颗星，只可以匹配到sex，sex选择性很差，意味着是一个宽索引片。")]),s._v(" "),t("h3",{attrs:{id:"索引实践"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#索引实践"}},[s._v("#")]),s._v(" 索引实践")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 示例表：")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("24")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("''")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'姓名'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'0'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'年龄'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("''")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'职位'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("hire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("timestamp")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CURRENT_TIMESTAMP")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'入职时间'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("idx_name_age_position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("USING")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BTREE")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ENGINE")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("InnoDB")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHARSET")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("utf8 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'员工记录表'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("hire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("NOW")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("hire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'HanMeimei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("23")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'dev'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("NOW")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("hire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Lucy'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("23")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'dev'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("NOW")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("h4",{attrs:{id:"全值匹配"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#全值匹配"}},[s._v("#")]),s._v(" 全值匹配")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119173019130.png",alt:"image-20240119173019130"}})]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119173027745.png",alt:"image-20240119173027745"}})]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v("  name"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v("  age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119173037638.png",alt:"image-20240119173037638"}})]),s._v(" "),t("h4",{attrs:{id:"最左前缀法则"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#最左前缀法则"}},[s._v("#")]),s._v(" 最左前缀法则")]),s._v(" "),t("p",[s._v("如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列。")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Bill'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("31")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'dev'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119173130722.png",alt:"image-20240119173130722"}})]),s._v(" "),t("h4",{attrs:{id:"索引列上不做任何操作"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#索引列上不做任何操作"}},[s._v("#")]),s._v(" 索引列上不做任何操作")]),s._v(" "),t("p",[s._v("例如（计算、函数、（自动or手动）类型转换）会导致索引失效而转向全表扫描")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("left")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119173158544.png",alt:"image-20240119173158544"}})]),s._v(" "),t("p",[s._v("给hire_time增加一个普通索引：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALTER")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ADD")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INDEX")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("idx_hire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("hire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("USING")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BTREE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("date")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2018-09-30'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119173217332.png",alt:"image-20240119173217332"}})]),s._v(" "),t("p",[s._v("转化为日期范围查询，有可能会走索引：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" hire_time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2018-09-30 00:00:00'")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v("  hire_time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2018-09-30 23:59:59'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119173237898.png",alt:"image-20240119173237898"}})]),s._v(" "),t("p",[s._v("还原最初索引状态")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALTER")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DROP")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INDEX")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("idx_hire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("h4",{attrs:{id:"不能使用索引中范围条件右边的列"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#不能使用索引中范围条件右边的列"}},[s._v("#")]),s._v(" 不能使用索引中范围条件右边的列")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119173407346.png",alt:"image-20240119173407346"}})]),s._v(" "),t("h4",{attrs:{id:"尽量使用覆盖索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#尽量使用覆盖索引"}},[s._v("#")]),s._v(" 尽量使用覆盖索引")]),s._v(" "),t("p",[s._v("只访问索引的查询（索引列包含查询列），减少 "),t("code",[s._v("select *")]),s._v(" 语句")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("age "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("23")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119173530046.png",alt:"image-20240119173530046"}})]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("23")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119173612426.png",alt:"image-20240119173612426"}})]),s._v(" "),t("h4",{attrs:{id:"使用-not-in-not-exists会导致全表扫描"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#使用-not-in-not-exists会导致全表扫描"}},[s._v("#")]),s._v(" 使用"),t("code",[s._v("!=,<>,not in,not exists")]),s._v("会导致全表扫描")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119173814256.png",alt:"image-20240119173814256"}})]),s._v(" "),t("h4",{attrs:{id:"is-null-is-not-null-一般情况下无法使用索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#is-null-is-not-null-一般情况下无法使用索引"}},[s._v("#")]),s._v(" "),t("code",[s._v("is null,is not null")]),s._v(" 一般情况下无法使用索引")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("is")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("null")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119173910946.png",alt:"image-20240119173910946"}})]),s._v(" "),t("h4",{attrs:{id:"like以通配符开头导致全表扫描"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#like以通配符开头导致全表扫描"}},[s._v("#")]),s._v(" like以通配符开头导致全表扫描")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("like")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'%Lei'")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119174035356.png",alt:"image-20240119174035356"}})]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("like")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Lei%'")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119174047983.png",alt:"image-20240119174047983"}})]),s._v(" "),t("p",[s._v("如何解决"),t("code",[s._v("like'%字符串%")]),s._v("失效的问题？")]),s._v(" "),t("ol",[t("li",[s._v("使用覆盖索引，查询字段必须是建立覆盖索引字段")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("position "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("like")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'%Lei%'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119174236395.png",alt:"image-20240119174236395"}})]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[s._v("如果不能使用覆盖索引则可能需要借助搜索引擎，如"),t("code",[s._v("ElasticSearch")])])]),s._v(" "),t("h4",{attrs:{id:"字符串不加单引号索引失效"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#字符串不加单引号索引失效"}},[s._v("#")]),s._v(" 字符串不加单引号索引失效")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'1000'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119174343623.png",alt:"image-20240119174343623"}})]),s._v(" "),t("h4",{attrs:{id:"少使用or或in"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#少使用or或in"}},[s._v("#")]),s._v(" 少使用or或in")]),s._v(" "),t("p",[s._v("用or或in查询时，mysql不一定使用索引，mysql内部优化器会根据检索比例、表大小等多个因素整体评估是否使用索引，详见范围查询优化")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("or")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'HanMeimei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119174444026.png",alt:"image-20240119174444026"}})]),s._v(" "),t("h4",{attrs:{id:"范围查询优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#范围查询优化"}},[s._v("#")]),s._v(" 范围查询优化")]),s._v(" "),t("p",[s._v("给年龄添加单值索引")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALTER")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ADD")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INDEX")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("idx_age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("USING")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BTREE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119174527127.png",alt:"image-20240119174527127"}})]),s._v(" "),t("p",[s._v("没走索引原因：mysql内部优化器会根据检索比例、表大小等多个因素整体评估是否使用索引。比如这个例子，可能是由于单次数据量查询过大导致优化器最终选择不走索引")]),s._v(" "),t("p",[s._v("优化方法：可以将大的范围拆分成多个小范围")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("explain")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1001")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119174553731.png",alt:"image-20240119174553731"}})]),s._v(" "),t("p",[s._v("还原最初索引状态")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALTER")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DROP")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INDEX")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("idx_age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("h4",{attrs:{id:"索引使用总结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#索引使用总结"}},[s._v("#")]),s._v(" 索引使用总结")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240119174623484.png",alt:"image-20240119174623484"}})]),s._v(" "),t("blockquote",[t("p",[t("code",[s._v("like KK%")]),s._v("相当于=常量，"),t("code",[s._v("%KK,%KK%")]),s._v(" 相当于范围")])]),s._v(" "),t("h3",{attrs:{id:"mysql查询成本计算"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mysql查询成本计算"}},[s._v("#")]),s._v(" MySQL查询成本计算")]),s._v(" "),t("p",[t("strong",[s._v("示例")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("order_exp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v("  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("bigint")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'订单的主键'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("order_no"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHARACTER")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SET")]),s._v(" utf8 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COLLATE")]),s._v(" utf8_general_ci "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'订单的编号'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("order_note"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHARACTER")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SET")]),s._v(" utf8 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COLLATE")]),s._v(" utf8_general_ci "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'订单的说明'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("insert_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("datetime")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CURRENT_TIMESTAMP")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ON")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("UPDATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CURRENT_TIMESTAMP")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'插入订单的时间'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("expire_duration"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("bigint")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'订单的过期时长，单位秒'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("expire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("datetime")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'订单的过期时间'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("order_status"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("smallint")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'订单的状态，0：未支付；1：已支付；-1：已过期，关闭'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("USING")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BTREE")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("UNIQUE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INDEX")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("u_idx_day_status"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("insert_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("order_status"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("expire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("USING")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BTREE")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INDEX")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("idx_order_no"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("order_no"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("USING")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BTREE")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INDEX")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("idx_expire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("expire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("USING")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BTREE")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ENGINE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("InnoDB")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10819")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHARACTER")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SET")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" utf8 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COLLATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" utf8_general_ci ROW_FORMAT "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Dynamic"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("order_exp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'DD00_15S'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'你好，李焕英。7排15号,过期时长:DD00_15S'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2021-03-22 18:23:42'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("15")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2021-03-22 18:23:57'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("order_exp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("21")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'DD00_10S'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'你好，李焕英。7排10号,过期时长:DD00_10S'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2021-03-22 18:28:18'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2021-03-22 18:28:28'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("order_exp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("27")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'DD00_16S'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'你好，李焕英。7排16号,过期时长:DD00_16S'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2021-03-22 18:28:19'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2021-03-22 18:28:35'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("order_exp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("38")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'DD00_18S'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'你好，李焕英。7排18号,过期时长:DD00_18S'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2021-03-22 18:28:20'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2021-03-22 18:28:38'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("order_exp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'DD00_23S'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'你好，李焕英。7排23号,过期时长:DD00_23S'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2021-03-22 18:28:21'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("23")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2021-03-22 18:28:44'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[s._v("通过"),t("code",[s._v("EXPLAIN")]),s._v("语句查看到最后优化器决定使用的执行计划，优化器最终会选择成本最低的那种方案来作为最终的执行计划。")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SET")]),s._v(" optimizer_trace"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"enabled=on"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" order_exp "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" order_no "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("IN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'DD00_10S'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'DD00_15S'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'DD00_16S'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v("  expire_time"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2021-03-22 18:22:28'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" expire_time"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2021-03-22 18:35:09'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" insert_time"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" expire_time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" order_note "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("LIKE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'%7排1%'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v("  order_status "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" information_schema"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("OPTIMIZER_TRACE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[s._v("可以看见全表扫描的成本："),t("strong",[s._v("2.85")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240122170500210.png",alt:"image-20240122170500210"}})]),s._v(" "),t("ul",[t("li",[t("p",[s._v("使用索引"),t("code",[s._v("idx_order_no")]),s._v("的成本为："),t("strong",[s._v("1.81")])])]),s._v(" "),t("li",[t("p",[s._v("使用索引"),t("code",[s._v("idx_expire_time")]),s._v("的成本为："),t("strong",[s._v("2.01")])])])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240122170810730.png",alt:"image-20240122170810730"}})]),s._v(" "),t("p",[s._v("最终MySQL使用了"),t("code",[s._v("idx_expire_no")]),s._v("作为这个SQL查询过程中索引：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240122171050487.png",alt:"image-20240122171050487"}})]),s._v(" "),t("ol",[t("li",[t("strong",[s._v("I/O成本")])])]),s._v(" "),t("p",[s._v("我们的表经常使用的MyISAM、InnoDB存储引擎都是将数据和索引都存储到磁盘上的，当我们想查询表中的记录时，需要先把数据或者索引加载到内存中然后再操作。这个从磁盘到内存这个加载的过程损耗的时间称之为I/O成本。")]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[t("strong",[s._v("CPU成本")])])]),s._v(" "),t("p",[s._v("读取以及检测记录是否满足对应的搜索条件、对结果集进行排序等这些操作损耗的时间称之为CPU成本。")]),s._v(" "),t("p",[s._v("对于InnoDB存储引擎来说，页是磁盘和内存之间交互的基本单位，MySQL规定读取一个页面花费的成本默认是1.0，读取以及检测一条记录是否符合搜索条件的成本默认是0.2。1.0、0.2这些数字称之为成本常数，这两个成本常数我们最常用到，当然还有其他的成本常数。")]),s._v(" "),t("blockquote",[t("p",[s._v("不管读取记录时需不需要检测是否满足搜索条件，其成本都算是0.2。")])]),s._v(" "),t("h2",{attrs:{id:"mysql索引优化实战"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mysql索引优化实战"}},[s._v("#")]),s._v(" MySQL索引优化实战")]),s._v(" "),t("p",[t("strong",[s._v("示例二")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 示例表")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("24")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("''")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'姓名'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'0'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'年龄'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("''")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'职位'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("hire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("timestamp")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CURRENT_TIMESTAMP")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'入职时间'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("idx_name_age_position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("USING")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BTREE")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ENGINE")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("InnoDB")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHARSET")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("utf8 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'员工记录表'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("hire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("NOW")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("hire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'HanMeimei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("23")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'dev'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("NOW")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("hire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Lucy'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("23")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'dev'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("NOW")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 插入一些示例数据")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("drop")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("procedure")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("exists")]),s._v(" insert_emp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("delimiter")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("create")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("procedure")]),s._v(" insert_emp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("        \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("begin")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("declare")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                    \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                          \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("                 \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("insert")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("into")]),s._v(" employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("CONCAT"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'zhuge'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'dev'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("  \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                       \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("delimiter")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("call")]),s._v(" insert_emp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("strong",[s._v("1、联合索引第一个字段用范围不会走索引")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98405.png",alt:"0"}})]),s._v(" "),t("blockquote",[t("p",[s._v("联合索引第一个字段就用范围查找不会走索引，mysql内部可能觉得第一个字段就用范围，结果集应该很大，回表效率不高，还不如就全表扫描")])]),s._v(" "),t("p",[t("strong",[s._v("2、强制走索引")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("force")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("index")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("idx_name_age_position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98401.png",alt:"0"}})]),s._v(" "),t("blockquote",[t("p",[s._v("虽然使用了强制走索引让联合索引第一个字段范围查找也走索引，扫描的行rows看上去也少了点，但是最终查找效率不一定比全表扫描高，因为回表效率不高")])]),s._v(" "),t("p",[s._v("做一个小实验：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 关闭查询缓存")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("global")]),s._v(" query_cache_size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("  \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("global")]),s._v(" query_cache_type"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 执行时间0.333s")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 执行时间0.444s")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("force")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("index")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("idx_name_age_position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("strong",[s._v("3、覆盖索引优化")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("position "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98402.png",alt:"0"}})]),s._v(" "),t("p",[t("strong",[s._v("4、in和or在表数据量比较大的情况会走索引，在表记录不多的情况下会选择全表扫描")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'HanMeimei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Lucy'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98400-170547754227750.png",alt:"img"}})]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("or")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'HanMeimei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98400.png",alt:"0"}})]),s._v(" "),t("p",[s._v("做一个小实验，将employees 表复制一张employees_copy的表，里面保留两三条记录")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees_copy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'HanMeimei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Lucy'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98406.png",alt:"0"}})]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees_copy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("or")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'HanMeimei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98408.png",alt:"0"}})]),s._v(" "),t("p",[t("strong",[s._v("5、like KK% 一般情况都会走索引")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("like")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei%'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98404.png",alt:"0"}})]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees_copy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("like")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei%'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98407.png",alt:"0"}})]),s._v(" "),t("p",[s._v("这里补充一个概念，"),t("strong",[s._v("索引下推（Index Condition Pushdown，ICP）")]),s._v(", "),t("code",[s._v("like KK%")]),s._v("其实就是用到了索引下推优化")]),s._v(" "),t("h3",{attrs:{id:"索引下推"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#索引下推"}},[s._v("#")]),s._v(" 索引下推")]),s._v(" "),t("p",[s._v("对于辅助的联合索引"),t("code",[s._v("idx_name_age_position(name,age,position)")]),s._v("，正常情况按照"),t("strong",[s._v("最左前缀原则")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("like")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'LiLei%'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" position "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'manager'")]),s._v("\n")])])]),t("p",[s._v("这种情况只会走name字段索引，因为根据name字段过滤完，得到的索引行里的age和position是无序的，无法很好的利用索引。")]),s._v(" "),t("p",[s._v("在MySQL5.6之前的版本，这个查询只能在联合索引里匹配到名字是 "),t("strong",[s._v("'LiLei' 开头")]),s._v("的索引，然后拿这些索引对应的主键逐个回表，到主键索引上找出相应的记录，再比对"),t("strong",[s._v("age")]),s._v("和"),t("strong",[s._v("position")]),s._v("这两个字段的值是否符合。")]),s._v(" "),t("p",[s._v("MySQL 5.6引入了索引下推优化，"),t("strong",[s._v("可以在索引遍历过程中，对索引中包含的所有字段先做判断，过滤掉不符合条件的记录之后再回表，可以有效的减少回表次数")]),s._v("。使用了索引下推优化后，上面那个查询在联合索引里匹配到名字是 "),t("strong",[s._v("'LiLei' 开头")]),s._v("的索引之后，同时还会在索引里过滤"),t("strong",[s._v("age")]),s._v("和"),t("strong",[s._v("position")]),s._v("这两个字段，拿着过滤完剩下的索引对应的主键id再回表查整行数据。")]),s._v(" "),t("p",[s._v("索引下推会减少回表次数，对于innodb引擎的表索引下推"),t("strong",[s._v("只能用于二级索引")]),s._v("，innodb的主键索引（聚簇索引）树叶子节点上保存的是全行数据，所以这个时候索引下推并不会起到减少查询全行数据的效果。")]),s._v(" "),t("p",[t("strong",[s._v("为什么范围查找Mysql没有用索引下推优化？")])]),s._v(" "),t("p",[s._v("可能是Mysql认为范围查找过滤的结果集过大，"),t("code",[s._v("like KK%")]),s._v(" 在绝大多数情况来看，过滤后的结果集比较小，所以这里Mysql选择给 "),t("code",[s._v("like KK%")]),s._v(" 用了索引下推优化，当然这也不是绝对的，有时"),t("code",[s._v("like KK%")]),s._v(" 也不一定就会走索引下推。")]),s._v(" "),t("h3",{attrs:{id:"选择合适的索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#选择合适的索引"}},[s._v("#")]),s._v(" 选择合适的索引")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/75942.png",alt:"0"}})]),s._v(" "),t("p",[s._v("如果用name索引需要遍历name字段联合索引树，然后还需要根据遍历出来的主键值去主键索引树里再去查出最终数据，成本比全表扫描还高，可以用覆盖索引优化，这样只需要遍历name字段的联合索引树就能拿到所有结果，如下：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("position "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/75945.png",alt:"0"}})]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'zzz'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/75948.png",alt:"0"}})]),s._v(" "),t("p",[s._v("对于上面这两种 "),t("code",[s._v("name>'a'")]),s._v(" 和 "),t("code",[s._v("name>'zzz'")]),s._v(" 的执行结果，mysql最终是否选择走索引或者一张表涉及多个索引，mysql最终如何选择索引，我们可以用"),t("strong",[s._v("trace工具")]),s._v("来一查究竟，开启trace工具会影响mysql性能，所以只能临时分析sql使用，用完之后立即关闭")]),s._v(" "),t("p",[t("strong",[s._v("trace工具用法")]),s._v("：")]),s._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" session "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("optimizer_trace")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"enabled=on"')]),s._v(",end_markers_in_json"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("on"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("  --开启trace "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" * from employees where name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),s._v(" order by position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\nSELECT * FROM information_schema.OPTIMIZER_TRACE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n\n查看trace字段：\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"steps"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"join_preparation"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("    --第一阶段：SQL准备阶段，格式化sql\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"select#"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(",\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"steps"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"expanded_query"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"/* select#1 */ select '),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("id")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(" AS "),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("id")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(","),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(" AS "),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(","),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(" AS "),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(","),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(" AS "),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(","),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("hire_time"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(" AS "),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("hire_time"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(" from "),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(" where ("),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(" > 'a') order by "),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v('"')]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* steps */\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" /* join_preparation */\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"join_optimization"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("    --第二阶段：SQL优化阶段\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"select#"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(",\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"steps"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"condition_processing"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("    --条件处理\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"condition"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"WHERE"')]),s._v(",\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"original_condition"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"('),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(" > 'a')\"")]),s._v(",\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"steps"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"transformation"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"equality_propagation"')]),s._v(",\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"resulting_condition"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"('),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(" > 'a')\"")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"transformation"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"constant_propagation"')]),s._v(",\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"resulting_condition"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"('),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(" > 'a')\"")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"transformation"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"trivial_condition_removal"')]),s._v(",\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"resulting_condition"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"('),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(" > 'a')\"")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* steps */\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" /* condition_processing */\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"substitute_generated_columns"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" /* substitute_generated_columns */\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"table_dependencies"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("    --表依赖详情\n              "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"table"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"'),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v('"')]),s._v(",\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"row_may_be_null"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" false,\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"map_bit"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(",\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"depends_on_map_bits"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* depends_on_map_bits */\n              "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* table_dependencies */\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"ref_optimizer_key_uses"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* ref_optimizer_key_uses */\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"rows_estimation"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("    --预估表的访问成本\n              "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"table"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"'),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v('"')]),s._v(",\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"range_analysis"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"table_scan"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("     --全表扫描情况\n                    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"rows"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10123")]),s._v(",    --扫描行数\n                    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cost"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2054.7")]),s._v("    --查询成本\n                  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" /* table_scan */,\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"potential_range_indexes"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("    --查询可能使用的索引\n                    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"index"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"PRIMARY"')]),s._v(",    --主键索引\n                      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"usable"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" false,\n                      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cause"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"not_applicable"')]),s._v("\n                    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n                    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"index"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"idx_name_age_position"')]),s._v(",    --辅助索引\n                      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"usable"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" true,\n                      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"key_parts"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n                        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),s._v(",\n                        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"age"')]),s._v(",\n                        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"position"')]),s._v(",\n                        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"id"')]),s._v("\n                      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* key_parts */\n                    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n                  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* potential_range_indexes */,\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"setup_range_conditions"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n                  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* setup_range_conditions */,\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"group_index_range"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"chosen"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" false,\n                    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cause"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"not_group_by_or_distinct"')]),s._v("\n                  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" /* group_index_range */,\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"analyzing_range_alternatives"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("    --分析各个索引使用成本\n                    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"range_scan_alternatives"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n                      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"index"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"idx_name_age_position"')]),s._v(",\n                        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"ranges"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n                          "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"a < name"')]),s._v("      --索引使用范围\n                        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* ranges */,\n                        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"index_dives_for_eq_ranges"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" true,\n                        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"rowid_ordered"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" false,    --使用该索引获取的记录是否按照主键排序\n                        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"using_mrr"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" false,\n                        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"index_only"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" false,       --是否使用覆盖索引\n                        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"rows"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5061")]),s._v(",              --索引扫描行数\n                        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cost"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6074.2")]),s._v(",            --索引使用成本\n                        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"chosen"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" false,           --是否选择该索引\n                        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cause"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cost"')]),s._v("\n                      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n                    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* range_scan_alternatives */,\n                    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"analyzing_roworder_intersect"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"usable"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" false,\n                      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cause"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"too_few_roworder_scans"')]),s._v("\n                    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" /* analyzing_roworder_intersect */\n                  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" /* analyzing_range_alternatives */\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" /* range_analysis */\n              "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* rows_estimation */\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"considered_execution_plans"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"plan_prefix"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* plan_prefix */,\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"table"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"'),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v('"')]),s._v(",\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"best_access_path"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("    --最优访问路径\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"considered_access_paths"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("   --最终选择的访问路径\n                    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"rows_to_scan"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10123")]),s._v(",\n                      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"access_type"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"scan"')]),s._v(",     --访问类型：为scan，全表扫描\n                      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"resulting_rows"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10123")]),s._v(",\n                      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cost"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2052.6")]),s._v(",\n                      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"chosen"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" true,            --确定选择\n                      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"use_tmp_table"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v("\n                    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n                  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* considered_access_paths */\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" /* best_access_path */,\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"condition_filtering_pct"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),s._v(",\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"rows_for_plan"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10123")]),s._v(",\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cost_for_plan"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2052.6")]),s._v(",\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"sort_cost"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10123")]),s._v(",\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"new_cost_for_plan"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12176")]),s._v(",\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"chosen"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* considered_execution_plans */\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"attaching_conditions_to_tables"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"original_condition"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"('),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(" > 'a')\"")]),s._v(",\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"attached_conditions_computation"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* attached_conditions_computation */,\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"attached_conditions_summary"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"table"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"'),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v('"')]),s._v(",\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"attached"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"('),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v(" > 'a')\"")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* attached_conditions_summary */\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" /* attaching_conditions_to_tables */\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"clause_processing"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"clause"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"ORDER BY"')]),s._v(",\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"original_clause"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"'),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v('"')]),s._v(",\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"items"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"item"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"'),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v('"')]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* items */,\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"resulting_clause_is_simple"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" true,\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"resulting_clause"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"'),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("."),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v('"')]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" /* clause_processing */\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"reconsidering_access_paths_for_index_ordering"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"clause"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"ORDER BY"')]),s._v(",\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"steps"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* steps */,\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"index_order_summary"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"table"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"'),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v('"')]),s._v(",\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"index_provides_order"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" false,\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"order_direction"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"undefined"')]),s._v(",\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"index"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"unknown"')]),s._v(",\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"plan_changed"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" /* index_order_summary */\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" /* reconsidering_access_paths_for_index_ordering */\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"refine_plan"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"table"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"'),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v('"')]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* refine_plan */\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* steps */\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" /* join_optimization */\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"join_execution"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("    --第三阶段：SQL执行阶段\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"select#"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(",\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"steps"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* steps */\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" /* join_execution */\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" /* steps */\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n结论：全表扫描的成本低于索引扫描，所以mysql最终选择全表扫描\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" * from employees where name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'zzz'")]),s._v(" order by position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\nSELECT * FROM information_schema.OPTIMIZER_TRACE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n查看trace字段可知索引扫描的成本低于全表扫描，所以mysql最终选择索引扫描\n\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" session "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("optimizer_trace")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"enabled=off"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("    --关闭trace\n")])])]),t("h3",{attrs:{id:"常见sql优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#常见sql优化"}},[s._v("#")]),s._v(" 常见sql优化")]),s._v(" "),t("h4",{attrs:{id:"order-by与group-by优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#order-by与group-by优化"}},[s._v("#")]),s._v(" order by与group by优化")]),s._v(" "),t("p",[s._v("Case1：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/75983.png",alt:"0"}})]),s._v(" "),t("blockquote",[t("p",[s._v("利用最左前缀法则：中间字段不能断，因此查询用到了name索引，从key_len=74也能看出，age索引列用在排序过程中，因为Extra字段里没有using filesort")])]),s._v(" "),t("p",[s._v("Case 2：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/75979.png",alt:"0"}})]),s._v(" "),t("blockquote",[t("p",[s._v("从explain的执行结果来看：key_len=74，查询使用了name索引，由于用了position进行排序，跳过了age，出现了Using filesort。")])]),s._v(" "),t("p",[s._v("Case 3：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/75993.png",alt:"0"}})]),s._v(" "),t("blockquote",[t("p",[s._v("查找只用到索引name，age和position用于排序，无Using filesort。")])]),s._v(" "),t("p",[s._v("Case 4：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/76003.png",alt:"0"}})]),s._v(" "),t("blockquote",[t("p",[s._v("和Case 3中explain的执行结果一样，但是出现了Using filesort，因为索引的创建顺序为name,age,position，但是排序的时候age和position颠倒位置了。")])]),s._v(" "),t("p",[s._v("Case 5：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/76025.png",alt:"0"}})]),s._v(" "),t("blockquote",[t("p",[s._v("与Case 4对比，在Extra中并未出现Using filesort，因为age为常量，在排序中被优化，所以索引未颠倒，不会出现Using filesort。")])]),s._v(" "),t("p",[s._v("Case 6：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/76038.png",alt:"0"}})]),s._v(" "),t("blockquote",[t("p",[s._v("虽然排序的字段列与索引顺序一样，且order by默认升序，这里position desc变成了降序，导致与索引的排序方式不同，从而产生Using filesort。Mysql8以上版本有降序索引可以支持该种查询方式。")])]),s._v(" "),t("p",[s._v("Case 7：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/76049.png",alt:"0"}})]),s._v(" "),t("blockquote",[t("p",[s._v("对于排序来说，多个相等条件也是范围查询")])]),s._v(" "),t("p",[s._v("Case 8：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/76074.png",alt:"0"}})]),s._v(" "),t("blockquote",[t("p",[s._v("可以用覆盖索引优化")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/76079.png",alt:"0"}})]),s._v(" "),t("p",[t("strong",[s._v("优化总结")]),s._v("：")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("MySQL支持两种方式的排序"),t("code",[s._v("filesort")]),s._v("和"),t("code",[s._v("index")]),s._v("，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低。")])]),s._v(" "),t("li",[t("p",[t("code",[s._v("order by")]),s._v("满足两种情况会使用"),t("code",[s._v("Using index")]),s._v("。")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("order by语句使用索引最左前缀。")])]),s._v(" "),t("li",[t("p",[s._v("使用where子句与order by子句条件列组合满足索引最左前缀。")])])])]),s._v(" "),t("li",[t("p",[s._v("尽量在索引列上完成排序，遵循索引建立（索引创建的顺序）时的最左前缀法则。")])]),s._v(" "),t("li",[t("p",[s._v("如果"),t("code",[s._v("order by")]),s._v("的条件不在索引列上，就会产生Using filesort。")])]),s._v(" "),t("li",[t("p",[s._v("能用覆盖索引尽量用覆盖索引。")])]),s._v(" "),t("li",[t("p",[t("code",[s._v("group by")]),s._v("与"),t("code",[s._v("order by")]),s._v("很类似，其实质是先排序后分组，遵照索引创建顺序的最左前缀法则。对于group by的优化如果不需要排序的可以加上"),t("strong",[s._v("order by null禁止排序")]),s._v("。注意，where高于having，能写在where中的限定条件就不要去having限定了。")])])]),s._v(" "),t("h4",{attrs:{id:"分页查询优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分页查询优化"}},[s._v("#")]),s._v(" 分页查询优化")]),s._v(" "),t("p",[t("strong",[s._v("示例三")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 示例表：")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("24")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("''")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'姓名'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'0'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'年龄'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("''")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'职位'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("hire_time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("timestamp")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CURRENT_TIMESTAMP")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'入职时间'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("idx_name_age_position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("age"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("USING")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BTREE")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ENGINE")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("InnoDB")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHARSET")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("utf8 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'员工记录表'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[s._v("很多时候我们业务系统实现分页功能可能会用如下sql实现")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[s._v("表示从表 employees 中取出从 10001 行开始的 10 行记录。看似只查询了 10 条记录，实际这条 SQL 是先读取 10010 条记录，然后抛弃前 10000 条记录，然后读到后面 10 条想要的数据。因此要查询一张大表比较靠后的数据，执行效率是非常低的。")]),s._v(" "),t("p",[t("strong",[s._v("常见的分页场景优化技巧")]),s._v("：")]),s._v(" "),t("p",[t("strong",[s._v("1、根据自增且连续的主键排序的分页查询")])]),s._v(" "),t("p",[s._v("首先来看一个根据自增且连续主键排序的分页查询的例子：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("90000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/100109.png",alt:"0"}})]),s._v(" "),t("p",[s._v("该 SQL 表示查询从第 90001开始的五行数据，没添加单独 order by，表示通过"),t("strong",[s._v("主键排序")]),s._v("。我们再看表 employees ，因为主键是自增并且连续的，所以可以改写成按照主键去查询从第 90001开始的五行数据，如下：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("90000")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/100108.png",alt:"0"}})]),s._v(" "),t("p",[s._v("查询的结果是一致的。我们再对比一下执行计划：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("90000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/100117.png",alt:"0"}})]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("90000")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/100113.png",alt:"0"}})]),s._v(" "),t("p",[s._v("显然改写后的 SQL 走了索引，而且扫描的行数大大减少，执行效率更高。")]),s._v(" "),t("p",[s._v("但是，这条改写的SQL 在很多场景并不实用，因为表中可能某些记录被删后，主键空缺，导致结果不一致，如下图试验所示（先删除一条前面的记录，然后再测试原 SQL 和优化后的 SQL）：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/100105.png",alt:"0"}})]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/100103.png",alt:"0"}})]),s._v(" "),t("p",[s._v("两条 SQL 的结果并不一样，因此，如果主键不连续，不能使用上面描述的优化方法。")]),s._v(" "),t("p",[s._v("另外如果原 SQL 是 order by 非主键的字段，按照上面说的方法改写会导致两条 SQL 的结果不一致。所以这种改写得满足以下两个条件：")]),s._v(" "),t("ul",[t("li",[s._v("主键自增且连续")]),s._v(" "),t("li",[s._v("结果是按照主键排序的")])]),s._v(" "),t("p",[t("strong",[s._v("2、根据非主键字段排序的分页查询")])]),s._v(" "),t("p",[s._v("再看一个根据非主键字段排序的分页查询，SQL 如下：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ORDER")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BY")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("90000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/100110.png",alt:"0"}})]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ORDER")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BY")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("90000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/100107.png",alt:"0"}})]),s._v(" "),t("p",[s._v("发现并没有使用 name 字段的索引（key 字段对应的值为 null），具体原因上面讲过："),t("strong",[s._v("扫描整个索引并查找到没索引的行(可能要遍历多个索引树)的成本比扫描全表的成本更高，所以优化器放弃使用索引")]),s._v("。")]),s._v(" "),t("p",[s._v("知道不走索引的原因，那么怎么优化呢？")]),s._v(" "),t("p",[s._v("其实关键是"),t("strong",[s._v("让排序时返回的字段尽可能少")]),s._v("，所以可以让排序和分页操作先查出主键，然后根据主键查到对应的记录，SQL改写如下")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees e "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("90000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" ed "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ed"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/100106.png",alt:"0"}})]),s._v(" "),t("p",[s._v("需要的结果与原 SQL 一致，执行时间减少了一半以上，我们再对比优化前后sql的执行计划：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/100104.png",alt:"0"}})]),s._v(" "),t("p",[s._v("原 SQL 使用的是 filesort 排序，而优化后的 SQL 使用的是索引排序。")]),s._v(" "),t("h4",{attrs:{id:"join关联查询优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#join关联查询优化"}},[s._v("#")]),s._v(" join关联查询优化")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 示例表：")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("t1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("a"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("b"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("idx_a"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("a"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ENGINE")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("InnoDB")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHARSET")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("utf8"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("create")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" t2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("like")]),s._v(" t1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 插入一些示例数据")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 往t1表插入1万行记录")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("drop")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("procedure")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("exists")]),s._v(" insert_t1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("delimiter")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("create")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("procedure")]),s._v(" insert_t1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("        \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("begin")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("declare")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                    \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                          \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("                 \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("insert")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("into")]),s._v(" t1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("a"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("b"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("  \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                       \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("delimiter")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("call")]),s._v(" insert_t1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 往t2表插入100行记录")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("drop")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("procedure")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("exists")]),s._v(" insert_t2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("delimiter")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("create")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("procedure")]),s._v(" insert_t2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("        \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("begin")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("declare")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                    \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                          \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("                 \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("insert")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("into")]),s._v(" t2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("a"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("b"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("  \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                       \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("end")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("delimiter")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("call")]),s._v(" insert_t2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("strong",[s._v("mysql的表关联常见有两种算法")])]),s._v(" "),t("ul",[t("li",[t("p",[s._v("Nested-Loop Join 算法")])]),s._v(" "),t("li",[t("p",[s._v("Block Nested-Loop Join 算法")])])]),s._v(" "),t("p",[t("strong",[s._v("1、")]),s._v(" "),t("strong",[s._v("嵌套循环连接")]),s._v(" "),t("strong",[s._v("Nested-Loop Join(NLJ) 算法")])]),s._v(" "),t("p",[s._v("一次一行循环地从第一张表（称为"),t("strong",[s._v("驱动表")]),s._v("）中读取行，在这行数据中取到关联字段，根据关联字段在另一张表（"),t("strong",[s._v("被驱动表")]),s._v("）里取出满足条件的行，然后取出两张表的结果合集。")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" t1 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v(" t2 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v(" t1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("a"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" t2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("a"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/100112.png",alt:"0"}})]),s._v(" "),t("p",[s._v("从执行计划中可以看到这些信息：")]),s._v(" "),t("ul",[t("li",[s._v("驱动表是 t2，被驱动表是 t1。先执行的就是驱动表(执行计划结果的id如果一样则按从上到下顺序执行sql)；优化器一般会优先选择"),t("strong",[s._v("小表做驱动表")]),s._v("，用where条件过滤完驱动表，然后再跟被驱动表做关联查询。"),t("strong",[s._v("所以使用 inner join 时，排在前面的表并不一定就是驱动表")]),s._v("。")]),s._v(" "),t("li",[s._v("当使用left join时，左表是驱动表，右表是被驱动表，当使用right join时，右表时驱动表，左表是被驱动表，当使用join时，mysql会选择数据量比较小的表作为驱动表，大表作为被驱动表。")]),s._v(" "),t("li",[s._v("使用了 NLJ算法。一般 join 语句中，如果执行计划 Extra 中未出现 "),t("strong",[s._v("Using join buffer")]),s._v(" 则表示使用的 join 算法是 NLJ。")])]),s._v(" "),t("p",[t("strong",[s._v("上面sql的大致流程如下")]),s._v("：")]),s._v(" "),t("ol",[t("li",[s._v("从表 t2 中读取一行数据（如果t2表有查询过滤条件的，用先用条件过滤完，再从过滤结果里取出一行数据）；")]),s._v(" "),t("li",[s._v("从第 1 步的数据中，取出关联字段 a，到表 t1 中查找；")]),s._v(" "),t("li",[s._v("取出表 t1 中满足条件的行，跟 t2 中获取到的结果合并，作为结果返回给客户端；")]),s._v(" "),t("li",[s._v("重复上面 3 步。")])]),s._v(" "),t("p",[s._v("整个过程会读取 t2 表的所有数据("),t("strong",[s._v("扫描100行")]),s._v(")，然后遍历这每行数据中字段 a 的值，根据 t2 表中 a 的值索引扫描 t1 表中的对应行("),t("strong",[s._v("扫描100次 t1 表的索引，1次扫描可以认为最终只扫描 t1 表一行完整数据，也就是总共 t1 表也扫描了100行")]),s._v(")。因此整个过程扫描了 "),t("strong",[s._v("200 行")]),s._v("。")]),s._v(" "),t("p",[s._v("如果被驱动表的关联字段没索引，"),t("strong",[s._v("使用NLJ算法性能会比较低")]),s._v("，mysql会选择Block Nested-Loop Join算法。")]),s._v(" "),t("p",[t("strong",[s._v("2、")]),s._v(" "),t("strong",[s._v("基于块的嵌套循环连接 Block Nested-Loop Join(BNL)算法")])]),s._v(" "),t("p",[s._v("把"),t("strong",[s._v("驱动表")]),s._v("的数据读入到 join_buffer 中，然后扫描"),t("strong",[s._v("被驱动表")]),s._v("，把"),t("strong",[s._v("被驱动表")]),s._v("每一行取出来跟 join_buffer 中的数据做对比。")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" t1 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("inner")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v(" t2 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v(" t1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("b"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" t2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("b"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/100111.png",alt:"0"}})]),s._v(" "),t("p",[s._v("Extra 中 的Using join buffer (Block Nested Loop)说明该关联查询使用的是 BNL 算法。")]),s._v(" "),t("p",[t("strong",[s._v("上面sql的大致流程如下")]),s._v("：")]),s._v(" "),t("ol",[t("li",[s._v("把 t2 的所有数据放入到 "),t("strong",[s._v("join_buffer")]),s._v(" 中")]),s._v(" "),t("li",[s._v("把表 t1 中每一行取出来，跟 join_buffer 中的数据做对比")]),s._v(" "),t("li",[s._v("返回满足 join 条件的数据")])]),s._v(" "),t("p",[s._v("整个过程对表 t1 和 t2 都做了一次全表扫描，因此扫描的总行数为10000(表 t1 的数据总量) + 100(表 t2 的数据总量) = "),t("strong",[s._v("10100")]),s._v("。并且 join_buffer 里的数据是无序的，因此对表 t1 中的每一行，都要做 100 次判断，所以内存中的判断次数是 100 * 10000= "),t("strong",[s._v("100 万次")]),s._v("。")]),s._v(" "),t("p",[s._v("这个例子里表 t2 才 100 行，要是表 t2 是一个大表，join_buffer 放不下怎么办呢？·")]),s._v(" "),t("p",[s._v("join_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t2 的所有数据话，策略很简单，就是"),t("strong",[s._v("分段放")]),s._v("。")]),s._v(" "),t("p",[s._v("比如 t2 表有1000行记录， join_buffer 一次只能放800行数据，那么执行过程就是先往 join_buffer 里放800行记录，然后从 t1 表里取数据跟 join_buffer 中数据对比得到部分结果，然后清空  join_buffer ，再放入 t2 表剩余200行记录，再次从 t1 表里取数据跟 join_buffer 中数据对比。所以就多扫了一次 t1 表。")]),s._v(" "),t("p",[t("strong",[s._v("被驱动表的关联字段没索引为什么要选择使用 BNL 算法而不使用 Nested-Loop Join 呢？")])]),s._v(" "),t("p",[s._v("如果上面第二条sql使用 Nested-Loop Join，那么扫描行数为 100 * 10000 = 100万次，这个是"),t("strong",[s._v("磁盘扫描")]),s._v("。")]),s._v(" "),t("p",[s._v("很显然，用BNL磁盘扫描次数少很多，相比于磁盘扫描，BNL的内存计算会快得多。")]),s._v(" "),t("p",[s._v("因此MySQL对于被驱动表的关联字段没索引的关联查询，一般都会使用 BNL 算法。如果有索引一般选择 NLJ 算法，有索引的情况下 NLJ 算法比 BNL算法性能更高")]),s._v(" "),t("p",[t("strong",[s._v("对于关联sql的优化")])]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("关联字段加索引")]),s._v("，让mysql做join操作时尽量选择NLJ算法，驱动表因为需要全部查询出来，所以过滤的条件也尽量要走索引，避免全表扫描，总之，能走索引的过滤条件尽量都走索引")]),s._v(" "),t("li",[t("strong",[s._v("小表驱动大表")]),s._v("，写多表连接sql时如果"),t("strong",[s._v("明确知道")]),s._v("哪张表是小表可以用straight_join写法固定连接驱动方式，省去mysql优化器自己判断的时间")])]),s._v(" "),t("p",[t("strong",[s._v("straight_join解释：straight_join")]),s._v("功能同join类似，但能让左边的表来驱动右边的表，能改表优化器对于联表查询的执行顺序。")]),s._v(" "),t("p",[s._v("比如：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" t2 straight_join t1 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v(" t2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("a "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" t1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("a"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 代表指定mysql选着 t2 表作为驱动表。")]),s._v("\n")])])]),t("ul",[t("li",[t("strong",[s._v("straight_join")]),s._v("只适用于inner join，并不适用于left join，right join。（因为left join，right join已经代表指定了表的执行顺序）")]),s._v(" "),t("li",[s._v("尽可能让优化器去判断，因为大部分情况下mysql优化器是比人要聪明的。使用"),t("strong",[s._v("straight_join")]),s._v("一定要慎重，因为部分情况下人为指定的执行顺序并不一定会比优化引擎要靠谱。")])]),s._v(" "),t("p",[t("strong",[s._v("对于小表定义的明确")])]),s._v(" "),t("p",[s._v("在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，"),t("strong",[s._v("过滤完成之后")]),s._v("，计算参与 join 的各个字段的总数据量，"),t("strong",[s._v("数据量小的那个表，就是“小表")]),s._v("”，应该作为驱动表。")]),s._v(" "),t("h4",{attrs:{id:"in和exsits优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#in和exsits优化"}},[s._v("#")]),s._v(" in和exsits优化")]),s._v(" "),t("p",[s._v("原则："),t("strong",[s._v("小表驱动大表")]),s._v("，即小的数据集驱动大的数据集")]),s._v(" "),t("p",[t("strong",[s._v("in")]),s._v("：当B表的数据集小于A表的数据集时，in优于exists")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" A "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" B"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 等价于： 　")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" B"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("{      \n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" A "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" A"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" B"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id \n}              \n")])])]),t("p",[t("strong",[s._v("exists")]),s._v("：当A表的数据集小于B表的数据集时，exists优于in")]),s._v(" "),t("p",[s._v("将主查询A的数据，放到子查询B中做条件验证，根据验证结果（true或false）来决定主查询的数据是否保留")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" A "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("exists")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" B "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" B"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" A"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 等价于:")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" A"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("{\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" B "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" B"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" A"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id\n}\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#A表与B表的ID字段应建立索引              ")]),s._v("\n")])])]),t("p",[s._v("1、EXISTS (subquery)只返回TRUE或FALSE，因此子查询中的"),t("code",[s._v("SELECT *")]),s._v("也可以用"),t("code",[s._v("SELECT 1")]),s._v("替换,官方说法是实际执行时会忽略SELECT清单,因此没有区别")]),s._v(" "),t("p",[s._v("2、EXISTS子查询的实际执行过程可能经过了优化而不是我们理解上的逐条对比")]),s._v(" "),t("p",[s._v("3、EXISTS子查询往往也可以用JOIN来代替，何种最优需要具体问题具体分析")]),s._v(" "),t("h4",{attrs:{id:"count-查询优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#count-查询优化"}},[s._v("#")]),s._v(" count(*)查询优化")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 临时关闭mysql查询缓存，为了查看sql多次执行的真实时间")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("global")]),s._v(" query_cache_size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("global")]),s._v(" query_cache_type"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("count")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("count")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("count")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXPLAIN")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("count")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("              \n")])])]),t("blockquote",[t("p",[s._v("注意：以上4条sql只有根据某个字段count不会统计字段为null值的数据行")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/100116.png",alt:"0"}})]),s._v(" "),t("p",[t("strong",[s._v("四个sql的执行计划一样，说明这四个sql执行效率应该差不多")])]),s._v(" "),t("ul",[t("li",[t("p",[s._v("字段有索引："),t("code",[s._v("count(*)≈count(1)>count(字段)>count(主键 id)")]),s._v("，字段有索引，"),t("code",[s._v("count(字段)")]),s._v("统计走二级索引，二级索引存储数据比主键索引少，所以"),t("code",[s._v("count(字段)>count(主键 id)")])])]),s._v(" "),t("li",[t("p",[s._v("字段无索引："),t("code",[s._v("count(*)≈count(1)>count(主键 id)>count(字段)")]),s._v("，字段没有索引，"),t("code",[s._v("count(字段)")]),s._v("统计走不了索引，"),t("code",[s._v("count(主键 id)")]),s._v("可以走主键索引，所以"),t("code",[s._v("count(主键 id)>count(字段)")])])]),s._v(" "),t("li",[t("p",[t("code",[s._v("count(1)、count(字段)")]),s._v("执行过程类似，不过"),t("code",[s._v("count(1)")]),s._v("不需要取出字段统计，就用常量1做统计，"),t("code",[s._v("count(字段)")]),s._v("还需要取出字段，所以理论上"),t("code",[s._v("count(1)")]),s._v("比"),t("code",[s._v("count(字段)")]),s._v("会快一点。")])]),s._v(" "),t("li",[t("p",[t("code",[s._v("count(*)")]),s._v(" 是例外，mysql并不会把全部字段取出来，而是专门做了优化，不取值，按行累加，效率很高，所以不需要用"),t("code",[s._v("count(列名)或count(常量)")]),s._v("来替代 "),t("code",[s._v("count(*)")]),s._v("。")])])]),s._v(" "),t("p",[s._v("为什么对于"),t("code",[s._v("count(id)")]),s._v("，mysql最终选择辅助索引而不是主键聚簇索引？因为"),t("strong",[s._v("二级索引相对主键索引存储数据更少")]),s._v("，检索性能应该更高，mysql内部做了点优化(应该是在5.7版本才优化)。")]),s._v(" "),t("h4",{attrs:{id:"常见优化方法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#常见优化方法"}},[s._v("#")]),s._v(" 常见优化方法")]),s._v(" "),t("p",[t("strong",[s._v("1、查询mysql自己维护的总行数")])]),s._v(" "),t("p",[s._v("对于"),t("strong",[s._v("myisam存储引擎")]),s._v("的表做不带where条件的"),t("code",[s._v("count查询")]),s._v("性能是很高的，因为myisam存储引擎的表的总行数会被mysql存储在磁盘上，查询不需要计算")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/100114.png",alt:"0"}})]),s._v(" "),t("p",[s._v("对于"),t("strong",[s._v("innodb存储引擎")]),s._v("的表mysql不会存储表的总记录行数("),t("strong",[s._v("因为有MVCC机制")]),s._v(")，"),t("code",[s._v("count查询")]),s._v("需要实时计算")]),s._v(" "),t("p",[t("strong",[s._v("2、show table status")])]),s._v(" "),t("p",[s._v("如果只需要知道表总行数的估计值可以用如下sql查询，性能很高")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/100115.png",alt:"0"}})]),s._v(" "),t("p",[t("strong",[s._v("3、将总数维护到Redis里")])]),s._v(" "),t("p",[s._v("插入或删除表数据行的时候同时维护redis里的表总行数key的计数值(用incr或decr命令)，但是这种方式可能不准，很难保证表操作和redis操作的事务一致性")]),s._v(" "),t("p",[t("strong",[s._v("4、增加数据库计数表")])]),s._v(" "),t("p",[s._v("插入或删除表数据行的时候同时维护计数表，让他们在同一个事务里操作")]),s._v(" "),t("h3",{attrs:{id:"filesort文件排序"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#filesort文件排序"}},[s._v("#")]),s._v(" filesort文件排序")]),s._v(" "),t("p",[t("strong",[s._v("filesort文件排序方式")])]),s._v(" "),t("ul",[t("li",[s._v("单路排序：是一次性取出满足条件行的所有字段，然后在"),t("code",[s._v("sort buffer")]),s._v("中进行排序；用trace工具可以看到"),t("strong",[s._v("sort_mode")]),s._v("信息里显示"),t("code",[s._v("< sort_key, additional_fields >")]),s._v("或者"),t("code",[s._v("< sort_key, packed_additional_fields >")])]),s._v(" "),t("li",[s._v("双路排序（又叫"),t("strong",[s._v("回表")]),s._v("排序模式）：是首先根据相应的条件取出相应的"),t("strong",[s._v("排序字段")]),s._v("和"),t("strong",[s._v("可以直接定位行数据的行 ID")]),s._v("，然后在 sort buffer 中进行排序，排序完后需要再次取回其它需要的字段；用trace工具可以看到"),t("strong",[s._v("sort_mode")]),s._v("信息里显示"),t("code",[s._v("< sort_key, rowid >")])])]),s._v(" "),t("p",[s._v("MySQL 通过比较系统变量 "),t("code",[s._v("max_length_for_sort_data")]),s._v("("),t("strong",[s._v("默认1024字节")]),s._v(") 的大小和需要查询的字段总大小来判断使用哪种排序模式。")]),s._v(" "),t("ul",[t("li",[s._v("如果字段的总长度小于"),t("code",[s._v("max_length_for_sort_data")]),s._v(" ，使用单路排序模式；")]),s._v(" "),t("li",[s._v("如果字段的总长度大于"),t("code",[s._v("max_length_for_sort_data")]),s._v(" ，使用双路排序模式。")])]),s._v(" "),t("p",[t("strong",[s._v("示例验证下各种排序方式")]),s._v("：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/76138.png",alt:"0"}})]),s._v(" "),t("p",[s._v("查看下这条sql对应trace结果如下(只展示排序部分)：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("session")]),s._v(" optimizer_trace"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"enabled=on"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("end_markers_in_json"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--开启trace")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'zhuge'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" information_schema"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("OPTIMIZER_TRACE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\ntrace排序部分结果：\n"),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"join_execution"')]),s._v(": {    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--Sql执行阶段")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"select#"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"steps"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n          {\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"filesort_information"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n              {\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"direction"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"asc"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"table"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"`employees`"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"field"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"position"')]),s._v("\n              }\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* filesort_information */")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"filesort_priority_queue_optimization"')]),s._v(": {\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"usable"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cause"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"not applicable (no LIMIT)"')]),s._v("\n            } "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* filesort_priority_queue_optimization */")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"filesort_execution"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* filesort_execution */")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"filesort_summary"')]),s._v(": {                      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--文件排序信息")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"rows"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("                           "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--预计扫描行数")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"examined_rows"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("                  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--参与排序的行")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"number_of_tmp_files"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("                "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--使用临时文件的个数，这个值如果为0代表全部使用的sort_buffer内存排序，否则使用的磁盘文件排序")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"sort_buffer_size"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("262056")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("              "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--排序缓存的大小，单位Byte")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"sort_mode"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"<sort_key, packed_additional_fields>"')]),s._v("       "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--排序方式，这里用的单路排序")]),s._v("\n            } "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* filesort_summary */")]),s._v("\n          }\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* steps */")]),s._v("\n      } "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* join_execution */")]),s._v("\n      \n      \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" max_length_for_sort_data "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--employees表所有字段长度总和肯定大于10字节")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employees "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'zhuge'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" position"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" information_schema"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("OPTIMIZER_TRACE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\ntrace排序部分结果：\n"),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"join_execution"')]),s._v(": {\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"select#"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"steps"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n          {\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"filesort_information"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n              {\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"direction"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"asc"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"table"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"`employees`"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"field"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"position"')]),s._v("\n              }\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* filesort_information */")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"filesort_priority_queue_optimization"')]),s._v(": {\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"usable"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cause"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"not applicable (no LIMIT)"')]),s._v("\n            } "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* filesort_priority_queue_optimization */")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"filesort_execution"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* filesort_execution */")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"filesort_summary"')]),s._v(": {\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"rows"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"examined_rows"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"number_of_tmp_files"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"sort_buffer_size"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("262136")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("   \n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"sort_mode"')]),s._v(": "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"<sort_key, rowid>"')]),s._v("         "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--排序方式，这里用的双路排序")]),s._v("\n            } "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* filesort_summary */")]),s._v("\n          }\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* steps */")]),s._v("\n      } "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* join_execution */")]),s._v("\n\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("session")]),s._v(" optimizer_trace"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"enabled=off"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--关闭trace")]),s._v("\n")])])]),t("p",[s._v("我们先看"),t("strong",[s._v("单路排序")]),s._v("的详细过程：")]),s._v(" "),t("ol",[t("li",[s._v("从索引name找到第一个满足 name = ‘zhuge’ 条件的主键 id")]),s._v(" "),t("li",[s._v("根据主键 id 取出整行，"),t("strong",[s._v("取出所有字段的值，存入 sort_buffer 中")])]),s._v(" "),t("li",[s._v("从索引name找到下一个满足 name = ‘zhuge’ 条件的主键 id")]),s._v(" "),t("li",[s._v("重复步骤 2、3 直到不满足 name = ‘zhuge’")]),s._v(" "),t("li",[s._v("对 sort_buffer 中的数据按照字段 position 进行排序")]),s._v(" "),t("li",[s._v("返回结果给客户端")])]),s._v(" "),t("p",[s._v("我们再看下"),t("strong",[s._v("双路排序")]),s._v("的详细过程：")]),s._v(" "),t("ol",[t("li",[s._v("从索引 name 找到第一个满足 name = ‘zhuge’  的主键id")]),s._v(" "),t("li",[s._v("根据主键 id 取出整行，"),t("strong",[s._v("把排序字段 position 和主键 id 这两个字段放到 sort buffer 中")])]),s._v(" "),t("li",[s._v("从索引 name 取下一个满足 name = ‘zhuge’  记录的主键 id")]),s._v(" "),t("li",[s._v("重复 3、4 直到不满足 name = ‘zhuge’")]),s._v(" "),t("li",[s._v("对 sort_buffer 中的字段 position 和主键 id 按照字段 position 进行排序")]),s._v(" "),t("li",[s._v("遍历排序好的 id 和字段 position，按照 id 的值"),t("strong",[s._v("回到原表")]),s._v("中取出 所有字段的值返回给客户端")])]),s._v(" "),t("p",[s._v("其实对比两个排序模式，单路排序会把所有需要查询的字段都放到 sort buffer 中，而双路排序只会把主键和需要排序的字段放到 sort buffer 中进行排序，然后再通过主键回到原表查询需要的字段。")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("如果 MySQL "),t("strong",[s._v("排序内存")]),s._v(" "),t("strong",[s._v("sort_buffer")]),s._v(" 配置的比较小并且没有条件继续增加了，可以适当把 "),t("code",[s._v("max_length_for_sort_data")]),s._v(" 配置小点，让优化器选择使用"),t("strong",[s._v("双路排序")]),s._v("算法，可以在sort_buffer 中一次排序更多的行，只是需要再根据主键回到原表取数据。")])]),s._v(" "),t("li",[t("p",[s._v("如果 MySQL 排序内存有条件可以配置比较大，可以适当增大 "),t("code",[s._v("max_length_for_sort_data")]),s._v(" 的值，让优化器优先选择全字段排序("),t("strong",[s._v("单路排序")]),s._v(")，把需要的字段放到 sort_buffer 中，这样排序后就会直接从内存里返回查询结果了。")])])]),s._v(" "),t("p",[s._v("所以，MySQL通过 "),t("strong",[s._v("max_length_for_sort_data")]),s._v(" 这个参数来控制排序，在不同场景使用不同的排序模式，从而提升排序效率。")]),s._v(" "),t("blockquote",[t("p",[s._v("如果全部使用sort_buffer内存排序一般情况下效率会高于磁盘文件排序，但不能因为这个就随便增大sort_buffer(默认1M)，mysql很多参数设置都是做过优化的，不要轻易调整。")])]),s._v(" "),t("h3",{attrs:{id:"慢查询"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#慢查询"}},[s._v("#")]),s._v(" 慢查询")]),s._v(" "),t("p",[s._v("MySQL的慢查询，全名是"),t("strong",[s._v("慢查询日志")]),s._v("，是MySQL提供的一种日志记录，用来记录在MySQL中"),t("strong",[s._v("响应时间超过阀值")]),s._v("的语句。")]),s._v(" "),t("p",[s._v("具体环境中，运行时间超过"),t("code",[s._v("long_query_time")]),s._v("值的SQL语句，则会被记录到慢查询日志中。")]),s._v(" "),t("p",[t("code",[s._v("long_query_time")]),s._v("的默认值为10，意思是记录运行10秒以上的语句。")]),s._v(" "),t("p",[s._v("默认情况下，MySQL数据库并不启动慢查询日志，需要手动来设置这个参数。")]),s._v(" "),t("p",[s._v("当然，"),t("strong",[s._v("如果不是调优需要的话，一般不建议启动该参数")]),s._v("，因为开启慢查询日志会或多或少带来一定的性能影响。")]),s._v(" "),t("p",[s._v("慢查询日志支持将日志记录写入文件和数据库表。")]),s._v(" "),t("p",[t("strong",[s._v("慢查询的相关参数")])]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("参数名")]),s._v(" "),t("th",[s._v("描述")]),s._v(" "),t("th",[s._v("取值范围")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("slow_query_log")]),s._v(" "),t("td",[s._v("是否开启慢查询日志")]),s._v(" "),t("td",[s._v("1: 开启, 0: 关闭")])]),s._v(" "),t("tr",[t("td",[s._v("log-slow-queries")]),s._v(" "),t("td",[s._v("旧版MySQL数据库慢查询日志存储路径")]),s._v(" "),t("td",[s._v("字符串")])]),s._v(" "),t("tr",[t("td",[s._v("slow-query-log-file")]),s._v(" "),t("td",[s._v("新版MySQL数据库慢查询日志存储路径")]),s._v(" "),t("td",[s._v("字符串")])]),s._v(" "),t("tr",[t("td",[s._v("long_query_time")]),s._v(" "),t("td",[s._v("慢查询阈值")]),s._v(" "),t("td",[s._v("正整数")])]),s._v(" "),t("tr",[t("td",[s._v("log_queries_not_using_indexes")]),s._v(" "),t("td",[s._v("是否记录未使用索引的查询到慢查询日志中")]),s._v(" "),t("td",[s._v("1: 记录, 0: 不记录")])]),s._v(" "),t("tr",[t("td",[s._v("log_output")]),s._v(" "),t("td",[s._v("日志存储方式")]),s._v(" "),t("td",[s._v("'FILE': 存入文件, 'TABLE': 存入数据库")])])])]),s._v(" "),t("p",[t("strong",[s._v("配置示例")])]),s._v(" "),t("p",[s._v("默认情况下"),t("code",[s._v("slow_query_log")]),s._v("的值为OFF，表示慢查询日志是禁用的，可以通过设置"),t("code",[s._v("slow_query_log")]),s._v("的值来开启，如下所示：")]),s._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("show variables  like "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'%slow_query_log%'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n +---------------------+-----------------------------------------------+\n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" Variable_name       "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" Value                                         "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n +---------------------+-----------------------------------------------+\n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" slow_query_log      "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" OFF                                           "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" slow_query_log_file "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" /home/WDPM/MysqlData/mysql/DB-Server-slow.log "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n +---------------------+-----------------------------------------------+\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" rows "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.00")]),s._v(" sec"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" global "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("slow_query_log")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\nQuery OK, "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" rows affected "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.09")]),s._v(" sec"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),t("p",[s._v("使用"),t("code",[s._v("set global slow_query_log=1")]),s._v("开启了慢查询日志只对当前数据库生效，MySQL重启后则会失效。如果要永久生效，就必须修改配置文件"),t("code",[s._v("my.cnf")]),s._v("（其它系统变量也是如此）。")]),s._v(" "),t("p",[t("code",[s._v("my.cnf")]),s._v("要增加或修改参数"),t("code",[s._v("slow_query_log")]),s._v(" 和"),t("code",[s._v("slow_query_log_file")]),s._v("，然后重启MySQL服务器，如下所示")]),s._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("slow_query_log")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("slow_query_log_file")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("/tmp/mysql_slow.log\n"),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("long_query_time")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("log_output")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("FILE \t"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 将日志存入文件")]),s._v("\n")])])]),t("p",[s._v("设置慢查询阈值")]),s._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("show variables like "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'long_query_time%'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n +-----------------+-----------+\n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" Variable_name   "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" Value     "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n +-----------------+-----------+\n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" long_query_time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.000000")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n +-----------------+-----------+\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" row "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.00")]),s._v(" sec"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" global "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("long_query_time")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n Query OK, "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" rows affected "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.00")]),s._v(" sec"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \nshow variables like "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'long_query_time'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n +-----------------+-----------+\n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" Variable_name   "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" Value     "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n +-----------------+-----------+\n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" long_query_time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.000000")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n +-----------------+-----------+\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" row "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.00")]),s._v(" sec"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),t("h3",{attrs:{id:"索引合并"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#索引合并"}},[s._v("#")]),s._v(" 索引合并")]),s._v(" "),t("p",[s._v("MySQL在一般情况下执行一个查询时最多只会用到单个二级索引，但存在有特殊情况，在这些特殊情况下也可能在一个查询中使用到多个二级索引，MySQL中这种使用到多个索引来完成一次查询的执行方法称之为：索引合并（"),t("code",[s._v("index merge")]),s._v("）")]),s._v(" "),t("h4",{attrs:{id:"intersection合并"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#intersection合并"}},[s._v("#")]),s._v(" Intersection合并")]),s._v(" "),t("p",[s._v("交集合并：某个查询可以使用多个二级索引，将从多个二级索引中查询到的结果取交集，比方说下边这个查询：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" order_exp "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" order_no "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" expire_time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[s._v("假设这个查询使用"),t("code",[s._v("Intersection")]),s._v("合并的方式执行的话，那这个过程就是这样的：")]),s._v(" "),t("ol",[t("li",[s._v("从"),t("code",[s._v("idx_order_no")]),s._v("二级索引对应的B+树中取出"),t("code",[s._v("order_no= 'a'")]),s._v("的相关记录。")]),s._v(" "),t("li",[s._v("从"),t("code",[s._v("idx_insert_time")]),s._v("二级索引对应的B+树中取出"),t("code",[s._v("insert_time= 'b'")]),s._v("的相关记录。")]),s._v(" "),t("li",[s._v("二级索引的记录都是由"),t("strong",[s._v("索引列 + 主键")]),s._v("构成的，所以可以计算出这两个结果集中id值的"),t("strong",[s._v("交集")]),s._v("。 按照上面步骤取到的id值列表进行回表操作，也就是从聚簇索引中把指定id值的完整用户记录取出来，返回给用户。")])]),s._v(" "),t("p",[s._v("为啥不直接使用"),t("code",[s._v("idx_order_no")]),s._v("或者"),t("code",[s._v("idx_insert_time")]),s._v("只根据某个搜索条件去读取一个二级索引，然后回表后再过滤另外一个搜索条件呢？这里要分析一下两种查询执行方式之间需要的成本代价。")]),s._v(" "),t("ul",[t("li",[s._v("只读取一个二级索引的成本： 按照某个搜索条件读取一个二级索引，根据从该二级索引得到的主键值进行回表操作，然后再过滤其他的搜索条件。")]),s._v(" "),t("li",[s._v("读取多个二级索引之后取交集成本： 按照不同的搜索条件分别读取不同的二级索引，将从多个二级索引得到的主键值取交集， 然后进行回表操作。")])]),s._v(" "),t("p",[s._v("虽然读取多个二级索引比读取一个二级索引消耗性能，但是大部分情况下读取二级索引的操作是"),t("strong",[s._v("顺序I/O")]),s._v("，而回表操作是"),t("strong",[s._v("随机I/O")]),s._v("，所以如果只读取一个二级索引时需要回表的记录数特别多，而读取多个二级索引之后取交集的记录数非常少，当节省的因为回表而造成的性能损耗比访问多个二级索引带来的性能损耗更高时，读取多个二级索引后取交集比只读 取一个二级索引的成本更低。")]),s._v(" "),t("p",[s._v("MySQL在某些特定的情况下才可能会使用到"),t("code",[s._v("Intersection")]),s._v("索引合并")]),s._v(" "),t("ol",[t("li",[s._v("等值匹配")])]),s._v(" "),t("p",[s._v("二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只匹配部分列的情况。 而下边这两个查询就不能进行"),t("code",[s._v("Intersection")]),s._v("索引合并：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" order_exp "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" order_no"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" insert_time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" order_status "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" expire_time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" order_exp "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" order_no "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" insert_time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[s._v("第一个查询是因为对"),t("code",[s._v("order_no")]),s._v("进行了范围匹配")]),s._v(" "),t("p",[s._v("第二个查询是因为联合索引"),t("code",[s._v("u_idx_day_status")]),s._v("中的"),t("code",[s._v("order_status和expire_time")]),s._v("列并没有出现在搜索条件中，所以这两个查询不能进行Intersection索引合并。")]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[s._v("主键列可以是范围匹配")])]),s._v(" "),t("p",[s._v("比方说下边这个查询可能用到主键和"),t("code",[s._v("u_idx_day_status")]),s._v("进行"),t("code",[s._v("Intersection")]),s._v("索引合并的操作：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" order_exp "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" insert_time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("blockquote",[t("p",[s._v("之所以在二级索引列都是等值匹配的情况下才可能使用"),t("code",[s._v("Intersection")]),s._v("索引合并，是因为只有在这种情况下根据二级索引查询出的结果集是按照主键值排序的。")])]),s._v(" "),t("p",[t("code",[s._v("Intersection")]),s._v("索引合并会把从多个二级索引中查询出的主键值求交集，如果从各个二级索引中查询的到的结果集本身就是已经按照主键排好序的，那么求交集的过程就很容易。")]),s._v(" "),t("p",[s._v("按照有序的主键值去回表取记录有个专有名词，叫："),t("code",[s._v("Rowid Ordered Retrieval")]),s._v("，简称"),t("code",[s._v("ROR")]),s._v("。")]),s._v(" "),t("blockquote",[t("p",[s._v("联合索引可以替代"),t("code",[s._v("Intersection")]),s._v("索引合并")])]),s._v(" "),t("h4",{attrs:{id:"union合并"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#union合并"}},[s._v("#")]),s._v(" Union合并")]),s._v(" "),t("p",[s._v("在写查询语句时经常想把既符合某个搜索条件的记录取出来，也把符合另外的某个搜索条件的记录取出来，这些不同的搜索条件之间是OR关系。有时候OR关系的不同搜索条件会使用到不同的索引，比方说这样：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" order_exp "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" order_no "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("OR")]),s._v(" expire_time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),s._v("\n")])])]),t("p",[t("code",[s._v("Intersection")]),s._v("是交集的意思，这适用于使用不同索引的搜索条件之间使用"),t("code",[s._v("AND")]),s._v("连接起来的 情况；"),t("code",[s._v("Union")]),s._v("是并集的意思，适用于使用不同索引的搜索条件之间使用"),t("code",[s._v("OR")]),s._v("连接起来的情 况。与"),t("code",[s._v("Intersection")]),s._v("索引合并类似，MySQL在某些特定的情况下才可能会使用到"),t("code",[s._v("Union")]),s._v("索引合并。")]),s._v(" "),t("p",[s._v("等值匹配、主键列可以是范围匹配与"),t("code",[s._v("Intersection")]),s._v("分析类似")]),s._v(" "),t("p",[t("strong",[s._v("使用"),t("code",[s._v("Intersection")]),s._v("索引合并的搜索条件")])]),s._v(" "),t("p",[s._v("就是搜索条件的某些部分使用"),t("code",[s._v("Intersection")]),s._v("索引合并的方式得到的主键集合和其他方式得到的主键集合取交集，比方说这个查询：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" order_exp "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" insert_time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" order_status "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" expire_time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("OR")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("order_no "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("AND")]),s._v(" expire_time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[s._v("优化器可能采用这样的方式来执行这个查询：")]),s._v(" "),t("ol",[t("li",[s._v("先按照搜索条件"),t("code",[s._v("order_no = 'a' AND expire_time = 'b'")]),s._v("从索引"),t("code",[s._v("idx_order_no和 idx_expire_time")]),s._v("中使用"),t("code",[s._v("Intersection")]),s._v("索引合并的方式得到一个主键集合。")]),s._v(" "),t("li",[s._v("再按照搜索条件 "),t("code",[s._v("insert_time = 'a' AND order_status = 'b' AND expire_time = 'c'")]),s._v("从联合索引"),t("code",[s._v("u_idx_day_status")]),s._v("中得到另一个主键集合。")]),s._v(" "),t("li",[s._v("最后采用"),t("code",[s._v("Union")]),s._v("索引合并的方式把上述两个主键集合取并集，然后进行回表操作，将结果返回给用户。")])]),s._v(" "),t("blockquote",[t("p",[s._v("查询条件符合了这些情况也不一定就会采用"),t("code",[s._v("Intersection、Union")]),s._v("索引合并。")]),s._v(" "),t("p",[s._v("优化器只有在单独根据搜索条件从某个二级索引中获取的记录数比较少，通过"),t("code",[s._v("Intersection、Union")]),s._v(" 索引合并后进行访问的代价比全表扫描更小时才会使用"),t("code",[s._v("Intersection、Union")]),s._v("索引合并")])]),s._v(" "),t("h4",{attrs:{id:"sort-union合并"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#sort-union合并"}},[s._v("#")]),s._v(" Sort-Union合并")]),s._v(" "),t("p",[t("code",[s._v("Union")]),s._v("索引合并的使用条件太苛刻，必须保证各个二级索引列在进行等值匹配的条件下才可能被用到，比方说下边这个查询就无法使用到"),t("code",[s._v("Union")]),s._v("索引合并：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" order_exp "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHERE")]),s._v(" order_no"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("OR")]),s._v(" expire_time"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'z'")]),s._v("\n")])])]),t("p",[s._v("这是因为根据"),t("code",[s._v("order_no< 'a'")]),s._v("从"),t("code",[s._v("idx_order_no")]),s._v("索引中获取的二级索引记录的主键值不是排好序的，根据"),t("code",[s._v("expire_time> 'z'")]),s._v("从"),t("code",[s._v("idx_expire_time")]),s._v("索引中获取的二级索引记录的主键值也不是排好序的，但是"),t("code",[s._v("order_no< 'a'")]),s._v("和"),t("code",[s._v("expire_time> 'z'")]),s._v("这两个条件又特别让我们动心。所以我们可以这样做：")]),s._v(" "),t("ol",[t("li",[s._v("先根据"),t("code",[s._v("order_no< 'a'")]),s._v("条件从"),t("code",[s._v("idx_order_no")]),s._v("二级索引中获取记录，并按照记录的主键值进行排序")]),s._v(" "),t("li",[s._v("再根据"),t("code",[s._v("expire_time> 'z'")]),s._v("条件从"),t("code",[s._v("idx_expire_time")]),s._v("二级索引中获取记录，并按照记录的主键值进行排序，因为上述的两个二级索引主键值都是排好序的，剩下的操作和"),t("code",[s._v("Union")]),s._v("索引合并方式就一样 了。")])]),s._v(" "),t("p",[s._v("上述这种"),t("strong",[s._v("先按照二级索引记录的主键值进行排序，之后按照"),t("code",[s._v("Union")]),s._v("索引合并方式执行")]),s._v("称之为"),t("code",[s._v("Sort-Union")]),s._v("索引合并，很显然，这种"),t("code",[s._v("Sort-Union")]),s._v("索引合并比单纯的"),t("code",[s._v("Union")]),s._v("索引合并多了一步对"),t("strong",[s._v("二级索引记录的主键值排序")]),s._v("的过程。")]),s._v(" "),t("h3",{attrs:{id:"索引设计原则"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#索引设计原则"}},[s._v("#")]),s._v(" 索引设计原则")]),s._v(" "),t("p",[t("strong",[s._v("1、代码先行，索引后上")])]),s._v(" "),t("p",[s._v("不知大家一般是怎么给数据表建立索引的，是建完表马上就建立索引吗？")]),s._v(" "),t("p",[s._v("这其实是不对的，一般应该等到主体业务功能开发完毕，把涉及到该表相关sql都要拿出来分析之后再建立索引。")]),s._v(" "),t("p",[t("strong",[s._v("2、联合索引尽量覆盖条件")])]),s._v(" "),t("p",[s._v("比如可以设计一个或者两三个联合索引(尽量少建单值索引)，让每一个联合索引都尽量去包含sql语句里的where、order by、group by的字段，还要确保这些联合索引的字段顺序尽量满足sql查询的最左前缀原则。")]),s._v(" "),t("p",[t("strong",[s._v("3、不要在小基数字段上建立索引")])]),s._v(" "),t("p",[s._v("索引基数是指这个字段在表里总共有多少个不同的值，比如一张表总共100万行记录，其中有个性别字段，其值不是男就是女，那么该字段的基数就是2。")]),s._v(" "),t("p",[s._v("如果对这种小基数字段建立索引的话，还不如全表扫描了，因为你的索引树里就包含男和女两种值，根本没法进行快速的二分查找，那用索引就没有太大的意义了。")]),s._v(" "),t("p",[s._v("一般建立索引，尽量使用那些基数比较大的字段，就是值比较多的字段，那么才能发挥出B+树快速二分查找的优势来。")]),s._v(" "),t("p",[t("strong",[s._v("4、长字符串可以采用前缀索引")])]),s._v(" "),t("p",[s._v("尽量对字段类型较小的列设计索引，比如说什么tinyint之类的，因为字段类型较小的话，占用磁盘空间也会比较小，此时你在搜索的时候性能也会比较好一点。")]),s._v(" "),t("p",[s._v("当然，这个所谓的字段类型小一点的列，也不是绝对的，很多时候你就是要针对varchar(255)这种字段建立索引，哪怕多占用一些磁盘空间也是有必要的。")]),s._v(" "),t("p",[s._v("对于这种varchar(255)的大字段可能会比较占用磁盘空间，可以稍微优化下，比如针对这个字段的前20个字符建立索引，就是说，对这个字段里的每个值的前20个字符放在索引树里，类似于 KEY index(name(20),age,position)。")]),s._v(" "),t("p",[s._v("此时你在where条件里搜索的时候，如果是根据name字段来搜索，那么此时就会先到索引树里根据name字段的前20个字符去搜索，定位到之后前20个字符的前缀匹配的部分数据之后，再回到聚簇索引提取出来完整的name字段值进行比对。")]),s._v(" "),t("p",[s._v("但是假如你要是order by name，那么此时你的name因为在索引树里仅仅包含了前20个字符，所以这个排序是没法用上索引的， group by也是同理。所以这里大家要对前缀索引有一个了解。")]),s._v(" "),t("p",[t("strong",[s._v("5、where与order by冲突时优先where")])]),s._v(" "),t("p",[s._v("在where和order by出现索引设计冲突时，到底是针对where去设计索引，还是针对order by设计索引？到底是让where去用上索引，还是让order by用上索引?")]),s._v(" "),t("p",[s._v("一般这种时候往往都是让where条件去使用索引来快速筛选出来一部分指定的数据，接着再进行排序。")]),s._v(" "),t("p",[s._v("因为大多数情况基于索引进行where筛选往往可以最快速度筛选出你要的少部分数据，然后做排序的成本可能会小很多。")]),s._v(" "),t("h3",{attrs:{id:"索引设计实战"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#索引设计实战"}},[s._v("#")]),s._v(" 索引设计实战")]),s._v(" "),t("p",[s._v("以社交场景APP来举例，我们一般会去搜索一些好友，这里面就涉及到对用户信息的筛选，这里肯定就是对用户user表搜索了，这个表一般来说数据量会比较大，我们先不考虑分库分表的情况，比如，我们一般会筛选地区(省市)，性别，年龄，身高，爱好之类的，有的APP可能用户还有评分，比如用户的受欢迎程度评分，我们可能还会根据评分来排序等等。")]),s._v(" "),t("p",[s._v("对于后台程序来说除了过滤用户的各种条件，还需要分页之类的处理，可能会生成类似sql语句执行：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" xx "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("user")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" xx"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("xx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" xx"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("xx "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" xx "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" xx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("xx\n")])])]),t("p",[s._v("对于这种情况如何合理设计索引了，比如"),t("strong",[s._v("用户可能经常会根据省市优先筛选同城的用户，还有根据性别去筛选")]),s._v("，那我们是否应该设计一个联合索引"),t("code",[s._v("(province,city,sex)")]),s._v("了？这些字段好像基数都不大，其实是应该的，因为这些字段查询太频繁了。")]),s._v(" "),t("p",[s._v("假设"),t("strong",[s._v("又有用户根据年龄范围去筛选")]),s._v("了，比如 ：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" xx "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("user")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" province"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("xx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" city"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("xx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" age"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v("xx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" age"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),s._v("xx\n")])])]),t("p",[s._v("我们尝试着把age字段加入联合索引"),t("code",[s._v("(province,city,sex,age)")]),s._v("，注意，一般这种范围查找的条件都要放在最后，之前讲过联合索引范围之后条件的是不能用索引的，但是对于当前这种情况依然用不到age这个索引字段，因为"),t("strong",[s._v("用户没有筛选sex字段")]),s._v("，那怎么优化了？其实我们可以这么来优化下sql的写法：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" xx "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("user")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" province"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("xx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" city"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("xx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" sex "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'female'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'male'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" age"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v("xx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" age"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),s._v("xx\n")])])]),t("p",[t("strong",[s._v("对于爱好之类的字段也可以类似sex字段处理")]),s._v("，所以可以把爱好字段也加入索引 "),t("code",[s._v("(province,city,sex,hobby,age)")])]),s._v(" "),t("p",[s._v("假设可能还有一个筛选条件，比如"),t("strong",[s._v("要筛选最近一周登录过的用户")]),s._v("，一般大家肯定希望跟活跃用户交友了，这样能尽快收到反馈，对应后台sql可能是这样：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" xx "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("user")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v("  province"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("xx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" city"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("xx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" sex "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'female'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'male'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" age"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v("xx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" age"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),s._v("xx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" latest_login_time"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v(" xx\n")])])]),t("p",[s._v("那我们是否能把 latest_login_time 字段也加入索引了？比如"),t("code",[s._v("(province,city,sex,hobby,age,latest_login_time)")]),s._v("，显然是不行的，那怎么来优化这种情况了？其实我们可以试着再设计一个字段"),t("code",[s._v("is_login_in_latest_7_days")]),s._v("，用户如果一周内有登录值就为1，否则为0，那么我们就可以把索引设计成"),t("code",[s._v("(province,city,sex,hobby,is_login_in_latest_7_days,age)")]),s._v("  来满足上面那种场景了！")]),s._v(" "),t("p",[s._v("一般来说，通过这么一个多字段的索引是能够过滤掉绝大部分数据的，就保留小部分数据下来基于磁盘文件进行"),t("code",[s._v("order by")]),s._v("语句的排序，最后基于limit进行分页，那么一般性能还是比较高的。")]),s._v(" "),t("p",[s._v("不过有时可能用户会这么来查询，就"),t("strong",[s._v("查下受欢迎度较高的女性")]),s._v("，比如sql：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" xx "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("user")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" sex "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'female'")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" score "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" xx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("xx\n")])])]),t("p",[s._v("那么上面那个索引是很难用上的，不能把太多的字段以及太多的值都用 in 语句拼接到sql里的，那怎么办了？其实我们可以再设计一个辅助的联合索引，比如 (sex,score)，这样就能满足查询要求了。")]),s._v(" "),t("p",[s._v("以上就是给大家讲的一些索引设计的思路了，核心思想就是，尽量利用一两个复杂的多字段联合索引，抗下你80%以上的查询，然后用一两个辅助索引尽量抗下剩余的一些非典型查询，保证这种大数据量表的查询尽可能多的都能充分利用索引，这样就能保证你的查询速度和性能了！")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/127322-17056503928981.png",alt:"img"}})]),s._v(" "),t("h2",{attrs:{id:"mysql事务与锁机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mysql事务与锁机制"}},[s._v("#")]),s._v(" MySQL事务与锁机制")]),s._v(" "),t("h3",{attrs:{id:"事务"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#事务"}},[s._v("#")]),s._v(" 事务")]),s._v(" "),t("p",[t("strong",[s._v("概述")])]),s._v(" "),t("p",[s._v("数据库一般都会并发执行多个事务，多个事务可能会并发的对相同的一批数据进行增删改查操作，可能就会导致脏写、脏读、不可重复读、幻读这些问题。")]),s._v(" "),t("p",[s._v("这些问题的本质都是数据库的多事务并发问题，为了解决多事务并发问题，数据库设计了"),t("strong",[s._v("事务隔离机制、锁机制、MVCC多版本并发控制隔离机制")]),s._v("，用一整套机制来"),t("strong",[s._v("解决多事务并发问题")]),s._v("。")]),s._v(" "),t("h4",{attrs:{id:"acid属性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#acid属性"}},[s._v("#")]),s._v(" ACID属性")]),s._v(" "),t("p",[s._v("事务是由一组SQL语句组成的逻辑处理单元,事务具有以下4个属性,通常简称为事务的ACID属性。")]),s._v(" "),t("ul",[t("li",[s._v("原子性(Atomicity) ：事务是一个原子操作单元,其对数据的修改,要么全都执行，要么全都不执行。")]),s._v(" "),t("li",[s._v("一致性(Consistent) ：在事务开始和完成时,数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以保持数据的完整性。")]),s._v(" "),t("li",[s._v("隔离性(Isolation) ：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的，反之亦然。")]),s._v(" "),t("li",[s._v("持久性(Durable) ：事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。")])]),s._v(" "),t("h4",{attrs:{id:"并发事务的问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#并发事务的问题"}},[s._v("#")]),s._v(" 并发事务的问题")]),s._v(" "),t("ol",[t("li",[t("strong",[s._v("更新丢失(Lost Update)或脏写")])])]),s._v(" "),t("p",[s._v("当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题–"),t("strong",[s._v("最后的更新覆盖了由其他事务所做的更新")]),s._v("。")]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[t("strong",[s._v("脏读（Dirty Reads）")])])]),s._v(" "),t("p",[s._v("一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致的状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”数据，并据此作进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象的叫做“脏读”。")]),s._v(" "),t("blockquote",[t("p",[t("strong",[s._v("事务A读取到了事务B已经修改但尚未提交的数据")]),s._v("，还在这个数据基础上做了操作。此时，如果B事务回滚，A读取的数据无效，不符合一致性要求。")])]),s._v(" "),t("ol",{attrs:{start:"3"}},[t("li",[t("strong",[s._v("不可重读（"),t("code",[s._v("Non-Repeatable Reads")]),s._v("）")])])]),s._v(" "),t("p",[s._v("一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了！这种现象就叫做“不可重复读”。")]),s._v(" "),t("blockquote",[t("p",[t("strong",[s._v("事务A内部的相同查询语句在不同时刻读出的结果不一致，不符合隔离性")])])]),s._v(" "),t("ol",{attrs:{start:"4"}},[t("li",[t("strong",[s._v("幻读（Phantom Reads）")])])]),s._v(" "),t("p",[s._v("一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。")]),s._v(" "),t("blockquote",[t("p",[t("strong",[s._v("事务A读取到了事务B提交的新增数据，不符合隔离性")])])]),s._v(" "),t("h4",{attrs:{id:"事务隔离级别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#事务隔离级别"}},[s._v("#")]),s._v(" 事务隔离级别")]),s._v(" "),t("p",[s._v("“脏读”、“不可重复读”和“幻读”，其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决。")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("隔离级别")]),s._v(" "),t("th",[s._v("脏读(Dirty Read)")]),s._v(" "),t("th",[s._v("不可重复读(NonRepeatable Read)")]),s._v(" "),t("th",[s._v("幻读(Phantom Read)")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("读未提交(Read uncommitted)")]),s._v(" "),t("td",[s._v("可能")]),s._v(" "),t("td",[s._v("可能")]),s._v(" "),t("td",[s._v("可能")])]),s._v(" "),t("tr",[t("td",[s._v("读已提交(Read committed)")]),s._v(" "),t("td",[s._v("不可能")]),s._v(" "),t("td",[s._v("可能")]),s._v(" "),t("td",[s._v("可能")])]),s._v(" "),t("tr",[t("td",[s._v("可重复读(Repeatableread)")]),s._v(" "),t("td",[s._v("不可能")]),s._v(" "),t("td",[s._v("不可能")]),s._v(" "),t("td",[s._v("可能")])]),s._v(" "),t("tr",[t("td",[s._v("可串行化(Serializable)")]),s._v(" "),t("td",[s._v("不可能")]),s._v(" "),t("td",[s._v("不可能")]),s._v(" "),t("td",[s._v("不可能")])])])]),s._v(" "),t("blockquote",[t("p",[s._v("数据库的事务隔离越严格，并发副作用越小，但付出的代价也就越大，因为事务隔离实质上就是使事务在一定程度上"),t("strong",[s._v("串行化")]),s._v("进行，这显然与“并发”是矛盾的。")]),s._v(" "),t("p",[s._v('同时，不同的应用对读一致性和事务隔离程度的要求也是不同的，比如许多应用对“不可重复读"和“幻读”并不敏感，可能更关心数据并发访问的能力。')])]),s._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 查看看当前数据库的事务隔离级别")]),s._v("\nshow variables like "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'tx_isolation'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 设置事务隔离级别")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("tx_isolation")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'REPEATABLE-READ'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("blockquote",[t("p",[s._v("MySQL默认的事务隔离级别是可重复读，用Spring开发程序时，如果不设置隔离级别默认用Mysql设置的隔离级别，如果Spring设置了就用已经设置的隔离级别")])]),s._v(" "),t("h3",{attrs:{id:"锁"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#锁"}},[s._v("#")]),s._v(" 锁")]),s._v(" "),t("p",[s._v("锁是计算机协调多个进程或线程并发访问某一资源的机制。")]),s._v(" "),t("p",[s._v("在数据库中，除了传统的计算资源（如CPU、RAM、I/O等）的争用以外，数据也是一种供需要用户共享的资源。如何保证数据并发访问的一致性、有效性是所有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。")]),s._v(" "),t("h4",{attrs:{id:"锁分类"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#锁分类"}},[s._v("#")]),s._v(" 锁分类")]),s._v(" "),t("p",[s._v("锁分类：")]),s._v(" "),t("ul",[t("li",[s._v("从性能上分为乐观锁(用版本对比来实现)和悲观锁")]),s._v(" "),t("li",[s._v("从对数据操作的粒度分，分为表锁和行锁")]),s._v(" "),t("li",[s._v("从对数据库操作的类型分，分为读锁和写锁(都属于悲观锁)，还有意向锁")])]),s._v(" "),t("p",[t("strong",[s._v("读锁")]),s._v("（共享锁，S锁("),t("code",[s._v("Shared")]),s._v(")）：针对同一份数据，多个读操作可以同时进行而不会互相影响，比如：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" T "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("lock")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("share")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("mode")]),s._v("\n")])])]),t("p",[t("strong",[s._v("写锁")]),s._v("（排它锁，X锁("),t("code",[s._v("Exclusive")]),s._v(")）：当前写操作没有完成前，它会阻断其他写锁和读锁，数据修改操作都会加写锁，查询也可以通过"),t("code",[s._v("for update")]),s._v("加写锁，比如：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" T "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("update")]),s._v("\n")])])]),t("p",[t("strong",[s._v("意向锁")]),s._v("（"),t("code",[s._v("Intention Lock")]),s._v("）：又称I锁，针对表锁，主要是为了提高加表锁的效率，是mysql数据库自己加的。当有事务给表的数据行加了共享锁或排他锁，同时会给表设置一个标识，代表已经有行锁了，其他事务要想对表加表锁时，就不必逐行判断有没有行锁可能跟表锁冲突了，直接读这个标识就可以确定自己该不该加表锁。特别是表中的记录很多时，逐行判断加表锁的方式效率很低。而这个标识就是意向锁。")]),s._v(" "),t("p",[s._v("意向锁主要分为：")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("意向共享锁，IS锁，对整个表加共享锁之前，需要先获取到意向共享锁。")])]),s._v(" "),t("li",[t("p",[s._v("意向排他锁，IX锁，对整个表加排他锁之前，需要先获取到意向排他锁。")])])]),s._v(" "),t("h4",{attrs:{id:"表锁"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#表锁"}},[s._v("#")]),s._v(" 表锁")]),s._v(" "),t("p",[s._v("每次操作锁住整张表。开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低；一般用在整表数据迁移的场景。")]),s._v(" "),t("p",[t("strong",[s._v("基本操作")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 建表SQL")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("mylock"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("NAME"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VARCHAR")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ENGINE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" MyISAM "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHARSET")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" utf8"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 插入数据")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("mylock"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("NAME"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'1'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("mylock"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("NAME"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("mylock"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("NAME"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'3'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("mylock"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("NAME"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'4'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'d'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 手动增加表锁")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("lock")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" 表名称 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("read")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("write")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("表名称"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("read")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("write")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 查看表上加过的锁")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("show")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("open")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("tables")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 删除表锁")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("unlock")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("tables")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("strong",[s._v("案例分析(加读锁）")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98805-17057216865341.png",alt:"img"}})]),s._v(" "),t("p",[s._v("当前session和其他session都可以读该表，当前session中插入或者更新锁定的表都会报错，其他session插入或更新则会等待。")]),s._v(" "),t("p",[t("strong",[s._v("案例分析(加写锁）")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98803.png",alt:"0"}})]),s._v(" "),t("p",[s._v("当前session对该表的增删改查都没有问题，其他session对该表的所有操作被阻塞")]),s._v(" "),t("p",[t("strong",[s._v("案例结论")])]),s._v(" "),t("ol",[t("li",[t("p",[s._v("对MyISAM表的读操作(加读锁) ，不会阻塞其他进程对同一表的读请求，但会阻塞对同一表的写请求。只有当读锁释放后，才会执行其它进程的写操作。")])]),s._v(" "),t("li",[t("p",[s._v("对MylSAM表的写操作(加写锁)，会阻塞其他进程对同一表的读和写操作，只有当写锁释放后，才会执行其它进程的读写操作。")])])]),s._v(" "),t("h4",{attrs:{id:"行锁"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#行锁"}},[s._v("#")]),s._v(" 行锁")]),s._v(" "),t("p",[s._v("每次操作锁住一行数据。开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度最高。")]),s._v(" "),t("p",[s._v("InnoDB与MYISAM的最大不同有两点：")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("InnoDB支持事务（TRANSACTION）")])]),s._v(" "),t("li",[t("strong",[s._v("InnoDB支持行级锁")])])]),s._v(" "),t("p",[t("strong",[s._v("行锁演示")])]),s._v(" "),t("p",[s._v("一个session开启事务更新不提交，另一个session更新同一条记录会阻塞，更新不同记录不会阻塞")]),s._v(" "),t("p",[t("strong",[s._v("总结")]),s._v("：")]),s._v(" "),t("p",[s._v("InnoDB在执行查询语句"),t("code",[s._v("SELECT")]),s._v("时(非串行隔离级别)，不会加锁。但是"),t("code",[s._v("update、insert、delete")]),s._v("操作会加行锁。")]),s._v(" "),t("blockquote",[t("p",[t("strong",[s._v("读锁会阻塞写，但是不会阻塞读。而写锁则会把读和写都阻塞")]),s._v("。")])]),s._v(" "),t("h4",{attrs:{id:"行锁与事务隔离级别案例"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#行锁与事务隔离级别案例"}},[s._v("#")]),s._v(" 行锁与事务隔离级别案例")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("account"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AUTO_INCREMENT")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("255")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("balance"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PRIMARY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("KEY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ENGINE")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("InnoDB")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DEFAULT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHARSET")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("utf8"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("account"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("balance"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'lilei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'450'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("account"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("balance"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'hanmei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'16000'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INSERT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("account"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("balance"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'lucy'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2400'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("h5",{attrs:{id:"读未提交"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#读未提交"}},[s._v("#")]),s._v(" 读未提交")]),s._v(" "),t("ol",[t("li",[s._v("打开一个客户端A，并设置当前事务模式为"),t("code",[s._v("read uncommitted")]),s._v("（未提交读），查询表account的初始值：")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" tx_isolation"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'read-uncommitted'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("              \n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98804.png",alt:"0"}})]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[s._v("在客户端A的事务提交之前，打开另一个客户端B，更新表account：")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98791.png",alt:"0"}})]),s._v(" "),t("ol",{attrs:{start:"3"}},[t("li",[s._v("这时，虽然客户端B的事务还没提交，但是客户端A就可以查询到B已经更新的数据：")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98792.png",alt:"0"}})]),s._v(" "),t("ol",{attrs:{start:"4"}},[t("li",[s._v("一旦客户端B的事务因为某种原因回滚，所有的操作都将会被撤销，那客户端A查询到的数据其实就是"),t("strong",[s._v("脏数据")]),s._v("：")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98794.png",alt:"0"}})]),s._v(" "),t("ol",{attrs:{start:"5"}},[t("li",[s._v("在客户端A执行更新语句")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("update")]),s._v(" account "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" balance "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" balance "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n")])])]),t("p",[s._v("lilei的balance没有变成350，居然是400，是不是很奇怪，数据不一致啊，如果你这么想就太天真 了，在应用程序中，我们会用400-50=350，并不知道其他会话回滚了，要想解决这个问题可以采用读已提交的隔离级别")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98790.png",alt:"0"}})]),s._v(" "),t("h5",{attrs:{id:"读已提交"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#读已提交"}},[s._v("#")]),s._v(" 读已提交")]),s._v(" "),t("ol",[t("li",[s._v("打开一个客户端A，并设置当前事务模式为"),t("code",[s._v("read committed")]),s._v("（未提交读），查询表account的所有记录：")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" tx_isolation"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'read-committed'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98796.png",alt:"0"}})]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[s._v("在客户端A的事务提交之前，打开另一个客户端B，更新表account：")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98795.png",alt:"0"}})]),s._v(" "),t("ol",{attrs:{start:"3"}},[t("li",[s._v("这时，客户端B的事务还没提交，客户端A不能查询到B已经更新的数据，解决了脏读问题：")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98799.png",alt:"0"}})]),s._v(" "),t("ol",{attrs:{start:"4"}},[t("li",[s._v("客户端B的事务提交")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98797.png",alt:"0"}})]),s._v(" "),t("ol",{attrs:{start:"5"}},[t("li",[s._v("客户端A执行与上一步相同的查询，结果与上一步不一致，即产生了不可重复读的问题")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98798.png",alt:"0"}})]),s._v(" "),t("h5",{attrs:{id:"可重复读"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#可重复读"}},[s._v("#")]),s._v(" 可重复读")]),s._v(" "),t("ol",[t("li",[s._v("打开一个客户端A，并设置当前事务模式为"),t("code",[s._v("repeatable read")]),s._v("，查询表account的所有记录")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" tx_isolation"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'repeatable-read'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98800.png",alt:"0"}})]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[s._v("在客户端A的事务提交之前，打开另一个客户端B，更新表account并提交")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98789.png",alt:"0"}})]),s._v(" "),t("ol",{attrs:{start:"3"}},[t("li",[s._v("在客户端A查询表account的所有记录，与步骤1 查询结果一致，没有出现不可重复读的问题")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98793.png",alt:"0"}})]),s._v(" "),t("ol",{attrs:{start:"4"}},[t("li",[s._v("在客户端A，接着执行")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("update")]),s._v(" account "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" balance "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" balance "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n")])])]),t("p",[s._v("balance没有变成400-50=350，lilei的balance值用的是步骤2中的350来算的，所以是300，数据的一致性倒是没有被破坏。可重复读的隔离级别下使用了"),t("strong",[s._v("MVCC("),t("code",[s._v("multi-version concurrency control")]),s._v(")机制")]),s._v("，"),t("code",[s._v("select")]),s._v("操作不会更新版本号，是快照读（历史版本）；"),t("code",[s._v("insert、update、delete")]),s._v("会更新版本号，是当前读（当前版本）。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98787.png",alt:"0"}})]),s._v(" "),t("ol",{attrs:{start:"5"}},[t("li",[s._v("重新打开客户端B，插入一条新数据后提交")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98788.png",alt:"0"}})]),s._v(" "),t("ol",{attrs:{start:"6"}},[t("li",[s._v("在客户端A查询表account的所有记录，没有查出新增数据，所以没有出现幻读")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98802.png",alt:"0"}})]),s._v(" "),t("ol",{attrs:{start:"7"}},[t("li",[s._v("验证幻读")])]),s._v(" "),t("p",[s._v("在客户端A执行")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("update")]),s._v(" account "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" balance"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("888")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[s._v("能更新成功，再次查询能查到客户端B新增的数据")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98801.png",alt:"0"}})]),s._v(" "),t("h5",{attrs:{id:"串行化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#串行化"}},[s._v("#")]),s._v(" 串行化")]),s._v(" "),t("ol",[t("li",[s._v("打开一个客户端A，并设置当前事务模式为"),t("code",[s._v("serializable")]),s._v("，查询表account的初始值：")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" tx_isolation"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'serializable'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98830.png",alt:"0"}})]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[s._v("打开一个客户端B，并设置当前事务模式为"),t("code",[s._v("serializable")]),s._v("，更新相同的id为1 的记录会被阻塞等待，更新id为2的记录可以成功，说明在串行模式下"),t("code",[s._v("innodb")]),s._v("的查询也会被加上行锁。")])]),s._v(" "),t("p",[s._v("如果客户端A执行的是一个范围查询，那么该"),t("strong",[s._v("范围内的所有行包括每行记录所在的间隙区间范围")]),s._v("(就算该行数据还未被插入也会加锁，这种是间隙锁)"),t("strong",[s._v("都会被加锁")]),s._v("。此时如果客户端B在该范围内插入数据都会被阻塞，所以就避免了幻读。")]),s._v(" "),t("p",[s._v("这种隔离级别并发性极低，开发中很少会用到。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98844.png",alt:"0"}})]),s._v(" "),t("h5",{attrs:{id:"间隙锁-gap-lock"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#间隙锁-gap-lock"}},[s._v("#")]),s._v(" 间隙锁(Gap Lock)")]),s._v(" "),t("p",[s._v("间隙锁，锁的就是两个值之间的空隙。Mysql默认级别是"),t("code",[s._v("repeatable-read")]),s._v("，有办法解决幻读问题吗？间隙锁在某些情况下可以解决幻读问题。")]),s._v(" "),t("p",[s._v("假设account表里数据如下：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/98874.png",alt:"0"}})]),s._v(" "),t("p",[s._v("那么间隙就有 id 为 "),t("code",[s._v("(3,10)，(10,20)，(20,正无穷)")]),s._v(" 这三个区间，")]),s._v(" "),t("p",[s._v("在"),t("code",[s._v("Session_1")]),s._v("下面执行")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("update")]),s._v(" account "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'zhuge'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[s._v("则其他Session没法在这个"),t("strong",[s._v("范围所包含的所有行记录(包括间隙行记录)以及行记录所在的间隙")]),s._v("里插入或修改任何数据，即id在"),t("code",[s._v("(3,20]")]),s._v("区间都无法修改数据，注意最后那个20也是包含在内的。")]),s._v(" "),t("blockquote",[t("p",[s._v("间隙锁是在可重复读隔离级别下才会生效")])]),s._v(" "),t("h5",{attrs:{id:"临键锁-next-key-locks"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#临键锁-next-key-locks"}},[s._v("#")]),s._v(" 临键锁(Next-key Locks)")]),s._v(" "),t("p",[t("code",[s._v("Next-Key Locks")]),s._v("是行锁与间隙锁的组合。像上面那个例子里的这个"),t("code",[s._v("(3,20]")]),s._v("的整个区间可以叫做临键锁。")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("无索引行锁会升级为表锁(RR级别会升级为表锁，RC级别不会升级为表锁)")])]),s._v(" "),t("li",[t("p",[s._v("锁主要是加在索引上，如果对非索引字段更新，行锁可能会变表锁")])])]),s._v(" "),t("p",[t("code",[s._v("session1")]),s._v(" 执行：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("update")]),s._v(" account "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" balance "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("800")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'lilei'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[t("code",[s._v("session2")]),s._v(" 对该表任一行操作都会阻塞住")]),s._v(" "),t("p",[t("strong",[s._v("InnoDB的行锁是针对索引加的锁，不是针对记录加的锁。并且该索引不能失效，否则都会从行锁升级为表锁")]),s._v("。")]),s._v(" "),t("p",[s._v("锁定某一行还可以用"),t("code",[s._v("lock in share mode")]),s._v("(共享锁) 和"),t("code",[s._v("for update")]),s._v("(排它锁)，例如：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" test_innodb_lock "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" a "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("update")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[s._v("这样其他session只能读这行数据，修改则会被阻塞，直到锁定行的session提交")]),s._v(" "),t("p",[t("strong",[s._v("结论")])]),s._v(" "),t("p",[s._v("Innodb存储引擎由于实现了行级锁定，虽然在锁定机制的实现方面所带来的性能损耗可能比表级锁定会要更高一下，但是在整体并发处理能力方面要远远优于MYISAM的表级锁定的。当系统并发量高的时候，Innodb的整体性能和MYISAM相比就会有比较明显的优势了。")]),s._v(" "),t("p",[s._v("但是，Innodb的行级锁定同样也有其脆弱的一面，当我们使用不当的时候，可能会让Innodb的整体性能表现不仅不能比MYISAM高，甚至可能会更差。")]),s._v(" "),t("p",[t("strong",[s._v("行锁分析")])]),s._v(" "),t("p",[s._v("通过检查"),t("code",[s._v("InnoDB_row_lock")]),s._v("状态变量来分析系统上的行锁的争夺情况")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("show")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("status")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("like")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'innodb_row_lock%'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("              \n")])])]),t("p",[s._v("对各个状态量的说明如下：")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("指标")]),s._v(" "),t("th",[s._v("描述")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("★Innodb_row_lock_time")]),s._v(" "),t("td",[s._v("从系统启动到现在锁定总时间长度")])]),s._v(" "),t("tr",[t("td",[s._v("★Innodb_row_lock_time_avg")]),s._v(" "),t("td",[s._v("每次等待所花平均时间")])]),s._v(" "),t("tr",[t("td",[s._v("★Innodb_row_lock_waits")]),s._v(" "),t("td",[s._v("系统启动后到现在总共等待的次数")])]),s._v(" "),t("tr",[t("td",[s._v("Innodb_row_lock_current_waits")]),s._v(" "),t("td",[s._v("当前正在等待锁定的数量")])]),s._v(" "),t("tr",[t("td",[s._v("Innodb_row_lock_time_max")]),s._v(" "),t("td",[s._v("从系统启动到现在等待最长的一次所花时间")])])])]),s._v(" "),t("p",[s._v("对于这5个状态变量，比较重要的主要是：")]),s._v(" "),t("p",[t("code",[s._v("Innodb_row_lock_time_avg（等待平均时长）、Innodb_row_lock_waits（等待总次数）、Innodb_row_lock_time（等待总时长）")])]),s._v(" "),t("p",[s._v("尤其是当等待次数很高，而且每次等待时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化计划。")]),s._v(" "),t("p",[t("strong",[s._v("查看"),t("code",[s._v("INFORMATION_SCHEMA")]),s._v("系统库锁相关数据表")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 查看事务")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" INFORMATION_SCHEMA"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("INNODB_TRX"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 查看锁")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" INFORMATION_SCHEMA"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("INNODB_LOCKS"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 查看锁等待")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" INFORMATION_SCHEMA"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("INNODB_LOCK_WAITS"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 释放锁，trx_mysql_thread_id可以从INNODB_TRX表里查看到")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("kill")]),s._v(" trx_mysql_thread_id\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 查看锁等待详细信息")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("show")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("engine")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("innodb")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("status")]),s._v("\\G"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n")])])]),t("h4",{attrs:{id:"死锁"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#死锁"}},[s._v("#")]),s._v(" 死锁")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("set")]),s._v(" tx_isolation"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'repeatable-read'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- Session_1执行")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" account "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("update")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- Session_2执行")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" account "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("update")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- Session_1执行")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" account "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("update")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- Session_2执行")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" account "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("update")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 查看近期死锁日志信息")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("show")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("engine")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("innodb")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("status")]),s._v("\\G"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n")])])]),t("p",[s._v("大多数情况mysql可以自动检测死锁并回滚产生死锁的那个事务，但是有些情况mysql没法自动检测死锁")]),s._v(" "),t("h4",{attrs:{id:"锁优化建议"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#锁优化建议"}},[s._v("#")]),s._v(" 锁优化建议")]),s._v(" "),t("ul",[t("li",[s._v("尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁")]),s._v(" "),t("li",[s._v("合理设计索引，尽量缩小锁的范围")]),s._v(" "),t("li",[s._v("尽可能减少检索条件范围，避免间隙锁")]),s._v(" "),t("li",[s._v("尽量控制事务大小，减少锁定资源量和时间长度，涉及事务加锁的sql尽量放在事务最后执行")]),s._v(" "),t("li",[s._v("尽可能低级别事务隔离")])]),s._v(" "),t("h3",{attrs:{id:"mvcc多版本并发控制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mvcc多版本并发控制"}},[s._v("#")]),s._v(" MVCC多版本并发控制")]),s._v(" "),t("p",[s._v("MySQL在可重复读隔离级别下同样的sql查询语句在一个事务里多次执行查询结果相同，就算其它事务对数据有修改也不会影响当前事务sql语句的查询结果。")]),s._v(" "),t("p",[s._v("这个隔离性就是靠"),t("code",[s._v("MVCC(Multi-Version Concurrency Control)")]),s._v("机制来保证的，对一行数据的读和写两个操作默认是不会通过加锁互斥来保证隔离性，避免了频繁加锁互斥，而在串行化隔离级别为了保证较高的隔离性是通过将所有操作加锁互斥来实现的。")]),s._v(" "),t("p",[s._v("MySQL在读已提交和可重复读隔离级别下都实现了MVCC机制。")]),s._v(" "),t("p",[t("strong",[s._v("undo日志版本链与"),t("code",[s._v("read view")]),s._v("机制")])]),s._v(" "),t("p",[t("strong",[s._v("undo日志版本链")]),s._v("是指一行数据被多个事务依次修改过后，在每个事务修改完后，MySQL会保留修改前的数据"),t("strong",[s._v("undo回滚日志")]),s._v("，并且用两个隐藏字段"),t("code",[s._v("trx_id")]),s._v("和"),t("code",[s._v("roll_pointer")]),s._v("把这些undo日志串联起来形成一个历史记录版本链")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/99285.png",alt:"0"}})]),s._v(" "),t("p",[s._v("在"),t("strong",[s._v("可重复读隔离级别")]),s._v("，当事务开启，执行任何查询sql时会生成当前事务的"),t("strong",[s._v("一致性视图read-view")]),s._v("，该视图在事务结束之前都不会变化("),t("strong",[s._v("如果是读已提交隔离级别在每次执行查询sql时都会重新生成")]),s._v(")，这个视图由执行查询时所有未提交事务id数组（数组里最小的id为"),t("code",[s._v("min_id")]),s._v("）和已创建的最大事务id（"),t("code",[s._v("max_id")]),s._v("）组成，事务里的任何sql查询结果需要从对应版本链里的最新数据开始逐条跟"),t("code",[s._v("read-view")]),s._v("做比对从而得到最终的快照结果。")]),s._v(" "),t("p",[t("strong",[s._v("版本链比对规则")]),s._v("：")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("如果 row 的 trx_id 落在绿色部分"),t("code",[s._v("(trx_id<min_id)")]),s._v("，表示这个版本是已提交的事务生成的，这个数据是可见的；")])]),s._v(" "),t("li",[t("p",[s._v("如果 row 的 trx_id 落在红色部分"),t("code",[s._v("(trx_id>max_id)")]),s._v("，表示这个版本是由将来启动的事务生成的，是不可见的(若 row 的 trx_id 就是当前自己的事务是可见的）；")])]),s._v(" "),t("li",[t("p",[s._v("如果 row 的 trx_id 落在黄色部分"),t("code",[s._v("(min_id <=trx_id<= max_id)")]),s._v("，那就包括两种情况")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("若 row 的 trx_id 在视图数组中，表示这个版本是由还没提交的事务生成的，不可见(若 row 的 trx_id 就是当前自己的事务是可见的)；")])]),s._v(" "),t("li",[t("p",[s._v("若 row 的 trx_id 不在视图数组中，表示这个版本是已经提交了的事务生成的，可见。")])])])])]),s._v(" "),t("p",[s._v("对于删除的情况可以认为是"),t("code",[s._v("update")]),s._v("的特殊情况，会将版本链上最新的数据复制一份，然后将trx_id修改成删除操作的trx_id，同时在该条记录的头信息（"),t("code",[s._v("record header")]),s._v("）里的（"),t("code",[s._v("deleted_flag")]),s._v("）标记位写上true，来表示当前记录已经被删除，在查询时按照上面的规则查到对应的记录如果delete_flag标记位为true，意味着记录已被删除，则不返回数据。")]),s._v(" "),t("blockquote",[t("p",[t("code",[s._v("begin/start transaction")]),s._v(" 命令并不是一个事务的起点，在执行到它们之后的第一个修改操作InnoDB表的语句，事务才真正启动，才会向mysql申请事务id，mysql内部是严格按照事务的启动顺序来分配事务id的。")])]),s._v(" "),t("p",[t("strong",[s._v("实例分析")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240122111555523.png",alt:"image-20240122111555523"}})]),s._v(" "),t("p",[t("strong",[s._v("总结")]),s._v("：")]),s._v(" "),t("p",[t("code",[s._v("MVCC")]),s._v("机制的实现就是通过"),t("code",[s._v("read-view")]),s._v("机制与"),t("code",[s._v("undo版本链")]),s._v("比对机制，使得不同的事务会根据数据版本链对比规则读取同一条数据在版本链上的不同版本数据。")]),s._v(" "),t("h3",{attrs:{id:"innodb的bufferpool缓存机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#innodb的bufferpool缓存机制"}},[s._v("#")]),s._v(" Innodb的BufferPool缓存机制")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/99001.png",alt:"0"}})]),s._v(" "),t("p",[t("strong",[s._v("为什么Mysql不能直接更新磁盘上的数据而且设置这么一套复杂的机制来执行SQL？")])]),s._v(" "),t("blockquote",[t("ol",[t("li",[t("p",[s._v("因为来一个请求就直接对磁盘文件进行随机读写，然后更新磁盘文件里的数据性能可能相当差。")])]),s._v(" "),t("li",[t("p",[s._v("因为磁盘随机读写的性能是非常差的，所以直接更新磁盘文件是不能让数据库抗住很高并发的。")])])])]),s._v(" "),t("p",[s._v("MySQL这套机制看起来复杂，但它可以保证每个更新请求都是"),t("strong",[s._v("更新内存BufferPool")]),s._v("，然后"),t("strong",[s._v("顺序写日志文件")]),s._v("，同时还能保证各种异常情况下的数据一致性。")]),s._v(" "),t("p",[s._v("更新内存的性能是极高的，然后顺序写磁盘上的日志文件的性能也是非常高的，要远高于随机读写磁盘文件。")]),s._v(" "),t("p",[s._v("正是通过这套机制，才能让我们的MySQL数据库在较高配置的机器上每秒可以抗下几干甚至上万的读写请求。")]),s._v(" "),t("h2",{attrs:{id:"innodb-引擎底层存储和缓存原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#innodb-引擎底层存储和缓存原理"}},[s._v("#")]),s._v(" InnoDB 引擎底层存储和缓存原理")]),s._v(" "),t("p",[t("code",[s._v("InnoDB")]),s._v(" 读取表中数据采取的方式是：将数据划分为若干个页，以页作为磁盘和内存之间交互的基本单位，"),t("code",[s._v("InnoDB")]),s._v(" 中页的大小一般为 "),t("strong",[s._v("16KB")]),s._v("。也就是在一般情况下，一次最少从磁盘中读取 16KB 的内容到内存中，一次最少把内存中的 16KB 内容刷新到磁盘中。")]),s._v(" "),t("h3",{attrs:{id:"数据行格式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#数据行格式"}},[s._v("#")]),s._v(" 数据行格式")]),s._v(" "),t("p",[s._v("我们平时是以记录为单位来向表中插入数据的，这些记录在磁盘上的存放方式也被称为行格式或者记录格式。InnoDB 存储引擎设计了4 种不同类型的行格式，分别是 "),t("code",[s._v("Compact、Redundant、Dynamic、Compressed")]),s._v("行格式。")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 指定行格式")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" 表名 "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("列的信息"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" ROW_FORMAT"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("行格式名称\n")])])]),t("p",[t("code",[s._v("Compact")]),s._v("行格式：记录头信息，由固定的 5 个字节组成")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240123101443393.png",alt:"image-20240123101443393"}})]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("字段名")]),s._v(" "),t("th",[s._v("长度")]),s._v(" "),t("th",[s._v("描述")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("delete_mask")]),s._v(" "),t("td",[s._v("1b")]),s._v(" "),t("td",[s._v("标记该记录是否被删除")])]),s._v(" "),t("tr",[t("td",[s._v("min_rec_mask")]),s._v(" "),t("td",[s._v("1b")]),s._v(" "),t("td",[s._v("B+树的每层非叶子节点中的最小记录都会添加该标记")])]),s._v(" "),t("tr",[t("td",[s._v("n_owned")]),s._v(" "),t("td",[s._v("4b")]),s._v(" "),t("td",[s._v("表示当前记录拥有的记录数")])]),s._v(" "),t("tr",[t("td",[s._v("heap_no")]),s._v(" "),t("td",[s._v("13b")]),s._v(" "),t("td",[s._v("表示当前记录在页的位置信息")])]),s._v(" "),t("tr",[t("td",[s._v("record_type")]),s._v(" "),t("td",[s._v("3b")]),s._v(" "),t("td",[s._v("表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录")])]),s._v(" "),t("tr",[t("td",[s._v("next_record")]),s._v(" "),t("td",[s._v("16b")]),s._v(" "),t("td",[s._v("表示下一条记录的相对位置")])]),s._v(" "),t("tr",[t("td",[s._v("DB_ROW_ID(row_id)")]),s._v(" "),t("td",[s._v("6B")]),s._v(" "),t("td",[s._v("表示行 ID，唯一标识一条记录")])]),s._v(" "),t("tr",[t("td",[s._v("DB_TRX_ID")]),s._v(" "),t("td",[s._v("6B")]),s._v(" "),t("td",[s._v("表示事务 ID")])]),s._v(" "),t("tr",[t("td",[s._v("DB_ROLL_PTR")]),s._v(" "),t("td",[s._v("7B")]),s._v(" "),t("td",[s._v("表示回滚指针")])])])]),s._v(" "),t("p",[s._v("InnoDB 表对主键的生成策略是")]),s._v(" "),t("ol",[t("li",[s._v("优先使用用户自定义主键作为主键；")]),s._v(" "),t("li",[s._v("如果用户没有定义主键，则选取一个 Unique 键作为主键；")]),s._v(" "),t("li",[s._v("如果表中连 Unique 键都没有定义的话，则 InnoDB 会为表默认添加一个名为 row_id 的隐藏列作为主键。")])]),s._v(" "),t("p",[t("code",[s._v("DB_TRX_ID")]),s._v("（也可以称为 trx_id） 和 "),t("code",[s._v("DB_ROLL_PTR")]),s._v("（也可以称为 roll_ptr） 这两 个列是必有的，但是 "),t("code",[s._v("row_id")]),s._v("是可选的（在没有自定义主键以及 Unique 键的情 况下才会添加该列）。 其他的行格式和 Compact 行格式差别不大。")]),s._v(" "),t("blockquote",[t("p",[t("code",[s._v("Dynamic")]),s._v(" 和 "),t("code",[s._v("Compressed")]),s._v(" 行格式和 "),t("code",[s._v("Compact")]),s._v(" 行格式类似，只不过在处理行溢出数据时有所不同。"),t("code",[s._v("Compressed")]),s._v(" 行格式和 "),t("code",[s._v("Dynamic")]),s._v(" 不同的一点是，"),t("code",[s._v("Compressed")]),s._v(" 行格式会采用压缩算法对页面进行压缩，以节省空间。")])]),s._v(" "),t("p",[t("strong",[s._v("数据溢出")])]),s._v(" "),t("p",[s._v("如果一个页存放不了一条记录")]),s._v(" "),t("ul",[t("li",[s._v("在 "),t("code",[s._v("Compact")]),s._v(" 和 "),t("code",[s._v("Redundant")]),s._v(" 行格式中，对于占用存储空间非常大的列，在记录的真实数据处只会存储该列的该列的前 768 个字节的数据，然后把剩余的数据分散存储在几个其他的页中，记录的真实数据处用 20 个字节存储指向这些页的地址。这个过程也叫做行溢出，存储超出 768 字节的那些页面也被称为溢出页。")]),s._v(" "),t("li",[t("code",[s._v("Dynamic")]),s._v(" 和 "),t("code",[s._v("Compressed")]),s._v(" 行格式，把所有的字节都存储到其他页面中，在记录的真实数据处存储其他页面的地址。")])]),s._v(" "),t("h3",{attrs:{id:"索引页格式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#索引页格式"}},[s._v("#")]),s._v(" 索引页格式")]),s._v(" "),t("p",[s._v("InnoDB 管理存储空间的基本单位是页，一 个页的大小一般是 16KB。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240123103756125.png",alt:"image-20240123103756125"}})]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("块类型")]),s._v(" "),t("th",[s._v("长度")]),s._v(" "),t("th",[s._v("描述")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("File Header")]),s._v(" "),t("td",[s._v("38B")]),s._v(" "),t("td",[s._v("页的一些通用信息")])]),s._v(" "),t("tr",[t("td",[s._v("Page Header")]),s._v(" "),t("td",[s._v("56B")]),s._v(" "),t("td",[s._v("数据页专有的一些信息")])]),s._v(" "),t("tr",[t("td",[s._v("Infimum + Supremum")]),s._v(" "),t("td",[s._v("26B")]),s._v(" "),t("td",[s._v("两个虚拟的行记录（最小记录和最大记录）")])]),s._v(" "),t("tr",[t("td",[s._v("User Records")]),s._v(" "),t("td",[s._v("不确定")]),s._v(" "),t("td",[s._v("实际存储的行记录内容")])]),s._v(" "),t("tr",[t("td",[s._v("Free Space")]),s._v(" "),t("td",[s._v("不确定")]),s._v(" "),t("td",[s._v("页中尚未使用的空间")])]),s._v(" "),t("tr",[t("td",[s._v("Page Directory")]),s._v(" "),t("td",[s._v("不确定")]),s._v(" "),t("td",[s._v("页中的某些记录的相对位置")])]),s._v(" "),t("tr",[t("td",[s._v("File Trailer")]),s._v(" "),t("td",[s._v("8B")]),s._v(" "),t("td",[s._v("校验页是否完整")])])])]),s._v(" "),t("p",[t("strong",[s._v("User Records")])]),s._v(" "),t("p",[s._v("我们自己存储的记录会按照我们指定的行格式存储到 "),t("code",[s._v("User Records")]),s._v(" 部分。但是 在一开始生成页的时候，其实并没有 "),t("code",[s._v("User Records")]),s._v(" 这个部分，每当我们插入一条记录，都会从"),t("code",[s._v("Free Space")]),s._v(" 部分，也就是尚未使用的存储空间中申请一个记录大小 的空间划分到 "),t("code",[s._v("User Records")]),s._v(" 部分，当 "),t("code",[s._v("Free Space")]),s._v(" 部分的空间全部被 "),t("code",[s._v("User Records")]),s._v(" 部分替代掉之后，也就意味着这个页使用完了，如果还有新的记录插入的话，就需要去申请新的页了。")]),s._v(" "),t("p",[s._v("当前记录被删除时，则会修改记录头信息中的 "),t("code",[s._v("delete_mask")]),s._v(" 为 1，也就是说被 删除的记录还在页中，还在真实的磁盘上。这些被删除的记录之所以不立即从磁 盘上移除，是因为移除它们之后把其他的记录在磁盘上重新排列需要性能消耗。 所以只是打一个删除标记而已，所有被删除掉的记录都会组成一个所谓的垃圾链表，在这个链表中的记录占用的空间称之为所谓的"),t("strong",[s._v("可重用空间")]),s._v("，之后如果有新记录插入到表中的话，可能把这些被删除的记录占用的存储空间覆盖掉。")]),s._v(" "),t("p",[s._v("同时我们插入的记录在会记录自己在本页中的位置，写入了记录头信息中"),t("code",[s._v("heap_no")]),s._v(" 部分。"),t("code",[s._v("heap_no")]),s._v(" 值为 0 和 1 的记录是 InnoDB 自动给每个页增加的两个记录，称为"),t("strong",[s._v("伪记录或者虚拟记录")]),s._v("。这两个伪记录一个代表最小记录，一个代表最大记录，这两条存放在页的 "),t("code",[s._v("User Records")]),s._v(" 部分，他们被单独放在一个称为 "),t("code",[s._v("Infimum + Supremum")]),s._v(" 的部分。")]),s._v(" "),t("p",[s._v("我们的记录按照主键从小到大的顺序形成了一个单链表，记录被删除，则从这个链表上摘除。")]),s._v(" "),t("p",[t("strong",[s._v("Page Directory")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240123104854014.png",alt:"image-20240123104854014"}})]),s._v(" "),t("p",[t("code",[s._v("Page Directory")]),s._v(" 主要是解决记录链表的查找问题。")]),s._v(" "),t("ol",[t("li",[s._v("将所有正常的记录（包括最大和最小记录，不包括标记为已删除的记录） 划分为几个组。")]),s._v(" "),t("li",[s._v("每个组的最后一条记录（也就是组内最大的那条记录）的头信息中的 "),t("code",[s._v("n_owned")]),s._v(" 属性表示该记录拥有多少条记录，也就是该组内共有几条记录。")]),s._v(" "),t("li",[s._v("将每个组的最后一条记录的地址偏移量单独提取出来按顺序存储到靠近页的尾部的地方，这个地方就是所谓的 "),t("code",[s._v("Page Directory")]),s._v("，也就是页目录页面目录中的这些地址偏移量被称为槽（Slot），所以这个页面目录就是由槽组成的。")]),s._v(" "),t("li",[s._v("每个分组中的记录条数是有规定的：对于最小记录所在的分组只能有 1 条 记录，最大记录所在的分组拥有的记录条数只能在 1~8 条之间，剩下的分组中 记录的条数范围只能在是 4~8 条之间。")])]),s._v(" "),t("h3",{attrs:{id:"innodb的体系结构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#innodb的体系结构"}},[s._v("#")]),s._v(" InnoDB的体系结构")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240123105510491.png",alt:"image-20240123105510491"}})]),s._v(" "),t("p",[s._v("简化图")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240123105622217.png",alt:"image-20240123105622217"}})]),s._v(" "),t("h3",{attrs:{id:"innodb-的表空间"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#innodb-的表空间"}},[s._v("#")]),s._v(" InnoDB 的表空间")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240123105809510.png",alt:"image-20240123105809510"}})]),s._v(" "),t("h3",{attrs:{id:"doublewrite-buffer"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#doublewrite-buffer"}},[s._v("#")]),s._v(" Doublewrite buffer")]),s._v(" "),t("p",[s._v("双写缓冲区/双写机制是 InnoDB 的三大特性之一，还有两个是 "),t("code",[s._v("Buffer Pool")]),s._v("、自适应 Hash 索引。")]),s._v(" "),t("p",[s._v("它是一种特殊文件 "),t("code",[s._v("flush")]),s._v(" 技术，带给 InnoDB 存储引擎的是数据页的可靠性。")]),s._v(" "),t("p",[s._v("它的作用是：在把页写到数据文件之前，InnoDB 先把它们写到"),t("code",[s._v("doublewrite buffer")]),s._v("（双写缓冲区）的连续区域内，在写 "),t("code",[s._v("doublewrite buffer")]),s._v(" 完成后，InnoDB 才会把页写到数据文件的适当的位置。如果在写页的过程中发生意外崩溃，InnoDB 在稍后的恢复过程中在 "),t("code",[s._v("doublewrite buffer")]),s._v(" 中找到完好的 page 副本用于恢复。")]),s._v(" "),t("p",[s._v("在正常的情况下, MySQL 写数据页时，会写两遍到磁盘上，第一遍是写到 "),t("code",[s._v("doublewrite buffer")]),s._v("，第二遍是写到真正的数据文件中。如果发生了极端情况（断 电），InnoDB 再次启动后，发现了一个页数据已经损坏，那么此时就可以从 "),t("code",[s._v("doublewrite buffer")]),s._v(" 中进行数据恢复了。")]),s._v(" "),t("p",[s._v("在数据库异常关闭的情况下启动时，都会做数据库恢复（redo）操作，恢复的过程中，数据库都会检查页面是不是合法（校验等等），如果发现一个页面校验结果不一致，则此时会用到双写这个功能。")]),s._v(" "),t("h3",{attrs:{id:"buffer-pool"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#buffer-pool"}},[s._v("#")]),s._v(" Buffer Pool")]),s._v(" "),t("p",[s._v("InnoDB 为了缓存磁盘中的页，在 MySQL 服务器启动的时候就向操作系统申请了一片连续的内存("),t("code",[s._v("Buffer Pool")]),s._v(")")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 查看Buffer Pool大小")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("show")]),s._v(" variables "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("like")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'innodb_buffer_pool_size'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 可通过启动服务时配置conf文件，innodb_buffer_pool_size参数修改Buffer Pool大小")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 查看Buffer Pool的命中率")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("show")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("engine")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("innodb")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("status")]),s._v("；\n")])])]),t("p",[t("code",[s._v("Buffer Pool")]),s._v("中默认的缓存页大小和在磁盘上默认的页大小是一样的，都是16KB。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240123111011316.png",alt:"image-20240123111011316"}})]),s._v(" "),t("p",[s._v("对于free 链表中已经没有多余的空闲缓存页的情况，需要把某些旧的缓存页从 "),t("code",[s._v("Buffer Pool")]),s._v(" 中移除，然后再把新的页放进来")]),s._v(" "),t("p",[s._v("InnoDB 采用"),t("strong",[s._v("LRU")]),s._v("的策略对缓存页进行替换")]),s._v(" "),t("p",[s._v("InnoDB 把这个 "),t("strong",[s._v("LRU")]),s._v(" 链表按照一定比例分成两截，分别是：")]),s._v(" "),t("ol",[t("li",[s._v("一部分存储使用频率非常高的缓存页，所以这一部分链表也叫做热数据，或 者称 young 区域，褐色部分。")]),s._v(" "),t("li",[s._v("另一部分存储使用频率不是很高的缓存页，所以这一部分链表也叫做冷数据， 或者称 old 区域，绿色部分，占比37%。")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240123112258867.png",alt:"image-20240123112258867"}})]),s._v(" "),t("p",[t("strong",[s._v("多个 Buffer Pool 实例")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 查看Buffer Pool实例数")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("show")]),s._v(" variables "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("like")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'innodb_buffer_pool_instances'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 可通过启动服务时配置conf文件，innodb_buffer_pool_instances参数修改 Buffer Pool 实例的个数")]),s._v("\n")])])]),t("p",[s._v("在多线程环境下，访问 "),t("code",[s._v("Buffer Pool")]),s._v(" 中的各种链表都需要"),t("strong",[s._v("加锁")]),s._v("处理，在 "),t("code",[s._v("Buffer Pool")]),s._v(" 特别大而且多线程并发访问特别高的情况下，单一的 "),t("code",[s._v("Buffer Pool")]),s._v("可能会影响请求的处理速度。这个时候可以把它们拆分成若干个小的 "),t("code",[s._v("Buffer Pool")]),s._v("，每个 "),t("code",[s._v("Buffer Pool")]),s._v(" 都称为一个实例，它们都是独立的，独立的去申请内存空间，独立的管理各种链表，所以在多线程并发访问时并不会相互影响，从而提高并发处理能力。")]),s._v(" "),t("p",[t("strong",[s._v("free 链表的管理")])]),s._v(" "),t("p",[s._v("启动 MySQL 服务器的时候，先向操作系统申请 "),t("code",[s._v("Buffer Pool")]),s._v(" 的内存空间，然后把它划分成若干对控制块和缓存页。但是此时并没有真实的磁盘页被缓存到 "),t("code",[s._v("Buffer Pool")]),s._v(" 中（因为还没有用到）， 之后随着程序的运行，会不断的有磁盘上的页被缓存到 "),t("code",[s._v("Buffer Pool")]),s._v(" 中。")]),s._v(" "),t("p",[s._v("把所有空闲的缓存页对应的控制 块作为一个节点放到一个链表中，这个链表被称作 free 链表。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240123111307687.png",alt:"image-20240123111307687"}})]),s._v(" "),t("p",[s._v("用表空间号 + 页号作为 key，缓存页作为 value 创建一个"),t("strong",[s._v("哈希表")]),s._v("，用来判断页是否在"),t("code",[s._v("Buffer Pool")]),s._v("中。")]),s._v(" "),t("p",[t("strong",[s._v("flush 链表的管理")])]),s._v(" "),t("p",[s._v("如果我们修改了 "),t("code",[s._v("Buffer Pool")]),s._v(" 中某个缓存页的数据，那它就和磁盘上的页不一 致了，这样的缓存页也被称为脏页（"),t("code",[s._v("dirty page")]),s._v("）。")]),s._v(" "),t("p",[s._v("MySQL对脏页的处理是：每次修改缓存页后，并不会立即把修改同步到磁盘上，而是在未来的某个时间点进行同步。 这个时候需要创建一个存储脏页的链表，凡是修改过的缓存页对应的控制块都会作为一个节点加入到一个链表中。这就是 flush 链表。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240123111904428.png",alt:"image-20240123111904428"}})]),s._v(" "),t("p",[t("strong",[s._v("刷新脏页到磁盘")])]),s._v(" "),t("ol",[t("li",[s._v("从 LRU 链表的冷数据中刷新一部分页面到磁盘。")])]),s._v(" "),t("p",[t("code",[s._v("BUF_FLUSH_LRU")]),s._v("：后台线程会定时从 LRU 链表尾部开始扫描一些页面，扫描的页面数量可以通过系统变量 "),t("code",[s._v("innodb_lru_scan_depth")]),s._v(" 来指定，如果发现脏页，则会把它们刷新到磁盘。")]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[s._v("从 flush 链表中刷新一部分页面到磁盘。")])]),s._v(" "),t("p",[t("code",[s._v("BUF_FLUSH_LIST")]),s._v("：后台线程也会定时从 flush 链表中刷新一部分页面到磁盘，刷新的速率取决于当时系统否繁忙。")]),s._v(" "),t("p",[t("code",[s._v("BUF_FLUSH_SINGLE_PAGE")]),s._v("：用户线程在准备加载一个磁盘页到 "),t("code",[s._v("Buffer Pool")]),s._v(" 时没有可用的缓存页，这时就会尝试看flush 链表尾部有没有可以直接释放掉的未修改页面，如果没有的话会将链表尾部的一个脏页同步刷新到磁盘。")]),s._v(" "),t("h2",{attrs:{id:"innodb-引擎底层事务的原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#innodb-引擎底层事务的原理"}},[s._v("#")]),s._v(" InnoDB 引擎底层事务的原理")]),s._v(" "),t("p",[s._v("数据库事务的ACID特性如何保证")]),s._v(" "),t("ol",[t("li",[s._v("MySQL 中事务的原子性是通过 "),t("code",[s._v("undo log")]),s._v(" 来实现；")]),s._v(" "),t("li",[s._v("事务的持久性是通过 "),t("code",[s._v("redo log")]),s._v(" 来实现；")]),s._v(" "),t("li",[s._v("事务的隔离性是通过"),t("strong",[s._v("读写锁+MVCC")]),s._v("来实现；")]),s._v(" "),t("li",[s._v("事务的一致性通过原子性、隔离性、持久性来保证。")])]),s._v(" "),t("p",[s._v("在事务的具体实现机制上，MySQL 采用的是 "),t("code",[s._v("WAL（Write-ahead logging，预写式日志）")]),s._v("机制来实现的。")]),s._v(" "),t("p",[s._v("在使用 "),t("code",[s._v("WAL")]),s._v(" 的系统中，所有的修改都先被写入到日志中，然后再被应用到系统中。通常包含 "),t("code",[s._v("redo")]),s._v(" 和 "),t("code",[s._v("undo")]),s._v(" 两部分信息。")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("redo log")]),s._v("称为重做日志，每当有操作时，在数据变更之前将操作写入 "),t("code",[s._v("redo log")]),s._v("， 这样当发生掉电之类的情况时系统可以在重启后继续操作。")]),s._v(" "),t("li",[t("code",[s._v("undo log")]),s._v(" 称为撤销日志，当一些变更执行到一半无法完成时，可以根据撤销日志恢复到变更之间的状态。")]),s._v(" "),t("li",[s._v("MySQL 中用 "),t("code",[s._v("redo log")]),s._v("来在系统 Crash 重启之类的情况时修复数据（事 务的持久性），而 "),t("code",[s._v("undo log")]),s._v(" 来保证事务的原子性。")])]),s._v(" "),t("h3",{attrs:{id:"redo-日志"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redo-日志"}},[s._v("#")]),s._v(" redo 日志")]),s._v(" "),t("p",[s._v("想让已经提交了的事务对数据库中数据所做的修改永久生效，即使后来系统崩溃，在重启后也能把这种修改恢复出来。这就需要把修改了哪些东西记录到磁盘中。")]),s._v(" "),t("p",[s._v("比方说某个事务将系统表空间中的第 100 号页面中偏移量为 1000 处的那个字节的值 1 改成 2；")]),s._v(" "),t("p",[s._v("只需要记录一下： 将第 0 号表空间的 100 号页面的偏移量为 1000 处的值更新为 2。")]),s._v(" "),t("p",[s._v("这样在事务提交时，把上述内容刷新到磁盘中，即使之后系统崩溃了， 重启之后只要按照上述内容所记录的步骤重新更新一下数据页，那么该事务对数据库中所做的修改又可以被恢复出来，也就意味着满足持久性的要求。因为在系统崩溃重启时需要按照上述内容所记录的步骤重新更新数据页，所以上述内容也被称之为"),t("strong",[s._v("重做日志")]),s._v("("),t("code",[s._v("redo log")]),s._v(") 。")]),s._v(" "),t("p",[s._v("与在事务提交时将所有修改过的内存中的页面刷新到磁盘中相比，只将该事务执行过程中产生的 redo 日志刷新到磁盘的好处如下：")]),s._v(" "),t("ol",[t("li",[s._v("redo 日志占用的空间非常小存储表空间 ID、页号、偏移量以及需要更新的值所需的存储空间是很小的。")]),s._v(" "),t("li",[s._v("redo 日志是顺序写入磁盘的 在执行事务的过程中，每执行一条语句，就可能产生若干条 redo 日志，这些 日志是按照产生的顺序写入磁盘的，也就是使用顺序 IO。")])]),s._v(" "),t("p",[t("strong",[s._v("redo 日志格式")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240123150344630.png",alt:"image-20240123150344630"}})]),s._v(" "),t("p",[s._v("type：该条 redo 日志的类型，redo 日志设计大约有 53 种不同的类型日志。")]),s._v(" "),t("p",[s._v("space ID：表空间 ID。")]),s._v(" "),t("p",[s._v("page number：页号。")]),s._v(" "),t("p",[s._v("data：该条 redo 日志的具体内容。")]),s._v(" "),t("p",[t("strong",[s._v("redo 日志的写入过程")])]),s._v(" "),t("p",[s._v("InnoDB 为了更好的进行系统崩溃恢复，把 redo 日志都放在了大小为 512 字节 的块（block）中。 前边说过，为了解决磁盘速度过慢的问题而引入了 "),t("code",[s._v("Buffer Pool")]),s._v("。同理，写 入 redo 日志时也不能直接直接写到磁盘上，实际上在服务器启动时就向操作系统申请了一大片称之为 "),t("code",[s._v("redo log buffer")]),s._v(" 的连续内存空间。这片内存空间被划分成若干个连续的 "),t("code",[s._v("redo log block")]),s._v("，我们可以通过启动参数 "),t("code",[s._v("innodb_log_buffer_size")]),s._v(" 来指定 "),t("code",[s._v("log buffer")]),s._v(" 的大小，该启动参数的默认值为 "),t("strong",[s._v("16MB")]),s._v("。 向"),t("code",[s._v("log buffer")]),s._v("中写入redo日志的过程是顺序的，也就是先往前边的block中写， 当该 block 的空闲空间用完之后再往下一个 block 中写。")]),s._v(" "),t("p",[t("strong",[s._v("redo 日志刷盘时机")])]),s._v(" "),t("p",[s._v("在一些情况下"),t("code",[s._v("log buffer")]),s._v("会被刷新到磁盘里")]),s._v(" "),t("ol",[t("li",[t("code",[s._v("log buffer")]),s._v(" 空间不足时，"),t("code",[s._v("log buffer")]),s._v(" 的大小是有限的（通过系统变量 "),t("code",[s._v("innodb_log_buffer_size")]),s._v(" 指定），如果不停的往这个有限大小的 "),t("code",[s._v("log buffer")]),s._v(" 里塞入日志，很快它就会被填满。InnoDB 认为如果当前写入 "),t("code",[s._v("log buffer")]),s._v(" 的"),t("code",[s._v("redo")]),s._v("日志量已经占满了 "),t("code",[s._v("log buffer")]),s._v(" 总容量的大约"),t("strong",[s._v("一半左右")]),s._v("，就需要把这些日志刷新到磁盘上。")]),s._v(" "),t("li",[s._v("在事务提交时可以不把修改过的 "),t("code",[s._v("Buffer Pool")]),s._v(" 页面刷新到磁盘， 但是为了保证持久性，必须要把修改这些页面对应的 "),t("code",[s._v("redo")]),s._v(" 日志刷新到磁盘。")]),s._v(" "),t("li",[s._v("后台有一个线程，大约每秒都会刷新一次 "),t("code",[s._v("log buffer")]),s._v(" 中的 "),t("code",[s._v("redo")]),s._v(" 日志到磁盘。")]),s._v(" "),t("li",[s._v("正常关闭服务器时等等。")])]),s._v(" "),t("h3",{attrs:{id:"undo-日志"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#undo-日志"}},[s._v("#")]),s._v(" undo 日志")]),s._v(" "),t("p",[s._v("事务需要保证原子性：事务中的操作要么全部完成，要么什 么也不做。但是偏偏有时候事务执行到一半会出现一些情况，比如：")]),s._v(" "),t("ul",[t("li",[s._v("情况一：事务执行过程中可能遇到各种错误，比如服务器本身的错误，操作系统错误，甚至是突然断电导致的错误。")]),s._v(" "),t("li",[s._v("情况二：程序员可以在事务执行过程中手动输入 "),t("code",[s._v("ROLLBACK")]),s._v(" 语句结束当前的务的执行。")])]),s._v(" "),t("p",[s._v("这两种情况都会导致事务执行到一半就结束，但是事务执行过程中可能已经修改了很多东西，为了保证事务的原子性，需要把东西改回原先的样子，这个过程就称之为"),t("strong",[s._v("回滚")]),s._v("。")]),s._v(" "),t("p",[s._v("为了回滚而记录的这些东西称之为"),t("strong",[s._v("撤销日志")]),s._v("("),t("code",[s._v("undo log")]),s._v(")")]),s._v(" "),t("p",[t("strong",[s._v("事务 id 生成机制")])]),s._v(" "),t("p",[s._v("这个事务 id 本质上就是一个数字，它的分配策略和我们前边提到的对隐藏列 "),t("code",[s._v("row_id")]),s._v("（当用户没有为表创建主键和 UNIQUE 键时 InnoDB 自动创建的列）的分配策略大抵相同，具体策略如下：")]),s._v(" "),t("ol",[t("li",[s._v("服务器会在内存中维护一个全局变量，每当需要为某个事务分配一个事务 id 时，就会把该变量的值当作事务 id 分配给该事务，并且把该变量自增 1。")]),s._v(" "),t("li",[s._v("每当这个变量的值为 "),t("strong",[s._v("256 的倍数")]),s._v("时，就会将该变量的值刷新到系统表空间的页号为 5 的页面中一个称之为 "),t("code",[s._v("Max Trx ID")]),s._v(" 的属性处，这个属性占用 8 个字节的存储空间。 当系统下一次重新启动时，会将上边提到的 "),t("code",[s._v("Max Trx ID")]),s._v("属性加载到内存中，将该值加上 "),t("code",[s._v("256")]),s._v(" 之后赋值给我们前边提到的全局变量（因为在上次关机时该全局变量的值可能大于 "),t("code",[s._v("Max Trx ID")]),s._v(" 属性值）。")])]),s._v(" "),t("p",[s._v("这样就可以保证整个系统中分配的事务 id 值是一个递增的数字。先被分配 id 的事务得到的是较小的事务 id，后被分配 id 的事务得到的是较大的事务 id。")]),s._v(" "),t("p",[t("strong",[s._v("undo 日志的格式")])]),s._v(" "),t("p",[s._v("为了实现事务的原子性，InnoDB 存储引擎在实际进行增、删、改一条记录时， 都需要先把对应的 "),t("code",[s._v("undo")]),s._v(" 日志记下来。一般每对一条记录做一次改动，就对应着 1 条 "),t("code",[s._v("undo")]),s._v(" 日志，但在某些更新记录的操作中，也可能会对应着 2 条 "),t("code",[s._v("undo")]),s._v(" 日志。")]),s._v(" "),t("h3",{attrs:{id:"事务的流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#事务的流程"}},[s._v("#")]),s._v(" 事务的流程")]),s._v(" "),t("p",[s._v("事务流程分为事务的"),t("strong",[s._v("执行流程")]),s._v("和"),t("strong",[s._v("事务恢复流程")]),s._v("。")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("事务执行")])])]),s._v(" "),t("p",[s._v("MySQL 的事务主要是通过 "),t("code",[s._v("Redo Log")]),s._v(" 和 "),t("code",[s._v("Undo Log")]),s._v(" 实现的。 MySQL 事务执行流程如下图")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240123152901105.png",alt:"image-20240123152901105"}})]),s._v(" "),t("p",[s._v("可以看出，MySQL 在事务执行的过程中，会记录相应 SQL 语句的 "),t("code",[s._v("UndoLog")]),s._v(" 和 "),t("code",[s._v("Redo Log")]),s._v("，然后在内存中更新数据并形成数据脏页。接下来 "),t("code",[s._v("RedoLog")]),s._v(" 会根据一定规则触发刷盘操作，"),t("code",[s._v("Undo Log")]),s._v(" 和数据脏页则通过刷盘机制刷盘。事务提交时， 会将当前事务相关的所有 "),t("code",[s._v("Redo Log")]),s._v(" 刷盘，只有当前事务相关的所有 "),t("code",[s._v("Redo Log")]),s._v(" 刷 盘成功，事务才算提交成功。")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("事务恢复")])])]),s._v(" "),t("p",[s._v("如果一切正常，则 MySQL 事务会按照上图中的顺序执行。如果 MySQL 由于某种原因崩溃或者宕机，当然进行数据的恢复或者回滚操作。 如果事务在执行第 8 步,即事务提交之前，MySQL 崩溃或者宕机，此时会先使用 "),t("code",[s._v("Redo Log")]),s._v(" 恢复数据，然后使用 "),t("code",[s._v("Undo Log")]),s._v(" 回滚数据。 如果在执行第8步之后MySQL崩溃或者宕机，此时会使用"),t("code",[s._v("Redo Log")]),s._v("恢复数据， 大体流程如下图所示。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/MySQL/image-20240123152930717.png",alt:"image-20240123152930717"}})]),s._v(" "),t("p",[s._v("很明显，MySQL 崩溃恢复后，首先会获取日志检查点信息，随后根据日志检查点信息使用 "),t("code",[s._v("Redo Log")]),s._v(" 进行恢复。MySQL 崩溃或者宕机时事务未提交，则接下来使用 "),t("code",[s._v("Undo Log")]),s._v(" 回滚数据。如果在 MySQL 崩溃或者宕机时事务已经提交，则用 "),t("code",[s._v("Redo Log")]),s._v(" 恢复数据即可。")]),s._v(" "),t("p",[t("strong",[s._v("崩溃后的恢复为什么不用 "),t("code",[s._v("binlog")]),s._v("？")])]),s._v(" "),t("ol",[t("li",[s._v("这两者使用方式不一样"),t("code",[s._v("binlog")]),s._v("会记录表所有更改操作，包括更新删除数据，更改表结构等等，主要用于人工恢复数据，而 "),t("code",[s._v("redo log")]),s._v(" 对于我们是不可见的，它是 InnoDB 用于保证 "),t("code",[s._v("crash-safe")]),s._v(" 能力的，也就是在事务提交后 MySQL 崩溃的话，可以保证事务的持久性，即事务提交后其更改是永久性的。 一句话概括："),t("code",[s._v("binlog")]),s._v(" 是用作人工恢复数据，"),t("code",[s._v("redo log")]),s._v(" 是 MySQL 自己使用，用于保证在数据库崩溃时的事务持久性。")]),s._v(" "),t("li",[t("code",[s._v("redo log")]),s._v(" 是 InnoDB 引擎特有的，"),t("code",[s._v("binlog")]),s._v(" 是 MySQL 的 "),t("code",[s._v("Server")]),s._v(" 层实现的, 所有引擎都可以使用。")]),s._v(" "),t("li",[t("code",[s._v("redo log")]),s._v(" 是"),t("strong",[s._v("物理日志")]),s._v("，记录的是“在某个数据页上做了什么修改”，恢复的速度更快；"),t("code",[s._v("binlog")]),s._v(" 是"),t("strong",[s._v("逻辑日志")]),s._v("，记录的是这个语句的原始逻辑，比如“给 ID=2 这的 c 字段加 1 ” ；")]),s._v(" "),t("li",[t("code",[s._v("redo log")]),s._v(" 是"),t("strong",[s._v("循环写")]),s._v("的日志文件，"),t("code",[s._v("redo log")]),s._v(" 只会记录未刷盘的日志，已经刷入磁盘的数据都会从 "),t("code",[s._v("redo log")]),s._v(" 这个有限大小的日志文件里删除。"),t("code",[s._v("binlog")]),s._v(" 是"),t("strong",[s._v("追加日志")]),s._v("，保存的是"),t("strong",[s._v("全量")]),s._v("的日志。")]),s._v(" "),t("li",[s._v("最重要的是，当数据库 "),t("code",[s._v("crash")]),s._v(" 后，想要恢复未刷盘但已经写入 "),t("code",[s._v("redo log")]),s._v(" 和 "),t("code",[s._v("binlog")]),s._v(" 的数据到内存时，"),t("code",[s._v("binlog")]),s._v(" 是无法恢复的。虽然 "),t("code",[s._v("binlog")]),s._v(" 拥有全量的日志， 但没有一个标志让 InnoDB 判断哪些数据已经入表(写入磁盘)，哪些数据还没有。")])]),s._v(" "),t("h3",{attrs:{id:"redo-日志和-undo-日志的关系"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redo-日志和-undo-日志的关系"}},[s._v("#")]),s._v(" Redo 日志和 Undo 日志的关系")]),s._v(" "),t("p",[s._v("数据库崩溃重启后，需要先从 "),t("code",[s._v("redo log")]),s._v(" 中把未落盘的脏页数据恢复回来，重新写入磁盘，保证用户的数据不丢失。当然，在崩溃恢复中还需要把未提交的事务进行回滚操作。由于回滚操作需要 "),t("code",[s._v("undo log")]),s._v(" 日志支持，"),t("code",[s._v("undo log")]),s._v(" 日志的完整性和可靠性需要 "),t("code",[s._v("redo log")]),s._v(" 日志来保证，所以数据库崩溃需要先做 "),t("code",[s._v("redo log")]),s._v(" 数据恢复， 然后做 "),t("code",[s._v("undo log")]),s._v(" 回滚。")]),s._v(" "),t("p",[s._v("在事务执行过程中，除了记录 "),t("code",[s._v("redo")]),s._v(" 一些记录，还会记录 "),t("code",[s._v("undo log")]),s._v(" 日志。"),t("code",[s._v("Undo log")]),s._v(" 记录了数据每个操作前的状态，如果事务执行过程中需要回滚，就可以根据 "),t("code",[s._v("undo log")]),s._v(" 进行回滚操作。")]),s._v(" "),t("p",[s._v("因为 "),t("code",[s._v("redo log")]),s._v(" 是物理日志，记录的是数据库页的物理修改操作。所以 "),t("code",[s._v("undo log")]),s._v(" （可以看成数据库的数据）的写入也会伴随着 "),t("code",[s._v("redo log")]),s._v(" 的产生，这是因为 "),t("code",[s._v("undo log")]),s._v(" 也需要持久化的保护。")]),s._v(" "),t("p",[s._v("事务进行过程中，每次 sql 语句执行，都会记录 "),t("code",[s._v("undo log")]),s._v(" 和 "),t("code",[s._v("redo log")]),s._v("，然后更新数据形成脏页。事务执行 "),t("code",[s._v("COMMIT")]),s._v(" 操作时，会将本事务相关的所有 "),t("code",[s._v("redo log")]),s._v(" 进行落盘，只有所有的 "),t("code",[s._v("redo log")]),s._v(" 落盘成功，才算 "),t("code",[s._v("COMMIT")]),s._v(" 成功。然后内存中的 "),t("code",[s._v("undo log")]),s._v(" 和脏页按照同样的规则进行落盘。如果此时发生崩溃，则只使用 "),t("code",[s._v("redo log")]),s._v(" 恢复数据。")])])}),[],!1,null,null,null);t.default=e.exports}}]);