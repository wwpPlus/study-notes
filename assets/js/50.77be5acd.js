(window.webpackJsonp=window.webpackJsonp||[]).push([[50],{376:function(t,s,a){"use strict";a.r(s);var n=a(8),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"colossal简介"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#colossal简介"}},[t._v("#")]),t._v(" Colossal简介")]),t._v(" "),s("h2",{attrs:{id:"分布式训练"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#分布式训练"}},[t._v("#")]),t._v(" 分布式训练")]),t._v(" "),s("h3",{attrs:{id:"为什么需要分布式训练"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#为什么需要分布式训练"}},[t._v("#")]),t._v(" 为什么需要分布式训练")]),t._v(" "),s("ul",[s("li",[t._v("模型规模迅速增加：与较小的模型相比，超大型模型通常能提供更优越的性能。")])]),t._v(" "),s("p",[s("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/model_parameters.jpg",alt:"模型与参数量"}})]),t._v(" "),s("ul",[s("li",[s("p",[t._v("数据集规模迅速增加")])]),t._v(" "),s("li",[s("p",[t._v("计算能力越来越强：GPU是深度学习最常见的算力资源，GPU计算能力的提升使得我们能够更快地执行计算密\n集型任务。")])])]),t._v(" "),s("h3",{attrs:{id:"分布式训练的基本概念"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#分布式训练的基本概念"}},[t._v("#")]),t._v(" 分布式训练的基本概念")]),t._v(" "),s("p",[t._v("分布式训练需要多台机器/GPU。在训练期间，这些设备之间会有通信。")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("host: 主机(host)是通信网络中的主要设备。在初始化分布式环境时，经常需要它作为一个参数。")])]),t._v(" "),s("li",[s("p",[t._v("port: 这里的端口(port)主要是指主机上用于通信的主端口。")])]),t._v(" "),s("li",[s("p",[t._v("rank: 在网络中赋予设备的唯一ID。")])]),t._v(" "),s("li",[s("p",[t._v("world size: 网络中设备的数量。")])]),t._v(" "),s("li",[s("p",[t._v("process group: 进程组(process group)是一个通信网络，包括设备的一个子集。总是有一个默认的进程组，它包含所有的设备。一个子集的设备可以形成一个进程组，以便它们只在组内的设备之间进行通信。")])])]),t._v(" "),s("p",[t._v("假设有2台机器（也称为节点），每台机器有4个GPU。当在这两台机器上初始化分布式环境时，基本上启动了8个进程（每台机器上有4个进程），每个进程被绑定到一个 GPU 上。")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/distributed%20systems.jpg",alt:"分布式系统"}})]),t._v(" "),s("p",[t._v("可以创建一个新的进程组。这个新的进程组可以包含任何进程的子集。")]),t._v(" "),s("p",[t._v("在进程组中，各进程可以通过两种方式进行通信。")]),t._v(" "),s("ul",[s("li",[t._v("peer-to-peer: 一个进程向另一个进程发送数据。")]),t._v(" "),s("li",[t._v("collective: 一组进程一起执行分散、聚集、all-reduce、广播等操作。")])]),t._v(" "),s("p",[s("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/Collective%20communication.jpg",alt:"Collective communication"}})]),t._v(" "),s("h2",{attrs:{id:"关键技术-异构训练再升级"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#关键技术-异构训练再升级"}},[t._v("#")]),t._v(" 关键技术：异构训练再升级")]),t._v(" "),s("p",[t._v("使用单张消费级显卡训练 AI 大模型的最大困难在于显存容量极其有限，严重限制了可容纳的模型参数量。")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("微软 DeepSpeed 提出的 ZeRO-offload 方法，ZeRO-Offload 是一种通过将数据和计算从 GPU 卸载到 CPU，以此减少神经网络训练期间 GPU 内存占用的方法，该方法提供了更高的训练吞吐量，并避免了移动数据和在 CPU 上执行计算导致的减速问题。")])]),t._v(" "),s("li",[s("p",[t._v("但如下图左边所示，当 GPU 内存不足以满足其相应的模型数据要求时，即使当时 CPU 上仍有可用内存，系统也会崩溃。")])])]),t._v(" "),s("p",[s("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/ZeRO-offload.jpg",alt:"ZeRO-offload"}})]),t._v(" "),s("ul",[s("li",[s("p",[t._v("Colossal-AI 团队从头搭建了如 ZeRO 等核心关键技术，并针对 DeepSpeed 在 CPU 和 GPU 内存之间仅使用静态划分模型数据、对不同训练配置使用固定内存布局等问题做了诸多改进，进一步挖掘高效的 GPU 与 CPU 内存高效协同方案")])]),t._v(" "),s("li",[s("p",[t._v("Colossal-AI 设计的 Gemini，就像双子星一样，高效管理和利用 GPU 与 CPU 的异构内存，让张量在训练过程中动态分布在 CPU-GPU 的存储空间内，从而让模型训练突破 GPU 的内存墙。")])]),t._v(" "),s("li",[s("p",[t._v("利用深度学习网络训练过程的迭代特性，按迭代次数将训练分为 warmup 和 non-warmup 两个阶段。在初期 warmup 阶段，监测内存信息；在 non-warmup 阶段利用已收集的信息来高效移动张量，以达到最小化 CPU-GPU 数据移动的目的。")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("在大型网络训练初期，我们需要用较小的学习率先学n个step，能够防止一开始的时候模型对遇到的新数据过拟合，以改善后面的收敛效果，这个过程就是warmup（模型预热策略）")])]),t._v(" "),s("li",[s("p",[t._v("warmup：有助于减缓模型在初始阶段对mini-batch的提前过拟合现象，保持分布的平稳,有助于保持模型深层的稳定性")])])])])]),t._v(" "),s("p",[s("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/warmup_to_non-warmup.jpg",alt:"warmup_to_non-warmup"}})]),t._v(" "),s("p",[t._v("其中非模型的内存使用量其实难以获取，因为非模型数据的生存周期并不归用户管理，现有的深度学习框架没有暴露非模型数据的追踪接口给用户。其次，CUDA context 等非框架开销也需要统计。")]),t._v(" "),s("p",[t._v("Colossal-AI 通过采样方式在 warmup 阶段获得 CPU 和 GPU 内存的使用情况。非模型数据的使用可以通过统计两个时刻之间系统最大内存使用 - 模型内存使用获得。模型的内存使用情况可以通过查询内存管理器得知，如下图黑色实线所示。")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/sampling_warmup_cpu_gpu.jpg",alt:"sampling_warmup_cpu_gpu"}})]),t._v(" "),s("p",[t._v("而所有模型数据张量则交给内存管理器管理，每个张量标记一个状态信息，包括 HOLD，COMPUTE，FREE 等。并根据动态查询到的内存使用情况，不断动态转换张量状态，调整张量位置，最终实现对 GPU 显存和 CPU 内存的高效利用，实现在硬件极其有限的情况下，最大化模型容量和平衡训练速度，对于 AI 民主化和低成本微调大模型下游任务等意义巨大。")]),t._v(" "),s("h2",{attrs:{id:"模型训练优化方案"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#模型训练优化方案"}},[t._v("#")]),t._v(" 模型训练优化方案")]),t._v(" "),s("h3",{attrs:{id:"便捷高效并行扩展-多gpu"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#便捷高效并行扩展-多gpu"}},[t._v("#")]),t._v(" 便捷高效并行扩展（多GPU）")]),t._v(" "),s("p",[t._v("Colossal-AI 通过高效多维并行和异构并行等技术，让用户仅需极少量修改，即可高效快速部署 AI 大模型训练。")]),t._v(" "),s("p",[t._v("例如对于 GPT-3 这样的超大 AI 模型，相比英伟达方案，Colossal-AI 仅需一半的计算资源，即可启动训练；若使用相同计算资源，则能提速 11%，可降低 GPT-3 训练成本超百万美元。")]),t._v(" "),s("ol",[s("li",[s("p",[t._v("数据并行：将数据集分割成几个碎片，每个碎片被分配到一个设备上。这相当于沿批次维度对训练过程进行并行化。每个设备将持有一个完整的模型副本，并在分配的数据集碎片上进行训练。在反向传播之后，模型的梯度将被全部减少，以便在不同设备上的模型参数能够保持同步。")])]),t._v(" "),s("li",[s("p",[t._v("模型并行：在数据并行训练中，由于每个 GPU 持有整个模型权重的副本。这就会出现冗余问题。另一种并行模式是模型并行，即模型被分割并分布在一个设备阵列上。通常有两种类型的并行：张量并行和流水线并行。")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("张量并行训练是将一个张量沿特定维度分成 N 块，每个设备只持有整个张量的 1/N，同时不影响计算图的正确性。这需要额外的通信来确保结果的正确性。")])]),t._v(" "),s("li",[s("p",[t._v("流水线并行是在各层之间进行并行计算。模型按层分割成若干块，每块都交给一个设备。在前向传递过程中，每个设备将中间的激活传递给下一个阶段。在后向传递过程中，每个设备将输入张量的梯度传回给前一个流水线阶段。这允许设备同时进行计算，并增加了训练的吞吐量。流水线并行训练的一个缺点是，会有一些设备参与计算的冒泡时间，导致计算资源的浪费。")])])])]),t._v(" "),s("li",[s("p",[t._v("优化器相关的并行：目前这种并行最流行的方法是 ZeRO，即零冗余优化器。 ZeRO 在三个层面上工作，以消除内存冗余（ZeRO需要进行fp16训练）。")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("优化器状态在各进程中被划分。")])]),t._v(" "),s("li",[s("p",[t._v("用于更新模型权重的32位梯度也被划分，因此每个进程只存储与其优化器状态划分相对应的梯度。")])]),t._v(" "),s("li",[s("p",[t._v("16位模型参数在各进程中被划分。")])])])]),t._v(" "),s("li",[s("p",[t._v("异构系统的并行：依靠 CPU 甚至是 NVMe 磁盘来训练大型模型。主要的想法是，在不使用张量时，将其卸载回 CPU 内存或 NVMe 磁盘。通过使用异构系统架构，有可能在一台机器上容纳一个巨大的模型。")])])]),t._v(" "),s("p",[s("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/Parallelism%20of%20heterogeneous%20systems.jpg",alt:"Parallelism of heterogeneous systems"}})]),t._v(" "),s("h3",{attrs:{id:"其他优化方案"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#其他优化方案"}},[t._v("#")]),t._v(" 其他优化方案")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("自动混合精度训练 (AMP)：自动混合精度训练是混合 FP16 和 FP32 训练。")]),t._v(" "),s("ul",[s("li",[t._v("半精度浮点格式（FP16）具有较低的算法复杂度和较高的计算效率。此外，FP16 仅需要 FP32 所需的一半存储空间，并节省了内存和网络带宽，从而为大 batch size 和大模型提供了更多内存。然而，还有其他操作，如缩减，需要 FP32 的动态范围，以避免数值溢出/下溢。因此，引入自动混合精度，尝试将每个操作与其相应的数据类型相匹配，这可以减少内存占用并提高训练效率。")])])])]),t._v(" "),s("p",[s("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/AMP.jpg",alt:"AMP"}})]),t._v(" "),s("ul",[s("li",[s("p",[t._v("梯度累积：梯度累积是一种常见的增大训练 batch size 的方式。 在训练大模型时，内存经常会成为瓶颈，并且 batch size 通常会很小（如2），这导致收敛性无法保证。梯度累积将多次迭代的梯度累加，并仅在达到预设迭代次数时更新参数。")]),t._v(" "),s("ul",[s("li",[t._v("在 Colossal-AI 中使用梯度累积，仅需在 config中配置期望梯度累积的次数。"),s("code",[t._v("gradient_accumulation = 8")])])])]),t._v(" "),s("li",[s("p",[t._v("梯度裁剪：为了加快训练过程和寻求全局最优以获得更好的性能，通过控制学习率来调整训练中的下降速度。这使得梯度向量在每一步都能更好地统一。在这种情况下，下降速度可以按预期被控制。 因此，梯度裁剪，一种可以将梯度向量归一化，以将其限制在统一长度的技术。")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("要使用梯度裁剪，只需在配置文件中添加梯度裁剪范数即可。"),s("code",[t._v("clip_grad_norm = 1.0")])])]),t._v(" "),s("li",[s("p",[t._v("每个 GPU 只拥有线性层中权重的一部分参数。为了得到线性层权重的梯度向量的正确范数，每个 GPU 中的每个梯度向量的范数应该相加。更复杂的是，偏置的分布不同于权重的分布。通信组在求和运算中有所不同。")])])])])]),t._v(" "),s("p",[s("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/parameter%20distribution.jpg",alt:"Parameter distribution"}})]),t._v(" "),s("ul",[s("li",[s("p",[t._v("基于Chunk内存管理的零冗余优化器 (ZeRO)：零冗余优化器 (ZeRO) 通过对三个模型状态（优化器状态、梯度和参数）进行划分而不是复制他们，消除了数据并行进程中的内存冗余。该方法与传统的数据并行相比，内存效率得到了极大的提高，而计算粒度和通信效率得到了保留。")]),t._v(" "),s("ol",[s("li",[s("p",[t._v("分片优化器状态: 优化器状态 (如 Adam optimizer, 32位的权重, 以及一二阶动量估计) 被划分到各个进程中, 因此每个进程只更新其分区。")])]),t._v(" "),s("li",[s("p",[t._v("分片梯度: 在梯度在数据并行进程组内进行 reduction 后, 梯度张量也被划分，这样每个进程只存储与其划分的优化器状态对应的梯度。 注意, Colossal-AI 将梯度转换为 FP32 格式以参与更新参数。")])]),t._v(" "),s("li",[s("p",[t._v("分片参数: 16位的模型参数被划分到一个数据并行组的进程中。")])]),t._v(" "),s("li",[s("p",[t._v("Gemini: 对于参数、梯度、优化器状态的动态异构内存空间管理器。")])])])])]),t._v(" "),s("p",[t._v("在使用零冗余优化器 (ZeRO)时，通过切分参数的方式对模型进行分布式存储，这种方法的优点是每个节点的内存负载是完全均衡的。但是这种方式有很多缺点。首先，通信时需要申请一块临时内存用来通信，通信完毕释放，这回导致存在内存碎片化的问题。其次，以Tensor为粒度进行通信，会导致网络带宽无法充分利用。通常来说传输的消息长度越长带宽利用率越高。")]),t._v(" "),s("p",[t._v("利用Colossal-AI v0.1.8引入了Chunk机制，可以提升ZeRO的性能。通过将运算顺序上连续的一组参数存入一个Chunk中（Chunk即一段连续的内存空间），每个Chunk的大小相同。Chunk方式组织内存可以保证PCI-e和GPU-GPU之间网络带宽的高效利用，减小了通信次数，同时避免潜在的内存碎片。")]),t._v(" "),s("p",[t._v("Colossal-AI提供了轻量级的Chunk搜索机制，帮助用户自动找到内存碎片最小的Chunk尺寸。")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("NVMe offload：GPU显存限制了我们可以训练的模型规模，这称为GPU显存墙。如果我们将优化器状态 offload 到磁盘，就可以突破 GPU 内存墙。")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("NVMe的全称是Non-Volatile Memory Express，翻译过来就是非易失性内存主机控制器接口规范")])]),t._v(" "),s("li",[s("p",[t._v("Colossal-AI 实现了一个用户友好且高效的异步 Tensor I/O 库：TensorNVMe。有了这个库，我们可以简单地实现 NVMe offload。")])])])])]),t._v(" "),s("blockquote",[s("p",[t._v("该库与各种磁盘（HDD、SATA SSD 和 NVMe SSD）兼容。由于 HDD 或 SATA SSD 的 I/O 带宽较低，建议仅在 NVMe 磁盘上使用此库。")]),t._v(" "),s("p",[t._v("NVMe协议本质是上建立了多个计算机与存储设备的通路，从而提高读写数据的速度。在NVMe协议中，多个通路其实就是多个队列。在SATA中计算机与存储设备只能有一个队列，即使是多CPU情况下，所有请求只能经过这样一个狭窄的道路。而NVMe协议可以最多有64K个队列，每个CPU或者核心都可以有一个队列，这样并发程度大大提升，性能也就更高了。")])]),t._v(" "),s("ul",[s("li",[s("p",[t._v("ColoTensor是 ColossalAI 中张量的基本数据结构。 它是 torch.Tensor 的子类，可以当做 PyTorch Tensor使用，ColoTensor 包含额外的属性ColoTensorSpec 来描述张量的payload分布和计算模式")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("ProcessGroup：如何将进程组织为通信组。")]),t._v(" "),s("ul",[s("li",[t._v("ProcessGroup 类的一个实例描述了如何在进程组中组织进程。进程组内的进程可以一起参与同一个集合通信，比如allgather, allreduce等。进程组组织方式被张量的并行策略支配。")]),t._v(" "),s("li",[t._v("ColoTensor 的一个进程组由 tp_degree 和 dp_degree 两种配置定义")])])]),t._v(" "),s("li",[s("p",[t._v("Distributed Spec：张量如何在进程组之间分布。")]),t._v(" "),s("ul",[s("li",[t._v("张量在 DP 进程组之间的分布方式是自动导出的，不需要用户手动指定")]),t._v(" "),s("li",[t._v("在使用 Distributed Spec 时，只需要描述张量在 TP 进程组之间的分布方式即可。TP 进程组目前有两种分布式规范，即 ShardSpec和ReplicaSpec\n"),s("ul",[s("li",[t._v("ShardSpec 需要指定分区的维度索引 dim 和分区个数 num_partitions")]),t._v(" "),s("li",[t._v("TP进程组上不同的dist spec可以通过set_dist_spec()接口相互转换")])])])])]),t._v(" "),s("li",[s("p",[t._v("Compute Spec：计算过程中如何使用张量。")]),t._v(" "),s("ul",[s("li",[t._v("将作为module parameter的ColoTensor设置正确的Compute Pattern。可以触发正取的计算模式")])])])])])]),t._v(" "),s("h2",{attrs:{id:"colossal-ai-的使用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#colossal-ai-的使用"}},[t._v("#")]),t._v(" Colossal-AI 的使用")]),t._v(" "),s("h3",{attrs:{id:"colossal-ai-的工作流"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#colossal-ai-的工作流"}},[t._v("#")]),t._v(" Colossal-AI 的工作流")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/Colossal-AI%20workflow.jpg",alt:"Colossal-AI workflow"}})]),t._v(" "),s("ol",[s("li",[s("p",[t._v("准备一个配置文件，指定您要使用的功能和参数。")])]),t._v(" "),s("li",[s("p",[t._v("用 colossalai.launch 初始化分布式后端。")])]),t._v(" "),s("li",[s("p",[t._v("用 colossalai.initialize 将训练特征注入您的训练组件（如模型、优化器）中。")])]),t._v(" "),s("li",[s("p",[t._v("进行训练和测试。")])])]),t._v(" "),s("h3",{attrs:{id:"构建配置文件"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#构建配置文件"}},[t._v("#")]),t._v(" 构建配置文件")]),t._v(" "),s("p",[t._v("配置文件中指定参数")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# config.py 文件中设置 BATCH_SIZE超参数")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" colossalai\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" colossalai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" global_context "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" gpc\n\ncolossalai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("launch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("config"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./config.py'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# access your parameter")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("gpc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("config"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("BATCH_SIZE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"初始化"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#初始化"}},[t._v("#")]),t._v(" 初始化")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# initialize features")]),t._v("\nengine"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" train_dataloader"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" test_dataloader"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _ "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" colossalai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("initialize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                                                     optimizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                                                     criterion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                                                     train_dataloader"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                                                     test_dataloader"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"自动混合精度训练-amp"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#自动混合精度训练-amp"}},[t._v("#")]),t._v(" 自动混合精度训练 (AMP)")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用 Torch AMP 可选参数如init_scale(float, optional, default=2.**16): 初始缩放因子")]),t._v("\nfp16"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("dict")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    mode "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AMP_TYPE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("TORCH \n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"并行配置"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#并行配置"}},[t._v("#")]),t._v(" 并行配置")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("parallel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("dict")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n   pipeline"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("dict")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"size"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n   tensor"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("dict")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"size"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mode"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'1d'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("or")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2d'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("or")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2.5d'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("or")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'3d'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"kwargs"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Any"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"基于chunk内存管理的零冗余优化器-zero"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#基于chunk内存管理的零冗余优化器-zero"}},[t._v("#")]),t._v(" 基于Chunk内存管理的零冗余优化器 (ZeRO)")]),t._v(" "),s("p",[t._v("运用GeminiDDP的方式来使用基于Chunk内存管理的ZeRO，它使用 ZeRO-DP 和 Gemini，其中ZeRO 用于并行，Gemini 用于内存管理")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 确保模型是在 ColoInitContext 的上下文中初始化的")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" ColoInitContext"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cpu'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default_dist_spec"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("default_dist_spec"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default_pg"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("default_pg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  model "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" gpt2_medium"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("checkpoint"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("''' 模型参数如下 \n      hidden dim是DNN的隐藏维度。用户可以提供这个参数来加快搜索速度。 默认值 1024；\n      min_chunk_size_mb是以兆字节为单位的最小块大小。如果参数的总大小仍然小于最小块大小，则所有参数将被压缩为一个小块\n'''")]),t._v("\nchunk_manager "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" init_chunk_manager"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("module"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                   init_device"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                   hidden_dim"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("hidden_dim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                   search_range_mb"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("search_range_mb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                   min_chunk_size_mb"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("min_chunk_size_mb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ngemini_manager "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" GeminiManager"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("placement_policy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" chunk_manager"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ZeroDDP"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" gemini_manager"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("定义一个使用 Gemini + ZeRO DDP 的模型：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("gemini_zero_dpp")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Module"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ProcessGroup"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" placememt_policy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"auto"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    cai_version "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" colossalai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__version__\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cai_version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0.1.10"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" colossalai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallel "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" GeminiDDP\n        model "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" GeminiDDP"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                          device"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("get_current_device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                          placement_policy"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("placememt_policy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                          pin_memory"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                          search_range_mb"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cai_version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0.1.10"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cai_version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0.1.9"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" colossalai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gemini "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ChunkManager"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" GeminiManager\n        chunk_size "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChunkManager"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("search_chunk_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1024")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        gemini_manager "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" GeminiManager"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("placememt_policy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" chunk_manager"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        chunk_manager "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ChunkManager"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("chunk_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                     pg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                     enable_distributed_storage"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                            init_device"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("GeminiManager"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_default_device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("placememt_policy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        model "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ZeroDDP"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" gemini_manager"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("raise")]),t._v(" NotImplemented"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"CAI version ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("cai_version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(' is not supported"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" model\n")])])]),s("h3",{attrs:{id:"nvme-offload-异步-tensor-i-o-库"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#nvme-offload-异步-tensor-i-o-库"}},[t._v("#")]),t._v(" NVMe offload（异步 Tensor I/O 库）")]),t._v(" "),s("p",[t._v("使用前安装：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 目前实验平台装不上")]),t._v("\npip install packaging\npip install tensornvme\n")])])]),s("p",[t._v("Adam (CPUAdam 和 HybridAdam) 实现了优化器状态的 NVMe offload")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" colossalai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optimizer "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" CPUAdam"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" HybridAdam\n"),s("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n    nvme_offload_fraction 是要 offload 到 NVMe 的优化器状态的比例。\n    nvme_offload_dir 是保存 NVMe offload 文件的目录。如果 nvme_offload_dir 为 None，将使用随机临时目录\n'''")]),t._v("\noptimizer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" HybridAdam"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parameters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nvme_offload_fraction"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nvme_offload_dir"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("blockquote",[s("p",[t._v("它只会卸载在 CPU 上的优化器状态。这意味着它只会影响 CPU 训练或者使用卸载的 Zero/Gemini")])]),t._v(" "),s("h3",{attrs:{id:"colotensor"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#colotensor"}},[t._v("#")]),t._v(" ColoTensor")]),t._v(" "),s("p",[t._v("使用 tp_degree=4, dp_dgree=2 在 8 个 GPU 上初始化并Shard一个ColoTensor。 然后tensor被沿着 TP 进程组中的最后一个维度进行分片。 最后，我们沿着 TP 进程组中的第一个维度（dim 0）对其进行重新Shard。 注意观察每个张量的形状。")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("multiprocessing "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" mp\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" colossalai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("utils "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" free_port"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" print_rank_0\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" functools "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" partial\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" colossalai\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" colossalai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tensor "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ProcessGroup"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ColoTensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ColoTensorSpec"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ShardSpec"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ComputeSpec"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ComputePattern\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" colossalai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("utils "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" free_port\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("run_dist_tests")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rank"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" world_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" port"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    colossalai"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("launch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("config"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" rank"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rank"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" world_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("world_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" host"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'localhost'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" port"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("port"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" backend"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'nccl'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    pg "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ProcessGroup"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tp_degree"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dp_degree"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("manual_seed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    local_tensor "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("randn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    print_rank_0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"shape ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("local_tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(", ")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("local_tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    spec "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ColoTensorSpec"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ShardSpec"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dims"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_partitions"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("pg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tp_world_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ComputeSpec"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ComputePattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("TP1D"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    t1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ColoTensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_torch_tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("local_tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" spec"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    t1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" t1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_replicate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    print_rank_0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"shape ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("t1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(", ")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("t1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    spec2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ShardSpec"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("pg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tp_world_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    t1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_dist_spec"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("spec2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    print_rank_0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"shape ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("t1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(", ")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("t1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("test_dist_cases")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("world_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    run_func "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" partial"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("run_dist_tests"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" world_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("world_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" port"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("free_port"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    mp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spawn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("run_func"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nprocs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("world_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" __name__ "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'__main__'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    test_dist_cases"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);