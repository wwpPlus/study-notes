<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Colossal-AI | PZ文档</title>
    <meta name="generator" content="VuePress 1.9.9">
    <link rel="icon" href="/study-notes/img/logo.png">
    <script src="https://cdn.wwads.cn/js/makemoney.js" type="text/javascript"></script>
    <meta name="description" content="Java技术文档">
    <meta name="keywords" content="vuepress,theme,blog,vdoing">
    <meta name="theme-color" content="#11a8cd">
    <meta name="wwads-cn-verify" content="6c4b761a28b734fe93831e3fb400ce87">
    
    <link rel="preload" href="/study-notes/assets/css/0.styles.551071e8.css" as="style"><link rel="preload" href="/study-notes/assets/js/app.8e25b80d.js" as="script"><link rel="preload" href="/study-notes/assets/js/2.75e49976.js" as="script"><link rel="preload" href="/study-notes/assets/js/50.77be5acd.js" as="script"><link rel="prefetch" href="/study-notes/assets/js/10.cd57f469.js"><link rel="prefetch" href="/study-notes/assets/js/11.6f82fa14.js"><link rel="prefetch" href="/study-notes/assets/js/12.42acabbb.js"><link rel="prefetch" href="/study-notes/assets/js/13.245cf1b9.js"><link rel="prefetch" href="/study-notes/assets/js/14.030717ae.js"><link rel="prefetch" href="/study-notes/assets/js/15.cdf354df.js"><link rel="prefetch" href="/study-notes/assets/js/16.e6d5fb47.js"><link rel="prefetch" href="/study-notes/assets/js/17.22193e95.js"><link rel="prefetch" href="/study-notes/assets/js/18.5eed5ae6.js"><link rel="prefetch" href="/study-notes/assets/js/19.1a6e6d5a.js"><link rel="prefetch" href="/study-notes/assets/js/20.29b0b965.js"><link rel="prefetch" href="/study-notes/assets/js/21.4ececdf7.js"><link rel="prefetch" href="/study-notes/assets/js/22.cb3bf150.js"><link rel="prefetch" href="/study-notes/assets/js/23.0e98bd37.js"><link rel="prefetch" href="/study-notes/assets/js/24.15884ade.js"><link rel="prefetch" href="/study-notes/assets/js/25.dcd75ef0.js"><link rel="prefetch" href="/study-notes/assets/js/26.824a8a9e.js"><link rel="prefetch" href="/study-notes/assets/js/27.4d3b91d1.js"><link rel="prefetch" href="/study-notes/assets/js/28.8964eb3d.js"><link rel="prefetch" href="/study-notes/assets/js/29.2c18eb50.js"><link rel="prefetch" href="/study-notes/assets/js/3.6f8e2fe7.js"><link rel="prefetch" href="/study-notes/assets/js/30.66a4f3cc.js"><link rel="prefetch" href="/study-notes/assets/js/31.d4ea88f0.js"><link rel="prefetch" href="/study-notes/assets/js/32.c7bee369.js"><link rel="prefetch" href="/study-notes/assets/js/33.735f589d.js"><link rel="prefetch" href="/study-notes/assets/js/34.a25eb313.js"><link rel="prefetch" href="/study-notes/assets/js/35.e8982b5c.js"><link rel="prefetch" href="/study-notes/assets/js/36.b197366f.js"><link rel="prefetch" href="/study-notes/assets/js/37.8b9b74a9.js"><link rel="prefetch" href="/study-notes/assets/js/38.1d0ab6e3.js"><link rel="prefetch" href="/study-notes/assets/js/39.b3db9e36.js"><link rel="prefetch" href="/study-notes/assets/js/4.d87e94ad.js"><link rel="prefetch" href="/study-notes/assets/js/40.2c8f3008.js"><link rel="prefetch" href="/study-notes/assets/js/41.1121a1f9.js"><link rel="prefetch" href="/study-notes/assets/js/42.42dbe2a6.js"><link rel="prefetch" href="/study-notes/assets/js/43.a89d998f.js"><link rel="prefetch" href="/study-notes/assets/js/44.33110d45.js"><link rel="prefetch" href="/study-notes/assets/js/45.12c2e422.js"><link rel="prefetch" href="/study-notes/assets/js/46.32b47d37.js"><link rel="prefetch" href="/study-notes/assets/js/47.1e7fe211.js"><link rel="prefetch" href="/study-notes/assets/js/48.d289f106.js"><link rel="prefetch" href="/study-notes/assets/js/49.9deb6b47.js"><link rel="prefetch" href="/study-notes/assets/js/5.d4912748.js"><link rel="prefetch" href="/study-notes/assets/js/51.6beb352f.js"><link rel="prefetch" href="/study-notes/assets/js/52.7e6607fc.js"><link rel="prefetch" href="/study-notes/assets/js/53.3c31dc68.js"><link rel="prefetch" href="/study-notes/assets/js/54.01b72ef9.js"><link rel="prefetch" href="/study-notes/assets/js/55.01c18821.js"><link rel="prefetch" href="/study-notes/assets/js/56.60d1fc93.js"><link rel="prefetch" href="/study-notes/assets/js/57.ea2e1370.js"><link rel="prefetch" href="/study-notes/assets/js/58.e063f1c5.js"><link rel="prefetch" href="/study-notes/assets/js/59.ac5c2f70.js"><link rel="prefetch" href="/study-notes/assets/js/6.fe6c88c8.js"><link rel="prefetch" href="/study-notes/assets/js/60.ddc89e73.js"><link rel="prefetch" href="/study-notes/assets/js/61.1611b6bd.js"><link rel="prefetch" href="/study-notes/assets/js/62.82117431.js"><link rel="prefetch" href="/study-notes/assets/js/7.6e9a0fda.js"><link rel="prefetch" href="/study-notes/assets/js/8.1e978ed7.js"><link rel="prefetch" href="/study-notes/assets/js/9.515d3a36.js">
    <link rel="stylesheet" href="/study-notes/assets/css/0.styles.551071e8.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/study-notes/" class="home-link router-link-active"><img src="/study-notes/img/logo.png" alt="PZ文档" class="logo"> <span class="site-name can-hide">PZ文档</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/study-notes/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><a href="/study-notes/pages/d2f50e/" class="link-title">前端</a> <span class="title" style="display:none;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端基础</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/study-notes/pages/d2f50e/" class="nav-link">HTML</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/fea2d7/" class="nav-link">CSS</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/8d6d1a/" class="nav-link">JavaScript</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/3aa5d6/" class="nav-link">ES6</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/5326c5/" class="nav-link">Npm</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/b8acc7/" class="nav-link">网络</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/5332ff/" class="nav-link">第三方库</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/e2ab93/" class="nav-link">Promise</a></li></ul></li><li class="dropdown-item"><h4>前端进阶</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/study-notes/pages/8b6af1/" class="nav-link">Nodejs</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/b5d3e4/" class="nav-link">Webpack</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/26c58d/" class="nav-link">Vue</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/f5fa28/" class="nav-link">Vue3</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/5f0e92/" class="nav-link">Threejs</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/351a94/" class="nav-link">TypeScript</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/6a7c67/" class="nav-link">浏览器</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/46afd7/" class="nav-link">工程化</a></li></ul></li><li class="dropdown-item"><h4>前端面试题</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/study-notes/pages/e3260c/" class="nav-link">HTML</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/478903/" class="nav-link">CSS</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/77bb95/" class="nav-link">JavaScript</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/f9216a/" class="nav-link">Promise</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/4b8e23/" class="nav-link">网络</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/bca98d/" class="nav-link">工程化</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/678074/" class="nav-link">Vue</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/70f2f1/" class="nav-link">浏览器</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Java基础" class="dropdown-title"><a href="/study-notes/pages/7419ce/" class="link-title">Java基础</a> <span class="title" style="display:none;">Java基础</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/00ce2a/" class="nav-link">Linux</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/c81b2a/" class="nav-link">设计模式</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/7419ce/" class="nav-link">并发编程</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/fba387/" class="nav-link">Spring</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/236603/" class="nav-link">MySQL</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/d0b82f/" class="nav-link">JVM</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="分布式" class="dropdown-title"><a href="/study-notes/pages/6e924b/" class="link-title">分布式</a> <span class="title" style="display:none;">分布式</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/6e924b/" class="nav-link">Redis</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/6a436f/" class="nav-link">Zookeeper</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/6c832f/" class="nav-link">RabbitMQ</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/a01b22/" class="nav-link">RocketMQ</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/3634f1/" class="nav-link">Dubbo</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/e06812/" class="nav-link">Netty</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="微服务" class="dropdown-title"><a href="/study-notes/pages/debdbe/" class="link-title">微服务</a> <span class="title" style="display:none;">微服务</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/debdbe/" class="nav-link">SpringBoot</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="运维" class="dropdown-title"><a href="/study-notes/pages/28c483/" class="link-title">运维</a> <span class="title" style="display:none;">运维</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/28c483/" class="nav-link">Docker</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="算法笔试" class="dropdown-title"><a href="/study-notes/pages/4b7495/" class="link-title">算法笔试</a> <span class="title" style="display:none;">算法笔试</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/4dde8d/" class="nav-link">LeetCode</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/b9c7ad/" class="nav-link">Acwing</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/4b7495/" class="nav-link">剑指Offer1</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/0a5a03/" class="nav-link">剑指Offer2</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="AI" class="dropdown-title"><a href="/study-notes/pages/a2ac81/" aria-current="page" class="link-title router-link-exact-active router-link-active">AI</a> <span class="title" style="display:none;">AI</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/a2ac81/" aria-current="page" class="nav-link router-link-exact-active router-link-active">Colossal-AI</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/d067ec/" class="nav-link">YOLO</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/c3610e/" class="nav-link">EfficientNet</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="项目经历" class="dropdown-title"><a href="/study-notes/pages/1e0b40/" class="link-title">项目经历</a> <span class="title" style="display:none;">项目经历</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/1e0b40/" class="nav-link">简历</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/13921d/" class="nav-link">软件杯</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/ef3306/" class="nav-link">科研创新实践平台</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/5c0bdb/" class="nav-link">微应用设计平台</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/6e6f76/" class="nav-link">微服务房屋租赁系统</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/a33dfc/" class="nav-link">分布式抽奖系统</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="工具" class="dropdown-title"><a href="/study-notes/pages/6d4d7f/" class="link-title">工具</a> <span class="title" style="display:none;">工具</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/6d4d7f/" class="nav-link">git</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/be1cd8/" class="nav-link">快捷键</a></li></ul></div></div> <a href="https://github.com/wwpPlus" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><!----> <nav class="nav-links"><div class="nav-item"><a href="/study-notes/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><a href="/study-notes/pages/d2f50e/" class="link-title">前端</a> <span class="title" style="display:none;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端基础</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/study-notes/pages/d2f50e/" class="nav-link">HTML</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/fea2d7/" class="nav-link">CSS</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/8d6d1a/" class="nav-link">JavaScript</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/3aa5d6/" class="nav-link">ES6</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/5326c5/" class="nav-link">Npm</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/b8acc7/" class="nav-link">网络</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/5332ff/" class="nav-link">第三方库</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/e2ab93/" class="nav-link">Promise</a></li></ul></li><li class="dropdown-item"><h4>前端进阶</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/study-notes/pages/8b6af1/" class="nav-link">Nodejs</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/b5d3e4/" class="nav-link">Webpack</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/26c58d/" class="nav-link">Vue</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/f5fa28/" class="nav-link">Vue3</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/5f0e92/" class="nav-link">Threejs</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/351a94/" class="nav-link">TypeScript</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/6a7c67/" class="nav-link">浏览器</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/46afd7/" class="nav-link">工程化</a></li></ul></li><li class="dropdown-item"><h4>前端面试题</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/study-notes/pages/e3260c/" class="nav-link">HTML</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/478903/" class="nav-link">CSS</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/77bb95/" class="nav-link">JavaScript</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/f9216a/" class="nav-link">Promise</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/4b8e23/" class="nav-link">网络</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/bca98d/" class="nav-link">工程化</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/678074/" class="nav-link">Vue</a></li><li class="dropdown-subitem"><a href="/study-notes/pages/70f2f1/" class="nav-link">浏览器</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Java基础" class="dropdown-title"><a href="/study-notes/pages/7419ce/" class="link-title">Java基础</a> <span class="title" style="display:none;">Java基础</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/00ce2a/" class="nav-link">Linux</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/c81b2a/" class="nav-link">设计模式</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/7419ce/" class="nav-link">并发编程</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/fba387/" class="nav-link">Spring</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/236603/" class="nav-link">MySQL</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/d0b82f/" class="nav-link">JVM</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="分布式" class="dropdown-title"><a href="/study-notes/pages/6e924b/" class="link-title">分布式</a> <span class="title" style="display:none;">分布式</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/6e924b/" class="nav-link">Redis</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/6a436f/" class="nav-link">Zookeeper</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/6c832f/" class="nav-link">RabbitMQ</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/a01b22/" class="nav-link">RocketMQ</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/3634f1/" class="nav-link">Dubbo</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/e06812/" class="nav-link">Netty</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="微服务" class="dropdown-title"><a href="/study-notes/pages/debdbe/" class="link-title">微服务</a> <span class="title" style="display:none;">微服务</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/debdbe/" class="nav-link">SpringBoot</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="运维" class="dropdown-title"><a href="/study-notes/pages/28c483/" class="link-title">运维</a> <span class="title" style="display:none;">运维</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/28c483/" class="nav-link">Docker</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="算法笔试" class="dropdown-title"><a href="/study-notes/pages/4b7495/" class="link-title">算法笔试</a> <span class="title" style="display:none;">算法笔试</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/4dde8d/" class="nav-link">LeetCode</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/b9c7ad/" class="nav-link">Acwing</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/4b7495/" class="nav-link">剑指Offer1</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/0a5a03/" class="nav-link">剑指Offer2</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="AI" class="dropdown-title"><a href="/study-notes/pages/a2ac81/" aria-current="page" class="link-title router-link-exact-active router-link-active">AI</a> <span class="title" style="display:none;">AI</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/a2ac81/" aria-current="page" class="nav-link router-link-exact-active router-link-active">Colossal-AI</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/d067ec/" class="nav-link">YOLO</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/c3610e/" class="nav-link">EfficientNet</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="项目经历" class="dropdown-title"><a href="/study-notes/pages/1e0b40/" class="link-title">项目经历</a> <span class="title" style="display:none;">项目经历</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/1e0b40/" class="nav-link">简历</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/13921d/" class="nav-link">软件杯</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/ef3306/" class="nav-link">科研创新实践平台</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/5c0bdb/" class="nav-link">微应用设计平台</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/6e6f76/" class="nav-link">微服务房屋租赁系统</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/a33dfc/" class="nav-link">分布式抽奖系统</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="工具" class="dropdown-title"><a href="/study-notes/pages/6d4d7f/" class="link-title">工具</a> <span class="title" style="display:none;">工具</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/study-notes/pages/6d4d7f/" class="nav-link">git</a></li><li class="dropdown-item"><!----> <a href="/study-notes/pages/be1cd8/" class="nav-link">快捷键</a></li></ul></div></div> <a href="https://github.com/wwpPlus" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>视觉算法</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/study-notes/pages/d067ec/" class="sidebar-link">YOLO</a></li><li><a href="/study-notes/pages/c3610e/" class="sidebar-link">EfficientNet</a></li><li><a href="/study-notes/pages/a2ac81/" aria-current="page" class="active sidebar-link">Colossal-AI</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/study-notes/pages/a2ac81/#分布式训练" class="sidebar-link">分布式训练</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/study-notes/pages/a2ac81/#为什么需要分布式训练" class="sidebar-link">为什么需要分布式训练</a></li><li class="sidebar-sub-header level3"><a href="/study-notes/pages/a2ac81/#分布式训练的基本概念" class="sidebar-link">分布式训练的基本概念</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/study-notes/pages/a2ac81/#关键技术-异构训练再升级" class="sidebar-link">关键技术：异构训练再升级</a></li><li class="sidebar-sub-header level2"><a href="/study-notes/pages/a2ac81/#模型训练优化方案" class="sidebar-link">模型训练优化方案</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/study-notes/pages/a2ac81/#便捷高效并行扩展-多gpu" class="sidebar-link">便捷高效并行扩展（多GPU）</a></li><li class="sidebar-sub-header level3"><a href="/study-notes/pages/a2ac81/#其他优化方案" class="sidebar-link">其他优化方案</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/study-notes/pages/a2ac81/#colossal-ai-的使用" class="sidebar-link">Colossal-AI 的使用</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/study-notes/pages/a2ac81/#colossal-ai-的工作流" class="sidebar-link">Colossal-AI 的工作流</a></li><li class="sidebar-sub-header level3"><a href="/study-notes/pages/a2ac81/#构建配置文件" class="sidebar-link">构建配置文件</a></li><li class="sidebar-sub-header level3"><a href="/study-notes/pages/a2ac81/#初始化" class="sidebar-link">初始化</a></li><li class="sidebar-sub-header level3"><a href="/study-notes/pages/a2ac81/#自动混合精度训练-amp" class="sidebar-link">自动混合精度训练 (AMP)</a></li><li class="sidebar-sub-header level3"><a href="/study-notes/pages/a2ac81/#并行配置" class="sidebar-link">并行配置</a></li><li class="sidebar-sub-header level3"><a href="/study-notes/pages/a2ac81/#基于chunk内存管理的零冗余优化器-zero" class="sidebar-link">基于Chunk内存管理的零冗余优化器 (ZeRO)</a></li><li class="sidebar-sub-header level3"><a href="/study-notes/pages/a2ac81/#nvme-offload-异步-tensor-i-o-库" class="sidebar-link">NVMe offload（异步 Tensor I/O 库）</a></li><li class="sidebar-sub-header level3"><a href="/study-notes/pages/a2ac81/#colotensor" class="sidebar-link">ColoTensor</a></li></ul></li></ul></li></ul></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/study-notes/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><span data-v-06225672>视觉算法</span></li><li data-v-06225672><span data-v-06225672>视觉算法</span></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://gitee.com/star_wwp" target="_blank" title="作者" class="beLink" data-v-06225672>wwp</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2023-11-16</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABKFJREFUSA3tVl1oFVcQnrMbrak3QUgkya1akpJYcrUtIqW1JvFBE9LiQ5v6JmJpolbMg32rVrhgoYK0QiMY6i9Y6EMaW5D+xFJaTYItIuK2Kr3+BJNwkxBj05sQY3b3nM6cs2dv9t7NT/vQJw/sndk5M/PNzJkzewGerP+pAmy+ON8lLzUJgA8ZYxYIYZmGYRnctDaWvJJAmTtfP1pvXsBCCPP8QFcCaRkZYACgDZFO4stNIcBCajEOlmmC9XpJ9bAGCaPaPmzPl32dvLSVu3BWCTQs0XQQ6g0DYgwLIoAZbBCdW/i+781o1VVlm/410mw4h06Y7bIPHNyWDyL4FHkX03Q8SrzNhZTZriieckWt7cL6MM85YcLpsi/7O9/iXFT6MswI0DmmpkSaJ0qLxFIm3+i1THHB3zmBH3PYx9CcykcLOeQVVa7QtdxTgQgEleX2AjHYfwA+2ddV77ruGoJUbhGDI09YSNXyMpUt5ylOzxgbUmtOp7NmbNt8v3arjTBfYELmLUV+M+nSawNNAUqpT3ClJWg5I3BLT+cGW/DXNGCa6tx1aakCGEigArTn4TDIPdrXXYKCZNrHLMCOEPvHBlLQ99s9eHB7EB6NTki73CVPQ2F5MSx/uRQixfmq7rK0wYD8w8E905bnPDfwoWs/rfv93NWN/ZfvwsLIU7A09gxECyISeGJkHAau98L97tuw7NXnoPyNF8FcYGLGKsOs0mN3OEyec9esGW/ZEl945dTP34wlR2FZVQWU1q0Cw8Tr7p+hgLLNL0FPxx/Q35mA8aEUrH6nCgwEl0tn7wUiZYJnNRh6DK4UH/k0lfyrsBKdPVv/AriGIQcEDQZ65LBAGe2Rzui9Ybjz7XUppz1/uKBbyVPGkN3ZAeC6hr0x7Nr38N5+EqkoOm17xpoqR9ohQF55ERSvr4Dkr3chNfC3DMzGJlNBElW8w9nsGQvhNGIzDkXzCg8cLK951xHsFBlTJspJNi3ZFIMF2AeDV3q8DNOB+YHi6QTrChDIWDBRi5U5f+ZMfJLu3ccrqxtdxk4SKH336LFxSmkqefwU5T8fhdSdQf9IVKD6aNiwI/hnmcAZ91isYMJIaCUCx9W098+LgruikeTqzqqxKPUwqJyCPJiyemVVZBOijDGjD38Os0jOiSPL1z3SPjXNANbiNPXAdzTfukjjuknNBbyz3nwgTd3AVFqUJ5hpHlq9MveLnWwttUfoygBmvVjuikxND3znrhsELnZk7k+OjIGxeNEkomyLVta0xxn+HZhjBc4YZ/AFjHjz9u3xRZl2BN4aq9nFwWh16IrQ1aHHEd3j1+4/dB9OtH4e29A2H1DyHQRmOSfQZ1Fy7MHBTGB6J/Djq6p3OxyO2cB+4Car7v/o3GXgfAkj23+x9ID1Teoamo/SXcbvSf2PX7Vc8DdCmE1vN9di+32P9/5YR3vLnhCVGUWBjEkr3yh4H8v9CzmsbdhzOKzsJKM90iFdaTMjRPhGVsakRvOaRidljo6H6G7j+ctrJpsP+4COhDIl0La2+FS4+5mlocBaXY5QnGZysIBYoeSsl5qQzrSj/cgNrfuEzlWBfwA+EjrZyWUvpAAAAABJRU5ErkJggg==">Colossal-AI<!----></h1>  <div class="theme-vdoing-content content__default"><h1 id="colossal简介"><a href="#colossal简介" class="header-anchor">#</a> Colossal简介</h1> <h2 id="分布式训练"><a href="#分布式训练" class="header-anchor">#</a> 分布式训练</h2> <h3 id="为什么需要分布式训练"><a href="#为什么需要分布式训练" class="header-anchor">#</a> 为什么需要分布式训练</h3> <ul><li>模型规模迅速增加：与较小的模型相比，超大型模型通常能提供更优越的性能。</li></ul> <p><img src="https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/model_parameters.jpg" alt="模型与参数量"></p> <ul><li><p>数据集规模迅速增加</p></li> <li><p>计算能力越来越强：GPU是深度学习最常见的算力资源，GPU计算能力的提升使得我们能够更快地执行计算密
集型任务。</p></li></ul> <h3 id="分布式训练的基本概念"><a href="#分布式训练的基本概念" class="header-anchor">#</a> 分布式训练的基本概念</h3> <p>分布式训练需要多台机器/GPU。在训练期间，这些设备之间会有通信。</p> <ul><li><p>host: 主机(host)是通信网络中的主要设备。在初始化分布式环境时，经常需要它作为一个参数。</p></li> <li><p>port: 这里的端口(port)主要是指主机上用于通信的主端口。</p></li> <li><p>rank: 在网络中赋予设备的唯一ID。</p></li> <li><p>world size: 网络中设备的数量。</p></li> <li><p>process group: 进程组(process group)是一个通信网络，包括设备的一个子集。总是有一个默认的进程组，它包含所有的设备。一个子集的设备可以形成一个进程组，以便它们只在组内的设备之间进行通信。</p></li></ul> <p>假设有2台机器（也称为节点），每台机器有4个GPU。当在这两台机器上初始化分布式环境时，基本上启动了8个进程（每台机器上有4个进程），每个进程被绑定到一个 GPU 上。</p> <p><img src="https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/distributed%20systems.jpg" alt="分布式系统"></p> <p>可以创建一个新的进程组。这个新的进程组可以包含任何进程的子集。</p> <p>在进程组中，各进程可以通过两种方式进行通信。</p> <ul><li>peer-to-peer: 一个进程向另一个进程发送数据。</li> <li>collective: 一组进程一起执行分散、聚集、all-reduce、广播等操作。</li></ul> <p><img src="https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/Collective%20communication.jpg" alt="Collective communication"></p> <h2 id="关键技术-异构训练再升级"><a href="#关键技术-异构训练再升级" class="header-anchor">#</a> 关键技术：异构训练再升级</h2> <p>使用单张消费级显卡训练 AI 大模型的最大困难在于显存容量极其有限，严重限制了可容纳的模型参数量。</p> <ul><li><p>微软 DeepSpeed 提出的 ZeRO-offload 方法，ZeRO-Offload 是一种通过将数据和计算从 GPU 卸载到 CPU，以此减少神经网络训练期间 GPU 内存占用的方法，该方法提供了更高的训练吞吐量，并避免了移动数据和在 CPU 上执行计算导致的减速问题。</p></li> <li><p>但如下图左边所示，当 GPU 内存不足以满足其相应的模型数据要求时，即使当时 CPU 上仍有可用内存，系统也会崩溃。</p></li></ul> <p><img src="https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/ZeRO-offload.jpg" alt="ZeRO-offload"></p> <ul><li><p>Colossal-AI 团队从头搭建了如 ZeRO 等核心关键技术，并针对 DeepSpeed 在 CPU 和 GPU 内存之间仅使用静态划分模型数据、对不同训练配置使用固定内存布局等问题做了诸多改进，进一步挖掘高效的 GPU 与 CPU 内存高效协同方案</p></li> <li><p>Colossal-AI 设计的 Gemini，就像双子星一样，高效管理和利用 GPU 与 CPU 的异构内存，让张量在训练过程中动态分布在 CPU-GPU 的存储空间内，从而让模型训练突破 GPU 的内存墙。</p></li> <li><p>利用深度学习网络训练过程的迭代特性，按迭代次数将训练分为 warmup 和 non-warmup 两个阶段。在初期 warmup 阶段，监测内存信息；在 non-warmup 阶段利用已收集的信息来高效移动张量，以达到最小化 CPU-GPU 数据移动的目的。</p> <ul><li><p>在大型网络训练初期，我们需要用较小的学习率先学n个step，能够防止一开始的时候模型对遇到的新数据过拟合，以改善后面的收敛效果，这个过程就是warmup（模型预热策略）</p></li> <li><p>warmup：有助于减缓模型在初始阶段对mini-batch的提前过拟合现象，保持分布的平稳,有助于保持模型深层的稳定性</p></li></ul></li></ul> <p><img src="https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/warmup_to_non-warmup.jpg" alt="warmup_to_non-warmup"></p> <p>其中非模型的内存使用量其实难以获取，因为非模型数据的生存周期并不归用户管理，现有的深度学习框架没有暴露非模型数据的追踪接口给用户。其次，CUDA context 等非框架开销也需要统计。</p> <p>Colossal-AI 通过采样方式在 warmup 阶段获得 CPU 和 GPU 内存的使用情况。非模型数据的使用可以通过统计两个时刻之间系统最大内存使用 - 模型内存使用获得。模型的内存使用情况可以通过查询内存管理器得知，如下图黑色实线所示。</p> <p><img src="https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/sampling_warmup_cpu_gpu.jpg" alt="sampling_warmup_cpu_gpu"></p> <p>而所有模型数据张量则交给内存管理器管理，每个张量标记一个状态信息，包括 HOLD，COMPUTE，FREE 等。并根据动态查询到的内存使用情况，不断动态转换张量状态，调整张量位置，最终实现对 GPU 显存和 CPU 内存的高效利用，实现在硬件极其有限的情况下，最大化模型容量和平衡训练速度，对于 AI 民主化和低成本微调大模型下游任务等意义巨大。</p> <h2 id="模型训练优化方案"><a href="#模型训练优化方案" class="header-anchor">#</a> 模型训练优化方案</h2> <h3 id="便捷高效并行扩展-多gpu"><a href="#便捷高效并行扩展-多gpu" class="header-anchor">#</a> 便捷高效并行扩展（多GPU）</h3> <p>Colossal-AI 通过高效多维并行和异构并行等技术，让用户仅需极少量修改，即可高效快速部署 AI 大模型训练。</p> <p>例如对于 GPT-3 这样的超大 AI 模型，相比英伟达方案，Colossal-AI 仅需一半的计算资源，即可启动训练；若使用相同计算资源，则能提速 11%，可降低 GPT-3 训练成本超百万美元。</p> <ol><li><p>数据并行：将数据集分割成几个碎片，每个碎片被分配到一个设备上。这相当于沿批次维度对训练过程进行并行化。每个设备将持有一个完整的模型副本，并在分配的数据集碎片上进行训练。在反向传播之后，模型的梯度将被全部减少，以便在不同设备上的模型参数能够保持同步。</p></li> <li><p>模型并行：在数据并行训练中，由于每个 GPU 持有整个模型权重的副本。这就会出现冗余问题。另一种并行模式是模型并行，即模型被分割并分布在一个设备阵列上。通常有两种类型的并行：张量并行和流水线并行。</p> <ul><li><p>张量并行训练是将一个张量沿特定维度分成 N 块，每个设备只持有整个张量的 1/N，同时不影响计算图的正确性。这需要额外的通信来确保结果的正确性。</p></li> <li><p>流水线并行是在各层之间进行并行计算。模型按层分割成若干块，每块都交给一个设备。在前向传递过程中，每个设备将中间的激活传递给下一个阶段。在后向传递过程中，每个设备将输入张量的梯度传回给前一个流水线阶段。这允许设备同时进行计算，并增加了训练的吞吐量。流水线并行训练的一个缺点是，会有一些设备参与计算的冒泡时间，导致计算资源的浪费。</p></li></ul></li> <li><p>优化器相关的并行：目前这种并行最流行的方法是 ZeRO，即零冗余优化器。 ZeRO 在三个层面上工作，以消除内存冗余（ZeRO需要进行fp16训练）。</p> <ul><li><p>优化器状态在各进程中被划分。</p></li> <li><p>用于更新模型权重的32位梯度也被划分，因此每个进程只存储与其优化器状态划分相对应的梯度。</p></li> <li><p>16位模型参数在各进程中被划分。</p></li></ul></li> <li><p>异构系统的并行：依靠 CPU 甚至是 NVMe 磁盘来训练大型模型。主要的想法是，在不使用张量时，将其卸载回 CPU 内存或 NVMe 磁盘。通过使用异构系统架构，有可能在一台机器上容纳一个巨大的模型。</p></li></ol> <p><img src="https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/Parallelism%20of%20heterogeneous%20systems.jpg" alt="Parallelism of heterogeneous systems"></p> <h3 id="其他优化方案"><a href="#其他优化方案" class="header-anchor">#</a> 其他优化方案</h3> <ul><li><p>自动混合精度训练 (AMP)：自动混合精度训练是混合 FP16 和 FP32 训练。</p> <ul><li>半精度浮点格式（FP16）具有较低的算法复杂度和较高的计算效率。此外，FP16 仅需要 FP32 所需的一半存储空间，并节省了内存和网络带宽，从而为大 batch size 和大模型提供了更多内存。然而，还有其他操作，如缩减，需要 FP32 的动态范围，以避免数值溢出/下溢。因此，引入自动混合精度，尝试将每个操作与其相应的数据类型相匹配，这可以减少内存占用并提高训练效率。</li></ul></li></ul> <p><img src="https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/AMP.jpg" alt="AMP"></p> <ul><li><p>梯度累积：梯度累积是一种常见的增大训练 batch size 的方式。 在训练大模型时，内存经常会成为瓶颈，并且 batch size 通常会很小（如2），这导致收敛性无法保证。梯度累积将多次迭代的梯度累加，并仅在达到预设迭代次数时更新参数。</p> <ul><li>在 Colossal-AI 中使用梯度累积，仅需在 config中配置期望梯度累积的次数。<code>gradient_accumulation = 8</code></li></ul></li> <li><p>梯度裁剪：为了加快训练过程和寻求全局最优以获得更好的性能，通过控制学习率来调整训练中的下降速度。这使得梯度向量在每一步都能更好地统一。在这种情况下，下降速度可以按预期被控制。 因此，梯度裁剪，一种可以将梯度向量归一化，以将其限制在统一长度的技术。</p> <ul><li><p>要使用梯度裁剪，只需在配置文件中添加梯度裁剪范数即可。<code>clip_grad_norm = 1.0</code></p></li> <li><p>每个 GPU 只拥有线性层中权重的一部分参数。为了得到线性层权重的梯度向量的正确范数，每个 GPU 中的每个梯度向量的范数应该相加。更复杂的是，偏置的分布不同于权重的分布。通信组在求和运算中有所不同。</p></li></ul></li></ul> <p><img src="https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/parameter%20distribution.jpg" alt="Parameter distribution"></p> <ul><li><p>基于Chunk内存管理的零冗余优化器 (ZeRO)：零冗余优化器 (ZeRO) 通过对三个模型状态（优化器状态、梯度和参数）进行划分而不是复制他们，消除了数据并行进程中的内存冗余。该方法与传统的数据并行相比，内存效率得到了极大的提高，而计算粒度和通信效率得到了保留。</p> <ol><li><p>分片优化器状态: 优化器状态 (如 Adam optimizer, 32位的权重, 以及一二阶动量估计) 被划分到各个进程中, 因此每个进程只更新其分区。</p></li> <li><p>分片梯度: 在梯度在数据并行进程组内进行 reduction 后, 梯度张量也被划分，这样每个进程只存储与其划分的优化器状态对应的梯度。 注意, Colossal-AI 将梯度转换为 FP32 格式以参与更新参数。</p></li> <li><p>分片参数: 16位的模型参数被划分到一个数据并行组的进程中。</p></li> <li><p>Gemini: 对于参数、梯度、优化器状态的动态异构内存空间管理器。</p></li></ol></li></ul> <p>在使用零冗余优化器 (ZeRO)时，通过切分参数的方式对模型进行分布式存储，这种方法的优点是每个节点的内存负载是完全均衡的。但是这种方式有很多缺点。首先，通信时需要申请一块临时内存用来通信，通信完毕释放，这回导致存在内存碎片化的问题。其次，以Tensor为粒度进行通信，会导致网络带宽无法充分利用。通常来说传输的消息长度越长带宽利用率越高。</p> <p>利用Colossal-AI v0.1.8引入了Chunk机制，可以提升ZeRO的性能。通过将运算顺序上连续的一组参数存入一个Chunk中（Chunk即一段连续的内存空间），每个Chunk的大小相同。Chunk方式组织内存可以保证PCI-e和GPU-GPU之间网络带宽的高效利用，减小了通信次数，同时避免潜在的内存碎片。</p> <p>Colossal-AI提供了轻量级的Chunk搜索机制，帮助用户自动找到内存碎片最小的Chunk尺寸。</p> <ul><li><p>NVMe offload：GPU显存限制了我们可以训练的模型规模，这称为GPU显存墙。如果我们将优化器状态 offload 到磁盘，就可以突破 GPU 内存墙。</p> <ul><li><p>NVMe的全称是Non-Volatile Memory Express，翻译过来就是非易失性内存主机控制器接口规范</p></li> <li><p>Colossal-AI 实现了一个用户友好且高效的异步 Tensor I/O 库：TensorNVMe。有了这个库，我们可以简单地实现 NVMe offload。</p></li></ul></li></ul> <blockquote><p>该库与各种磁盘（HDD、SATA SSD 和 NVMe SSD）兼容。由于 HDD 或 SATA SSD 的 I/O 带宽较低，建议仅在 NVMe 磁盘上使用此库。</p> <p>NVMe协议本质是上建立了多个计算机与存储设备的通路，从而提高读写数据的速度。在NVMe协议中，多个通路其实就是多个队列。在SATA中计算机与存储设备只能有一个队列，即使是多CPU情况下，所有请求只能经过这样一个狭窄的道路。而NVMe协议可以最多有64K个队列，每个CPU或者核心都可以有一个队列，这样并发程度大大提升，性能也就更高了。</p></blockquote> <ul><li><p>ColoTensor是 ColossalAI 中张量的基本数据结构。 它是 torch.Tensor 的子类，可以当做 PyTorch Tensor使用，ColoTensor 包含额外的属性ColoTensorSpec 来描述张量的payload分布和计算模式</p> <ul><li><p>ProcessGroup：如何将进程组织为通信组。</p> <ul><li>ProcessGroup 类的一个实例描述了如何在进程组中组织进程。进程组内的进程可以一起参与同一个集合通信，比如allgather, allreduce等。进程组组织方式被张量的并行策略支配。</li> <li>ColoTensor 的一个进程组由 tp_degree 和 dp_degree 两种配置定义</li></ul></li> <li><p>Distributed Spec：张量如何在进程组之间分布。</p> <ul><li>张量在 DP 进程组之间的分布方式是自动导出的，不需要用户手动指定</li> <li>在使用 Distributed Spec 时，只需要描述张量在 TP 进程组之间的分布方式即可。TP 进程组目前有两种分布式规范，即 ShardSpec和ReplicaSpec
<ul><li>ShardSpec 需要指定分区的维度索引 dim 和分区个数 num_partitions</li> <li>TP进程组上不同的dist spec可以通过set_dist_spec()接口相互转换</li></ul></li></ul></li> <li><p>Compute Spec：计算过程中如何使用张量。</p> <ul><li>将作为module parameter的ColoTensor设置正确的Compute Pattern。可以触发正取的计算模式</li></ul></li></ul></li></ul> <h2 id="colossal-ai-的使用"><a href="#colossal-ai-的使用" class="header-anchor">#</a> Colossal-AI 的使用</h2> <h3 id="colossal-ai-的工作流"><a href="#colossal-ai-的工作流" class="header-anchor">#</a> Colossal-AI 的工作流</h3> <p><img src="https://wwp-study-notes.oss-cn-nanjing.aliyuncs.com/imgs/colossalai/Colossal-AI%20workflow.jpg" alt="Colossal-AI workflow"></p> <ol><li><p>准备一个配置文件，指定您要使用的功能和参数。</p></li> <li><p>用 colossalai.launch 初始化分布式后端。</p></li> <li><p>用 colossalai.initialize 将训练特征注入您的训练组件（如模型、优化器）中。</p></li> <li><p>进行训练和测试。</p></li></ol> <h3 id="构建配置文件"><a href="#构建配置文件" class="header-anchor">#</a> 构建配置文件</h3> <p>配置文件中指定参数</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># config.py 文件中设置 BATCH_SIZE超参数</span>
<span class="token keyword">import</span> colossalai
<span class="token keyword">from</span> colossalai<span class="token punctuation">.</span>core <span class="token keyword">import</span> global_context <span class="token keyword">as</span> gpc

colossalai<span class="token punctuation">.</span>launch<span class="token punctuation">(</span>config<span class="token operator">=</span><span class="token string">'./config.py'</span><span class="token punctuation">)</span>

<span class="token comment"># access your parameter</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>gpc<span class="token punctuation">.</span>config<span class="token punctuation">.</span>BATCH_SIZE<span class="token punctuation">)</span>
</code></pre></div><h3 id="初始化"><a href="#初始化" class="header-anchor">#</a> 初始化</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># initialize features</span>
engine<span class="token punctuation">,</span> train_dataloader<span class="token punctuation">,</span> test_dataloader<span class="token punctuation">,</span> _ <span class="token operator">=</span> colossalai<span class="token punctuation">.</span>initialize<span class="token punctuation">(</span>model<span class="token punctuation">,</span>
                                                                     optimizer<span class="token punctuation">,</span>
                                                                     criterion<span class="token punctuation">,</span>
                                                                     train_dataloader<span class="token punctuation">,</span>
                                                                     test_dataloader<span class="token punctuation">)</span>
</code></pre></div><h3 id="自动混合精度训练-amp"><a href="#自动混合精度训练-amp" class="header-anchor">#</a> 自动混合精度训练 (AMP)</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 使用 Torch AMP 可选参数如init_scale(float, optional, default=2.**16): 初始缩放因子</span>
fp16<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>
    mode <span class="token operator">=</span> AMP_TYPE<span class="token punctuation">.</span>TORCH 
<span class="token punctuation">)</span>
</code></pre></div><h3 id="并行配置"><a href="#并行配置" class="header-anchor">#</a> 并行配置</h3> <div class="language-python extra-class"><pre class="language-python"><code>parallel <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>
   pipeline<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token string">&quot;size&quot;</span><span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
   tensor<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token string">&quot;size&quot;</span><span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token string">&quot;mode&quot;</span><span class="token punctuation">:</span> <span class="token string">'1d'</span> <span class="token keyword">or</span> <span class="token string">'2d'</span> <span class="token keyword">or</span> <span class="token string">'2.5d'</span> <span class="token keyword">or</span> <span class="token string">'3d'</span><span class="token punctuation">,</span> <span class="token string">&quot;kwargs&quot;</span><span class="token punctuation">:</span> Any<span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre></div><h3 id="基于chunk内存管理的零冗余优化器-zero"><a href="#基于chunk内存管理的零冗余优化器-zero" class="header-anchor">#</a> 基于Chunk内存管理的零冗余优化器 (ZeRO)</h3> <p>运用GeminiDDP的方式来使用基于Chunk内存管理的ZeRO，它使用 ZeRO-DP 和 Gemini，其中ZeRO 用于并行，Gemini 用于内存管理</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 确保模型是在 ColoInitContext 的上下文中初始化的</span>
<span class="token keyword">with</span> ColoInitContext<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">,</span> default_dist_spec<span class="token operator">=</span>default_dist_spec<span class="token punctuation">,</span> default_pg<span class="token operator">=</span>default_pg<span class="token punctuation">)</span><span class="token punctuation">:</span>
  model <span class="token operator">=</span> gpt2_medium<span class="token punctuation">(</span>checkpoint<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">''' 模型参数如下 
      hidden dim是DNN的隐藏维度。用户可以提供这个参数来加快搜索速度。 默认值 1024；
      min_chunk_size_mb是以兆字节为单位的最小块大小。如果参数的总大小仍然小于最小块大小，则所有参数将被压缩为一个小块
'''</span>
chunk_manager <span class="token operator">=</span> init_chunk_manager<span class="token punctuation">(</span>model<span class="token operator">=</span>module<span class="token punctuation">,</span>
                                   init_device<span class="token operator">=</span>device<span class="token punctuation">,</span>
                                   hidden_dim<span class="token operator">=</span>hidden_dim<span class="token punctuation">,</span>
                                   search_range_mb<span class="token operator">=</span>search_range_mb<span class="token punctuation">,</span>
                                   min_chunk_size_mb<span class="token operator">=</span>min_chunk_size_mb<span class="token punctuation">)</span>
gemini_manager <span class="token operator">=</span> GeminiManager<span class="token punctuation">(</span>placement_policy<span class="token punctuation">,</span> chunk_manager<span class="token punctuation">)</span>
model <span class="token operator">=</span> ZeroDDP<span class="token punctuation">(</span>model<span class="token punctuation">,</span> gemini_manager<span class="token punctuation">)</span>
</code></pre></div><p>定义一个使用 Gemini + ZeRO DDP 的模型：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">gemini_zero_dpp</span><span class="token punctuation">(</span>model<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">,</span> pg<span class="token punctuation">:</span> ProcessGroup<span class="token punctuation">,</span> placememt_policy<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">&quot;auto&quot;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    cai_version <span class="token operator">=</span> colossalai<span class="token punctuation">.</span>__version__
    <span class="token keyword">if</span> version<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>cai_version<span class="token punctuation">)</span> <span class="token operator">&gt;</span> version<span class="token punctuation">.</span>parse<span class="token punctuation">(</span><span class="token string">&quot;0.1.10&quot;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> colossalai<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>parallel <span class="token keyword">import</span> GeminiDDP
        model <span class="token operator">=</span> GeminiDDP<span class="token punctuation">(</span>model<span class="token punctuation">,</span>
                          device<span class="token operator">=</span>get_current_device<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          placement_policy<span class="token operator">=</span>placememt_policy<span class="token punctuation">,</span>
                          pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                          search_range_mb<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> version<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>cai_version<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> version<span class="token punctuation">.</span>parse<span class="token punctuation">(</span><span class="token string">&quot;0.1.10&quot;</span><span class="token punctuation">)</span> <span class="token keyword">and</span> version<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>cai_version<span class="token punctuation">)</span> <span class="token operator">&gt;=</span> version<span class="token punctuation">.</span>parse<span class="token punctuation">(</span><span class="token string">&quot;0.1.9&quot;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> colossalai<span class="token punctuation">.</span>gemini <span class="token keyword">import</span> ChunkManager<span class="token punctuation">,</span> GeminiManager
        chunk_size <span class="token operator">=</span> ChunkManager<span class="token punctuation">.</span>search_chunk_size<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token number">64</span> <span class="token operator">*</span> <span class="token number">1024</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
        gemini_manager <span class="token operator">=</span> GeminiManager<span class="token punctuation">(</span>placememt_policy<span class="token punctuation">,</span> chunk_manager<span class="token punctuation">)</span>
        chunk_manager <span class="token operator">=</span> ChunkManager<span class="token punctuation">(</span>chunk_size<span class="token punctuation">,</span>
                                     pg<span class="token punctuation">,</span>
                                     enable_distributed_storage<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                            init_device<span class="token operator">=</span>GeminiManager<span class="token punctuation">.</span>get_default_device<span class="token punctuation">(</span>placememt_policy<span class="token punctuation">)</span><span class="token punctuation">)</span>
        model <span class="token operator">=</span> ZeroDDP<span class="token punctuation">(</span>model<span class="token punctuation">,</span> gemini_manager<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> NotImplemented<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;CAI version </span><span class="token interpolation"><span class="token punctuation">{</span>cai_version<span class="token punctuation">}</span></span><span class="token string"> is not supported&quot;</span></span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model
</code></pre></div><h3 id="nvme-offload-异步-tensor-i-o-库"><a href="#nvme-offload-异步-tensor-i-o-库" class="header-anchor">#</a> NVMe offload（异步 Tensor I/O 库）</h3> <p>使用前安装：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 目前实验平台装不上</span>
pip install packaging
pip install tensornvme
</code></pre></div><p>Adam (CPUAdam 和 HybridAdam) 实现了优化器状态的 NVMe offload</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> colossalai<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>optimizer <span class="token keyword">import</span> CPUAdam<span class="token punctuation">,</span> HybridAdam
<span class="token triple-quoted-string string">'''
    nvme_offload_fraction 是要 offload 到 NVMe 的优化器状态的比例。
    nvme_offload_dir 是保存 NVMe offload 文件的目录。如果 nvme_offload_dir 为 None，将使用随机临时目录
'''</span>
optimizer <span class="token operator">=</span> HybridAdam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">,</span> nvme_offload_fraction<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> nvme_offload_dir<span class="token operator">=</span><span class="token string">'./'</span><span class="token punctuation">)</span>
</code></pre></div><blockquote><p>它只会卸载在 CPU 上的优化器状态。这意味着它只会影响 CPU 训练或者使用卸载的 Zero/Gemini</p></blockquote> <h3 id="colotensor"><a href="#colotensor" class="header-anchor">#</a> ColoTensor</h3> <p>使用 tp_degree=4, dp_dgree=2 在 8 个 GPU 上初始化并Shard一个ColoTensor。 然后tensor被沿着 TP 进程组中的最后一个维度进行分片。 最后，我们沿着 TP 进程组中的第一个维度（dim 0）对其进行重新Shard。 注意观察每个张量的形状。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>multiprocessing <span class="token keyword">as</span> mp
<span class="token keyword">from</span> colossalai<span class="token punctuation">.</span>utils <span class="token keyword">import</span> free_port<span class="token punctuation">,</span> print_rank_0
<span class="token keyword">from</span> functools <span class="token keyword">import</span> partial

<span class="token keyword">import</span> colossalai
<span class="token keyword">from</span> colossalai<span class="token punctuation">.</span>tensor <span class="token keyword">import</span> ProcessGroup<span class="token punctuation">,</span> ColoTensor<span class="token punctuation">,</span> ColoTensorSpec<span class="token punctuation">,</span> ShardSpec<span class="token punctuation">,</span> ComputeSpec<span class="token punctuation">,</span> ComputePattern
<span class="token keyword">from</span> colossalai<span class="token punctuation">.</span>utils <span class="token keyword">import</span> free_port

<span class="token keyword">import</span> torch

<span class="token keyword">def</span> <span class="token function">run_dist_tests</span><span class="token punctuation">(</span>rank<span class="token punctuation">,</span> world_size<span class="token punctuation">,</span> port<span class="token punctuation">)</span><span class="token punctuation">:</span>
    colossalai<span class="token punctuation">.</span>launch<span class="token punctuation">(</span>config<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> rank<span class="token operator">=</span>rank<span class="token punctuation">,</span> world_size<span class="token operator">=</span>world_size<span class="token punctuation">,</span> host<span class="token operator">=</span><span class="token string">'localhost'</span><span class="token punctuation">,</span> port<span class="token operator">=</span>port<span class="token punctuation">,</span> backend<span class="token operator">=</span><span class="token string">'nccl'</span><span class="token punctuation">)</span>
    pg <span class="token operator">=</span> ProcessGroup<span class="token punctuation">(</span>tp_degree<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> dp_degree<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

    torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    local_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    print_rank_0<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;shape </span><span class="token interpolation"><span class="token punctuation">{</span>local_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">, </span><span class="token interpolation"><span class="token punctuation">{</span>local_tensor<span class="token punctuation">.</span>data<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>

    spec <span class="token operator">=</span> ColoTensorSpec<span class="token punctuation">(</span>pg<span class="token punctuation">,</span> ShardSpec<span class="token punctuation">(</span>dims<span class="token operator">=</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_partitions<span class="token operator">=</span><span class="token punctuation">[</span>pg<span class="token punctuation">.</span>tp_world_size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ComputeSpec<span class="token punctuation">(</span>ComputePattern<span class="token punctuation">.</span>TP1D<span class="token punctuation">)</span><span class="token punctuation">)</span>
    t1 <span class="token operator">=</span> ColoTensor<span class="token punctuation">.</span>from_torch_tensor<span class="token punctuation">(</span>local_tensor<span class="token punctuation">,</span> spec<span class="token punctuation">)</span>
    t1 <span class="token operator">=</span> t1<span class="token punctuation">.</span>to_replicate<span class="token punctuation">(</span><span class="token punctuation">)</span>
    print_rank_0<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;shape </span><span class="token interpolation"><span class="token punctuation">{</span>t1<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">, </span><span class="token interpolation"><span class="token punctuation">{</span>t1<span class="token punctuation">.</span>data<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>

    spec2 <span class="token operator">=</span> ShardSpec<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>pg<span class="token punctuation">.</span>tp_world_size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    t1<span class="token punctuation">.</span>set_dist_spec<span class="token punctuation">(</span>spec2<span class="token punctuation">)</span>
    print_rank_0<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;shape </span><span class="token interpolation"><span class="token punctuation">{</span>t1<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">, </span><span class="token interpolation"><span class="token punctuation">{</span>t1<span class="token punctuation">.</span>data<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">test_dist_cases</span><span class="token punctuation">(</span>world_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    run_func <span class="token operator">=</span> partial<span class="token punctuation">(</span>run_dist_tests<span class="token punctuation">,</span> world_size<span class="token operator">=</span>world_size<span class="token punctuation">,</span> port<span class="token operator">=</span>free_port<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    mp<span class="token punctuation">.</span>spawn<span class="token punctuation">(</span>run_func<span class="token punctuation">,</span> nprocs<span class="token operator">=</span>world_size<span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    test_dist_cases<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>
</code></pre></div></div></div>  <div class="page-edit"><!----> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2024/04/10, 16:15:18</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/study-notes/pages/c3610e/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">EfficientNet</div></a> <!----></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/study-notes/pages/c3610e/" class="prev">EfficientNet</a></span> <!----></p></div></div></div> <!----></main></div> <div class="footer"><div class="icons"><a href="3249364788@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://gitee.com/star_wwp" title="Gitee" target="_blank" class="iconfont icon-gitee"></a><a href="https://music.163.com/#/playlist?id=755597173" title="听音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2024-2024
    <span>MIT License</span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"></div></div>
    <script src="/study-notes/assets/js/app.8e25b80d.js" defer></script><script src="/study-notes/assets/js/2.75e49976.js" defer></script><script src="/study-notes/assets/js/50.77be5acd.js" defer></script>
  </body>
</html>
